{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from itertools import product\n",
    "from random import sample\n",
    "from string import lowercase, digits\n",
    "# from captcha.image import ImageCaptcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import py4j\n",
    "from py4j.java_gateway import JavaGateway, GatewayParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .初始化验证生成控件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "port = py4j.java_gateway.launch_gateway(classpath='/usr/lib/jvm/lib/kaptcha-2.3.2.jar')\n",
    "gateway = JavaGateway(gateway_parameters=GatewayParameters(port=port))\n",
    "constants = gateway.jvm.com.google.code.kaptcha.Constants\n",
    "ImageIO = gateway.jvm.javax.imageio.ImageIO\n",
    "filename = tempfile.mktemp(suffix='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fontSizeList = ['39', '40', '41', '42', '43', '44', '45']\n",
    "fontNameList = [\n",
    "    'Ubuntu Light',\n",
    "    'Ubuntu Light Italic',\n",
    "    'Ubuntu Regular',\n",
    "    'Ubuntu Regular Italic',\n",
    "    'Lato-Hairline',\n",
    "    'lmroman8-italic', \n",
    "    'lmmonocaps10-regular',\n",
    "    'Loma-Oblique',\n",
    "    'Norasi-Oblique',\n",
    "    'Umpush-Light',\n",
    "]\n",
    "kaptchaList = []\n",
    "for fontSize, fontName in product(fontSizeList, fontNameList):\n",
    "    properties = gateway.jvm.java.util.Properties()\n",
    "    properties.put(constants.KAPTCHA_IMAGE_WIDTH, '223')\n",
    "    properties.put(constants.KAPTCHA_IMAGE_HEIGHT, '50')\n",
    "    properties.put(constants.KAPTCHA_TEXTPRODUCER_FONT_SIZE, fontSize)\n",
    "    properties.put(constants.KAPTCHA_TEXTPRODUCER_FONT_NAMES, fontName)\n",
    "    properties.put(constants.KAPTCHA_BORDER, 'no')\n",
    "    kaptchaConfig = gateway.jvm.com.google.code.kaptcha.util.Config(properties)\n",
    "    kaptcha = gateway.jvm.com.google.code.kaptcha.impl.DefaultKaptcha()\n",
    "    kaptcha.setConfig(kaptchaConfig)\n",
    "    kaptchaList.append(kaptcha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .定义模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "width = 223\n",
    "height = 50\n",
    "# charset = '0123456789'\n",
    "# charset = '0123456789' + lowercase\n",
    "charset = digits + lowercase\n",
    "# captchaLength = 4\n",
    "captchaLength = 1\n",
    "imageSize = width * height\n",
    "alpha = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .定义相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getCode():\n",
    "#     return ''.join(map(\n",
    "#         lambda x: charset[x], \n",
    "#         # np.random.randint(0, len(charset), captchaLength)  \n",
    "#         np.random.randint(0, len(charset), 4) # changed\n",
    "#     ))\n",
    "# captcha = ImageCaptcha(width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getData(n = 10):    \n",
    "#     codeList = [getCode() for _ in range(n)]\n",
    "#     imageList = map(lambda code: captcha.generate_image(code), codeList)\n",
    "#     return imageList, codeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCode():\n",
    "    return kaptcha.createText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateImage(code):\n",
    "    kaptcha = sample(kaptchaList, 1)[0]\n",
    "    image = kaptcha.createImage(code)\n",
    "    f = gateway.jvm.java.io.File(filename)    \n",
    "    ImageIO.write(image, 'JPG', f)\n",
    "    image = Image.open(filename)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(n = 10):    \n",
    "    codeList = [getCode() for _ in range(n)]\n",
    "    imageList = map(lambda code: generateImage(code), codeList)\n",
    "    return imageList, codeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.random_normal(shape, stddev=0.01)                                                                                                     \n",
    "    return tf.Variable(initial)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W): \n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def imageToVertor(image):\n",
    "#     \"\"\" 将图片转化为向量表示 \"\"\"\n",
    "#     image = image.convert(\"L\")\n",
    "#     image = np.asarray(image)\n",
    "#     image = image.reshape([width * height]) / 255\n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageToVertor(image):\n",
    "    \"\"\" 将图片转化为向量表示 \"\"\"\n",
    "    width = image.width\n",
    "    height = image.height\n",
    "    image = image.convert(\"L\")\n",
    "    image = np.asarray(image)\n",
    "    image = image.reshape([width * height]) / 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def codeToVertor(code):\n",
    "    \"\"\" 将验证码转化为向量表示 \"\"\"\n",
    "    labels = np.zeros([captchaLength, len(charset)])\n",
    "    for i in range(captchaLength):\n",
    "        labels[i, charset.index(code[i])] = 1\n",
    "    return labels.reshape(len(charset) * captchaLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyban\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN8AAAAyCAIAAABTQZknAAAqNElEQVR4nO19eXRb5Zn+d7UvV7ra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\nOla9v6LW779J+z9EgACRqFlwwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=223x50 at 0x7EFC08B9F990>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试验证码\n",
    "code = getCode()\n",
    "print code\n",
    "generateImage(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .定义神经网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义输入输出\n",
    "x = tf.placeholder(tf.float32, shape=[None, imageSize])\n",
    "y = tf.placeholder(tf.float32, shape=[None, len(charset) * captchaLength])   \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(x, shape=[-1, width, height, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第一层卷积\n",
    "conv_layer1_weight = weight_variable([5, 5, 1, 32])\n",
    "conv_layer1_bias = bias_variable([32])\n",
    "pool_layer1 = max_pool(\n",
    "    tf.nn.relu(conv2d(x_image, conv_layer1_weight) + conv_layer1_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第二层卷积\n",
    "conv_layer2_weight = weight_variable([5, 5, 32, 64])\n",
    "conv_layer2_bias = bias_variable([64])\n",
    "pool_layer2 = max_pool(\n",
    "    tf.nn.relu(conv2d(pool_layer1, conv_layer2_weight) + conv_layer2_bias)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第三层卷积\n",
    "conv_layer3_weight = weight_variable([5, 5, 64, 64])\n",
    "conv_layer3_bias = bias_variable([64])\n",
    "pool_layer3 = max_pool(\n",
    "    tf.nn.relu(conv2d(pool_layer2, conv_layer3_weight) + conv_layer3_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastWidth = int(math.ceil(width / 8))\n",
    "lastHeight = int(math.ceil(height / 8))\n",
    "lastWidth, lastHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义全连接层\n",
    "fc_layer_weight = weight_variable([lastWidth * lastHeight * 64, 1024])\n",
    "fc_layer_bias = bias_variable([1024])\n",
    "pool_layer3_flat = tf.reshape(pool_layer3, [-1, lastWidth * lastHeight * 64])\n",
    "fc_layer = tf.nn.relu(tf.add(tf.matmul(pool_layer3_flat, fc_layer_weight), fc_layer_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout层\n",
    "fc_layer_drop = tf.nn.dropout(fc_layer, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Readout层(输出层)\n",
    "output_layer_weight = weight_variable([1024, len(charset) * captchaLength])   \n",
    "output_layer_bias = bias_variable([len(charset) * captchaLength])              \n",
    "y_conv = tf.add(tf.matmul(fc_layer_drop, output_layer_weight), output_layer_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义输出函数\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "optimizer = tf.train.AdamOptimizer(alpha).minimize(loss)\n",
    "prediction = tf.argmax(tf.reshape(y_conv, [-1, captchaLength, len(charset)]), 2)\n",
    "correct = tf.argmax(tf.reshape(y, [-1, captchaLength, len(charset)]), 2)                                                           \n",
    "correct_prediction = tf.equal(prediction, correct)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初始化session\n",
    "saver = tf.train.Saver()\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]: loss: 0.690100 accuracy: 0.050000\n",
      "[2]: loss: 0.496634 accuracy: 0.020000\n",
      "[3]: loss: 0.195056 accuracy: 0.020000\n",
      "[4]: loss: 0.175721 accuracy: 0.070000\n",
      "[5]: loss: 0.229177 accuracy: 0.110000\n",
      "[6]: loss: 0.212748 accuracy: 0.080000\n",
      "[7]: loss: 0.164275 accuracy: 0.070000\n",
      "[8]: loss: 0.121352 accuracy: 0.170000\n",
      "[9]: loss: 0.130202 accuracy: 0.110000\n",
      "[10]: loss: 0.138163 accuracy: 0.070000\n",
      "[11]: loss: 0.135607 accuracy: 0.040000\n",
      "[12]: loss: 0.124071 accuracy: 0.050000\n",
      "[13]: loss: 0.115226 accuracy: 0.050000\n",
      "[14]: loss: 0.117037 accuracy: 0.050000\n",
      "[15]: loss: 0.118763 accuracy: 0.030000\n",
      "[16]: loss: 0.127365 accuracy: 0.000000\n",
      "[17]: loss: 0.125643 accuracy: 0.090000\n",
      "[18]: loss: 0.122861 accuracy: 0.040000\n",
      "[19]: loss: 0.119040 accuracy: 0.030000\n",
      "[20]: loss: 0.117896 accuracy: 0.050000\n",
      "[21]: loss: 0.112994 accuracy: 0.040000\n",
      "[22]: loss: 0.114978 accuracy: 0.050000\n",
      "[23]: loss: 0.117453 accuracy: 0.080000\n",
      "[24]: loss: 0.114296 accuracy: 0.110000\n",
      "[25]: loss: 0.115451 accuracy: 0.100000\n",
      "[26]: loss: 0.116587 accuracy: 0.060000\n",
      "[27]: loss: 0.111702 accuracy: 0.120000\n",
      "[28]: loss: 0.113151 accuracy: 0.070000\n",
      "[29]: loss: 0.111391 accuracy: 0.110000\n",
      "[30]: loss: 0.114100 accuracy: 0.090000\n",
      "[31]: loss: 0.113879 accuracy: 0.070000\n",
      "[32]: loss: 0.114551 accuracy: 0.040000\n",
      "[33]: loss: 0.114150 accuracy: 0.060000\n",
      "[34]: loss: 0.112563 accuracy: 0.110000\n",
      "[35]: loss: 0.113432 accuracy: 0.040000\n",
      "[36]: loss: 0.113587 accuracy: 0.030000\n",
      "[37]: loss: 0.112548 accuracy: 0.060000\n",
      "[38]: loss: 0.111940 accuracy: 0.070000\n",
      "[39]: loss: 0.113043 accuracy: 0.050000\n",
      "[40]: loss: 0.111349 accuracy: 0.060000\n",
      "[41]: loss: 0.110777 accuracy: 0.070000\n",
      "[42]: loss: 0.111479 accuracy: 0.060000\n",
      "[43]: loss: 0.111076 accuracy: 0.100000\n",
      "[44]: loss: 0.110304 accuracy: 0.060000\n",
      "[45]: loss: 0.112047 accuracy: 0.060000\n",
      "[46]: loss: 0.110200 accuracy: 0.090000\n",
      "[47]: loss: 0.112418 accuracy: 0.080000\n",
      "[48]: loss: 0.113360 accuracy: 0.080000\n",
      "[49]: loss: 0.112839 accuracy: 0.090000\n",
      "[50]: loss: 0.111913 accuracy: 0.080000\n",
      "[51]: loss: 0.113009 accuracy: 0.070000\n",
      "[52]: loss: 0.111572 accuracy: 0.100000\n",
      "[53]: loss: 0.111852 accuracy: 0.050000\n",
      "[54]: loss: 0.111694 accuracy: 0.060000\n",
      "[55]: loss: 0.111790 accuracy: 0.080000\n",
      "[56]: loss: 0.111676 accuracy: 0.050000\n",
      "[57]: loss: 0.110239 accuracy: 0.090000\n",
      "[58]: loss: 0.110843 accuracy: 0.090000\n",
      "[59]: loss: 0.111784 accuracy: 0.080000\n",
      "[60]: loss: 0.112147 accuracy: 0.070000\n",
      "[61]: loss: 0.112931 accuracy: 0.030000\n",
      "[62]: loss: 0.111076 accuracy: 0.100000\n",
      "[63]: loss: 0.110243 accuracy: 0.120000\n",
      "[64]: loss: 0.111800 accuracy: 0.050000\n",
      "[65]: loss: 0.111560 accuracy: 0.060000\n",
      "[66]: loss: 0.112273 accuracy: 0.080000\n",
      "[67]: loss: 0.112179 accuracy: 0.070000\n",
      "[68]: loss: 0.112638 accuracy: 0.050000\n",
      "[69]: loss: 0.112257 accuracy: 0.050000\n",
      "[70]: loss: 0.111441 accuracy: 0.080000\n",
      "[71]: loss: 0.113363 accuracy: 0.030000\n",
      "[72]: loss: 0.109948 accuracy: 0.050000\n",
      "[73]: loss: 0.111319 accuracy: 0.090000\n",
      "[74]: loss: 0.112686 accuracy: 0.090000\n",
      "[75]: loss: 0.110650 accuracy: 0.090000\n",
      "[76]: loss: 0.110983 accuracy: 0.070000\n",
      "[77]: loss: 0.110973 accuracy: 0.070000\n",
      "[78]: loss: 0.110774 accuracy: 0.080000\n",
      "[79]: loss: 0.111934 accuracy: 0.030000\n",
      "[80]: loss: 0.112086 accuracy: 0.070000\n",
      "[81]: loss: 0.110300 accuracy: 0.060000\n",
      "[82]: loss: 0.112227 accuracy: 0.060000\n",
      "[83]: loss: 0.111281 accuracy: 0.070000\n",
      "[84]: loss: 0.110726 accuracy: 0.130000\n",
      "[85]: loss: 0.108832 accuracy: 0.140000\n",
      "[86]: loss: 0.109819 accuracy: 0.120000\n",
      "[87]: loss: 0.111962 accuracy: 0.060000\n",
      "[88]: loss: 0.108587 accuracy: 0.130000\n",
      "[89]: loss: 0.111947 accuracy: 0.100000\n",
      "[90]: loss: 0.110604 accuracy: 0.090000\n",
      "[91]: loss: 0.113301 accuracy: 0.060000\n",
      "[92]: loss: 0.111367 accuracy: 0.100000\n",
      "[93]: loss: 0.109061 accuracy: 0.120000\n",
      "[94]: loss: 0.110825 accuracy: 0.110000\n",
      "[95]: loss: 0.110362 accuracy: 0.120000\n",
      "[96]: loss: 0.112197 accuracy: 0.080000\n",
      "[97]: loss: 0.112791 accuracy: 0.090000\n",
      "[98]: loss: 0.112094 accuracy: 0.060000\n",
      "[99]: loss: 0.112687 accuracy: 0.050000\n",
      "[100]: loss: 0.112729 accuracy: 0.020000\n",
      "[101]: loss: 0.110900 accuracy: 0.080000\n",
      "[102]: loss: 0.111586 accuracy: 0.070000\n",
      "[103]: loss: 0.111208 accuracy: 0.080000\n",
      "[104]: loss: 0.112092 accuracy: 0.030000\n",
      "[105]: loss: 0.112289 accuracy: 0.040000\n",
      "[106]: loss: 0.113153 accuracy: 0.030000\n",
      "[107]: loss: 0.112201 accuracy: 0.070000\n",
      "[108]: loss: 0.110728 accuracy: 0.030000\n",
      "[109]: loss: 0.110258 accuracy: 0.150000\n",
      "[110]: loss: 0.112667 accuracy: 0.080000\n",
      "[111]: loss: 0.111945 accuracy: 0.060000\n",
      "[112]: loss: 0.109721 accuracy: 0.120000\n",
      "[113]: loss: 0.110919 accuracy: 0.100000\n",
      "[114]: loss: 0.109281 accuracy: 0.150000\n",
      "[115]: loss: 0.110091 accuracy: 0.120000\n",
      "[116]: loss: 0.110323 accuracy: 0.120000\n",
      "[117]: loss: 0.112040 accuracy: 0.090000\n",
      "[118]: loss: 0.112119 accuracy: 0.100000\n",
      "[119]: loss: 0.111561 accuracy: 0.110000\n",
      "[120]: loss: 0.110025 accuracy: 0.110000\n",
      "[121]: loss: 0.113166 accuracy: 0.060000\n",
      "[122]: loss: 0.113332 accuracy: 0.060000\n",
      "[123]: loss: 0.110535 accuracy: 0.110000\n",
      "[124]: loss: 0.110851 accuracy: 0.080000\n",
      "[125]: loss: 0.112178 accuracy: 0.070000\n",
      "[126]: loss: 0.110621 accuracy: 0.090000\n",
      "[127]: loss: 0.111514 accuracy: 0.050000\n",
      "[128]: loss: 0.111955 accuracy: 0.070000\n",
      "[129]: loss: 0.110873 accuracy: 0.060000\n",
      "[130]: loss: 0.110860 accuracy: 0.060000\n",
      "[131]: loss: 0.111958 accuracy: 0.040000\n",
      "[132]: loss: 0.109777 accuracy: 0.090000\n",
      "[133]: loss: 0.111015 accuracy: 0.070000\n",
      "[134]: loss: 0.111816 accuracy: 0.080000\n",
      "[135]: loss: 0.111004 accuracy: 0.100000\n",
      "[136]: loss: 0.109216 accuracy: 0.140000\n",
      "[137]: loss: 0.109693 accuracy: 0.090000\n",
      "[138]: loss: 0.111665 accuracy: 0.120000\n",
      "[139]: loss: 0.111379 accuracy: 0.070000\n",
      "[140]: loss: 0.110428 accuracy: 0.110000\n",
      "[141]: loss: 0.110867 accuracy: 0.090000\n",
      "[142]: loss: 0.110149 accuracy: 0.160000\n",
      "[143]: loss: 0.109547 accuracy: 0.130000\n",
      "[144]: loss: 0.110481 accuracy: 0.130000\n",
      "[145]: loss: 0.111819 accuracy: 0.080000\n",
      "[146]: loss: 0.110808 accuracy: 0.110000\n",
      "[147]: loss: 0.111148 accuracy: 0.070000\n",
      "[148]: loss: 0.113458 accuracy: 0.060000\n",
      "[149]: loss: 0.112499 accuracy: 0.070000\n",
      "[150]: loss: 0.111781 accuracy: 0.060000\n",
      "[151]: loss: 0.111076 accuracy: 0.050000\n",
      "[152]: loss: 0.112513 accuracy: 0.030000\n",
      "[153]: loss: 0.110596 accuracy: 0.060000\n",
      "[154]: loss: 0.111195 accuracy: 0.100000\n",
      "[155]: loss: 0.111321 accuracy: 0.070000\n",
      "[156]: loss: 0.112835 accuracy: 0.040000\n",
      "[157]: loss: 0.111253 accuracy: 0.070000\n",
      "[158]: loss: 0.112042 accuracy: 0.020000\n",
      "[159]: loss: 0.112489 accuracy: 0.100000\n",
      "[160]: loss: 0.110020 accuracy: 0.090000\n",
      "[161]: loss: 0.112914 accuracy: 0.020000\n",
      "[162]: loss: 0.110711 accuracy: 0.070000\n",
      "[163]: loss: 0.111325 accuracy: 0.060000\n",
      "[164]: loss: 0.112048 accuracy: 0.090000\n",
      "[165]: loss: 0.110782 accuracy: 0.090000\n",
      "[166]: loss: 0.112270 accuracy: 0.020000\n",
      "[167]: loss: 0.111123 accuracy: 0.070000\n",
      "[168]: loss: 0.111273 accuracy: 0.130000\n",
      "[169]: loss: 0.111224 accuracy: 0.060000\n",
      "[170]: loss: 0.112100 accuracy: 0.080000\n",
      "[171]: loss: 0.109949 accuracy: 0.120000\n",
      "[172]: loss: 0.110453 accuracy: 0.090000\n",
      "[173]: loss: 0.110888 accuracy: 0.090000\n",
      "[174]: loss: 0.110652 accuracy: 0.110000\n",
      "[175]: loss: 0.111725 accuracy: 0.060000\n",
      "[176]: loss: 0.113250 accuracy: 0.060000\n",
      "[177]: loss: 0.111601 accuracy: 0.040000\n",
      "[178]: loss: 0.111328 accuracy: 0.100000\n",
      "[179]: loss: 0.111235 accuracy: 0.090000\n",
      "[180]: loss: 0.112920 accuracy: 0.050000\n",
      "[181]: loss: 0.110956 accuracy: 0.060000\n",
      "[182]: loss: 0.111195 accuracy: 0.080000\n",
      "[183]: loss: 0.110445 accuracy: 0.090000\n",
      "[184]: loss: 0.110311 accuracy: 0.060000\n",
      "[185]: loss: 0.112052 accuracy: 0.050000\n",
      "[186]: loss: 0.111217 accuracy: 0.070000\n",
      "[187]: loss: 0.111151 accuracy: 0.070000\n",
      "[188]: loss: 0.111054 accuracy: 0.090000\n",
      "[189]: loss: 0.109760 accuracy: 0.080000\n",
      "[190]: loss: 0.112410 accuracy: 0.080000\n",
      "[191]: loss: 0.110726 accuracy: 0.080000\n",
      "[192]: loss: 0.110248 accuracy: 0.100000\n",
      "[193]: loss: 0.111060 accuracy: 0.080000\n",
      "[194]: loss: 0.110684 accuracy: 0.120000\n",
      "[195]: loss: 0.111882 accuracy: 0.060000\n",
      "[196]: loss: 0.109790 accuracy: 0.140000\n",
      "[197]: loss: 0.110338 accuracy: 0.090000\n",
      "[198]: loss: 0.111919 accuracy: 0.050000\n",
      "[199]: loss: 0.112963 accuracy: 0.060000\n",
      "[200]: loss: 0.111410 accuracy: 0.090000\n",
      "[201]: loss: 0.111043 accuracy: 0.080000\n",
      "[202]: loss: 0.111369 accuracy: 0.060000\n",
      "[203]: loss: 0.110413 accuracy: 0.080000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]: loss: 0.111571 accuracy: 0.060000\n",
      "[205]: loss: 0.109684 accuracy: 0.100000\n",
      "[206]: loss: 0.110056 accuracy: 0.130000\n",
      "[207]: loss: 0.110817 accuracy: 0.090000\n",
      "[208]: loss: 0.110159 accuracy: 0.060000\n",
      "[209]: loss: 0.110704 accuracy: 0.090000\n",
      "[210]: loss: 0.110834 accuracy: 0.100000\n",
      "[211]: loss: 0.112131 accuracy: 0.070000\n",
      "[212]: loss: 0.109446 accuracy: 0.150000\n",
      "[213]: loss: 0.109884 accuracy: 0.120000\n",
      "[214]: loss: 0.109891 accuracy: 0.120000\n",
      "[215]: loss: 0.110079 accuracy: 0.130000\n",
      "[216]: loss: 0.109527 accuracy: 0.110000\n",
      "[217]: loss: 0.110136 accuracy: 0.130000\n",
      "[218]: loss: 0.111849 accuracy: 0.080000\n",
      "[219]: loss: 0.111186 accuracy: 0.090000\n",
      "[220]: loss: 0.109234 accuracy: 0.150000\n",
      "[221]: loss: 0.111562 accuracy: 0.070000\n",
      "[222]: loss: 0.109581 accuracy: 0.100000\n",
      "[223]: loss: 0.112030 accuracy: 0.080000\n",
      "[224]: loss: 0.110430 accuracy: 0.110000\n",
      "[225]: loss: 0.110680 accuracy: 0.120000\n",
      "[226]: loss: 0.111611 accuracy: 0.090000\n",
      "[227]: loss: 0.110460 accuracy: 0.110000\n",
      "[228]: loss: 0.110981 accuracy: 0.150000\n",
      "[229]: loss: 0.109381 accuracy: 0.130000\n",
      "[230]: loss: 0.112292 accuracy: 0.090000\n",
      "[231]: loss: 0.111509 accuracy: 0.090000\n",
      "[232]: loss: 0.110670 accuracy: 0.100000\n",
      "[233]: loss: 0.109771 accuracy: 0.110000\n",
      "[234]: loss: 0.110628 accuracy: 0.120000\n",
      "[235]: loss: 0.111437 accuracy: 0.040000\n",
      "[236]: loss: 0.109711 accuracy: 0.130000\n",
      "[237]: loss: 0.110965 accuracy: 0.090000\n",
      "[238]: loss: 0.112117 accuracy: 0.070000\n",
      "[239]: loss: 0.110655 accuracy: 0.070000\n",
      "[240]: loss: 0.110412 accuracy: 0.070000\n",
      "[241]: loss: 0.112276 accuracy: 0.070000\n",
      "[242]: loss: 0.109918 accuracy: 0.090000\n",
      "[243]: loss: 0.110882 accuracy: 0.080000\n",
      "[244]: loss: 0.112054 accuracy: 0.010000\n",
      "[245]: loss: 0.111255 accuracy: 0.110000\n",
      "[246]: loss: 0.110624 accuracy: 0.080000\n",
      "[247]: loss: 0.111408 accuracy: 0.060000\n",
      "[248]: loss: 0.111527 accuracy: 0.080000\n",
      "[249]: loss: 0.111171 accuracy: 0.080000\n",
      "[250]: loss: 0.108960 accuracy: 0.140000\n",
      "[251]: loss: 0.111697 accuracy: 0.050000\n",
      "[252]: loss: 0.111715 accuracy: 0.070000\n",
      "[253]: loss: 0.111340 accuracy: 0.080000\n",
      "[254]: loss: 0.109645 accuracy: 0.130000\n",
      "[255]: loss: 0.111317 accuracy: 0.080000\n",
      "[256]: loss: 0.111673 accuracy: 0.110000\n",
      "[257]: loss: 0.111100 accuracy: 0.090000\n",
      "[258]: loss: 0.112872 accuracy: 0.110000\n",
      "[259]: loss: 0.110876 accuracy: 0.070000\n",
      "[260]: loss: 0.111227 accuracy: 0.100000\n",
      "[261]: loss: 0.109908 accuracy: 0.130000\n",
      "[262]: loss: 0.111979 accuracy: 0.080000\n",
      "[263]: loss: 0.110726 accuracy: 0.100000\n",
      "[264]: loss: 0.110420 accuracy: 0.090000\n",
      "[265]: loss: 0.111174 accuracy: 0.080000\n",
      "[266]: loss: 0.109595 accuracy: 0.140000\n",
      "[267]: loss: 0.109637 accuracy: 0.110000\n",
      "[268]: loss: 0.112087 accuracy: 0.100000\n",
      "[269]: loss: 0.111205 accuracy: 0.070000\n",
      "[270]: loss: 0.112897 accuracy: 0.080000\n",
      "[271]: loss: 0.111874 accuracy: 0.100000\n",
      "[272]: loss: 0.111243 accuracy: 0.090000\n",
      "[273]: loss: 0.110331 accuracy: 0.100000\n",
      "[274]: loss: 0.110745 accuracy: 0.080000\n",
      "[275]: loss: 0.110292 accuracy: 0.100000\n",
      "[276]: loss: 0.111596 accuracy: 0.080000\n",
      "[277]: loss: 0.110449 accuracy: 0.090000\n",
      "[278]: loss: 0.110558 accuracy: 0.120000\n",
      "[279]: loss: 0.110545 accuracy: 0.110000\n",
      "[280]: loss: 0.111116 accuracy: 0.080000\n",
      "[281]: loss: 0.110702 accuracy: 0.080000\n",
      "[282]: loss: 0.110369 accuracy: 0.080000\n",
      "[283]: loss: 0.112196 accuracy: 0.080000\n",
      "[284]: loss: 0.110696 accuracy: 0.080000\n",
      "[285]: loss: 0.111724 accuracy: 0.060000\n",
      "[286]: loss: 0.112060 accuracy: 0.090000\n",
      "[287]: loss: 0.109864 accuracy: 0.110000\n",
      "[288]: loss: 0.110908 accuracy: 0.100000\n",
      "[289]: loss: 0.111729 accuracy: 0.090000\n",
      "[290]: loss: 0.110213 accuracy: 0.150000\n",
      "[291]: loss: 0.111192 accuracy: 0.080000\n",
      "[292]: loss: 0.111061 accuracy: 0.080000\n",
      "[293]: loss: 0.110794 accuracy: 0.110000\n",
      "[294]: loss: 0.110471 accuracy: 0.120000\n",
      "[295]: loss: 0.109565 accuracy: 0.110000\n",
      "[296]: loss: 0.108936 accuracy: 0.130000\n",
      "[297]: loss: 0.109402 accuracy: 0.150000\n",
      "[298]: loss: 0.109556 accuracy: 0.110000\n",
      "[299]: loss: 0.112721 accuracy: 0.050000\n",
      "[300]: loss: 0.111648 accuracy: 0.070000\n",
      "[301]: loss: 0.111633 accuracy: 0.080000\n",
      "[302]: loss: 0.111589 accuracy: 0.030000\n",
      "[303]: loss: 0.109459 accuracy: 0.140000\n",
      "[304]: loss: 0.111920 accuracy: 0.090000\n",
      "[305]: loss: 0.111092 accuracy: 0.100000\n",
      "[306]: loss: 0.112200 accuracy: 0.060000\n",
      "[307]: loss: 0.111558 accuracy: 0.080000\n",
      "[308]: loss: 0.110948 accuracy: 0.090000\n",
      "[309]: loss: 0.109556 accuracy: 0.130000\n",
      "[310]: loss: 0.110077 accuracy: 0.080000\n",
      "[311]: loss: 0.110860 accuracy: 0.080000\n",
      "[312]: loss: 0.110095 accuracy: 0.090000\n",
      "[313]: loss: 0.110842 accuracy: 0.080000\n",
      "[314]: loss: 0.110881 accuracy: 0.120000\n",
      "[315]: loss: 0.111127 accuracy: 0.100000\n",
      "[316]: loss: 0.110338 accuracy: 0.100000\n",
      "[317]: loss: 0.109736 accuracy: 0.120000\n",
      "[318]: loss: 0.109703 accuracy: 0.120000\n",
      "[319]: loss: 0.110281 accuracy: 0.090000\n",
      "[320]: loss: 0.110877 accuracy: 0.050000\n",
      "[321]: loss: 0.108938 accuracy: 0.170000\n",
      "[322]: loss: 0.109702 accuracy: 0.110000\n",
      "[323]: loss: 0.110819 accuracy: 0.110000\n",
      "[324]: loss: 0.110693 accuracy: 0.110000\n",
      "[325]: loss: 0.110463 accuracy: 0.120000\n",
      "[326]: loss: 0.110999 accuracy: 0.120000\n",
      "[327]: loss: 0.108412 accuracy: 0.150000\n",
      "[328]: loss: 0.110042 accuracy: 0.140000\n",
      "[329]: loss: 0.110722 accuracy: 0.070000\n",
      "[330]: loss: 0.110842 accuracy: 0.080000\n",
      "[331]: loss: 0.111404 accuracy: 0.090000\n",
      "[332]: loss: 0.112825 accuracy: 0.030000\n",
      "[333]: loss: 0.108792 accuracy: 0.130000\n",
      "[334]: loss: 0.109879 accuracy: 0.130000\n",
      "[335]: loss: 0.110639 accuracy: 0.100000\n",
      "[336]: loss: 0.110422 accuracy: 0.090000\n",
      "[337]: loss: 0.110962 accuracy: 0.080000\n",
      "[338]: loss: 0.110148 accuracy: 0.130000\n",
      "[339]: loss: 0.110398 accuracy: 0.120000\n",
      "[340]: loss: 0.110710 accuracy: 0.070000\n",
      "[341]: loss: 0.110145 accuracy: 0.120000\n",
      "[342]: loss: 0.110650 accuracy: 0.100000\n",
      "[343]: loss: 0.110289 accuracy: 0.120000\n",
      "[344]: loss: 0.110320 accuracy: 0.110000\n",
      "[345]: loss: 0.110254 accuracy: 0.110000\n",
      "[346]: loss: 0.109636 accuracy: 0.100000\n",
      "[347]: loss: 0.110232 accuracy: 0.110000\n",
      "[348]: loss: 0.110557 accuracy: 0.110000\n",
      "[349]: loss: 0.109695 accuracy: 0.140000\n",
      "[350]: loss: 0.111198 accuracy: 0.080000\n",
      "[351]: loss: 0.109917 accuracy: 0.110000\n",
      "[352]: loss: 0.111412 accuracy: 0.070000\n",
      "[353]: loss: 0.107976 accuracy: 0.160000\n",
      "[354]: loss: 0.111480 accuracy: 0.090000\n",
      "[355]: loss: 0.109580 accuracy: 0.120000\n",
      "[356]: loss: 0.111437 accuracy: 0.050000\n",
      "[357]: loss: 0.110307 accuracy: 0.100000\n",
      "[358]: loss: 0.113558 accuracy: 0.050000\n",
      "[359]: loss: 0.111774 accuracy: 0.040000\n",
      "[360]: loss: 0.110803 accuracy: 0.110000\n",
      "[361]: loss: 0.110111 accuracy: 0.100000\n",
      "[362]: loss: 0.109718 accuracy: 0.160000\n",
      "[363]: loss: 0.110679 accuracy: 0.110000\n",
      "[364]: loss: 0.110304 accuracy: 0.090000\n",
      "[365]: loss: 0.110644 accuracy: 0.110000\n",
      "[366]: loss: 0.111802 accuracy: 0.040000\n",
      "[367]: loss: 0.109801 accuracy: 0.140000\n",
      "[368]: loss: 0.109377 accuracy: 0.110000\n",
      "[369]: loss: 0.110649 accuracy: 0.090000\n",
      "[370]: loss: 0.109100 accuracy: 0.130000\n",
      "[371]: loss: 0.111826 accuracy: 0.080000\n",
      "[372]: loss: 0.111245 accuracy: 0.070000\n",
      "[373]: loss: 0.112102 accuracy: 0.030000\n",
      "[374]: loss: 0.110000 accuracy: 0.100000\n",
      "[375]: loss: 0.110449 accuracy: 0.080000\n",
      "[376]: loss: 0.110091 accuracy: 0.070000\n",
      "[377]: loss: 0.110445 accuracy: 0.110000\n",
      "[378]: loss: 0.110294 accuracy: 0.120000\n",
      "[379]: loss: 0.110763 accuracy: 0.080000\n",
      "[380]: loss: 0.109131 accuracy: 0.100000\n",
      "[381]: loss: 0.112061 accuracy: 0.060000\n",
      "[382]: loss: 0.110903 accuracy: 0.090000\n",
      "[383]: loss: 0.110477 accuracy: 0.120000\n",
      "[384]: loss: 0.111131 accuracy: 0.040000\n",
      "[385]: loss: 0.110891 accuracy: 0.060000\n",
      "[386]: loss: 0.111653 accuracy: 0.070000\n",
      "[387]: loss: 0.109454 accuracy: 0.110000\n",
      "[388]: loss: 0.109271 accuracy: 0.120000\n",
      "[389]: loss: 0.111835 accuracy: 0.070000\n",
      "[390]: loss: 0.111347 accuracy: 0.080000\n",
      "[391]: loss: 0.111134 accuracy: 0.080000\n",
      "[392]: loss: 0.112194 accuracy: 0.040000\n",
      "[393]: loss: 0.110493 accuracy: 0.080000\n",
      "[394]: loss: 0.111456 accuracy: 0.070000\n",
      "[395]: loss: 0.109032 accuracy: 0.120000\n",
      "[396]: loss: 0.111331 accuracy: 0.070000\n",
      "[397]: loss: 0.110588 accuracy: 0.120000\n",
      "[398]: loss: 0.113018 accuracy: 0.050000\n",
      "[399]: loss: 0.110468 accuracy: 0.100000\n",
      "[400]: loss: 0.111168 accuracy: 0.100000\n",
      "[401]: loss: 0.110786 accuracy: 0.080000\n",
      "[402]: loss: 0.111731 accuracy: 0.080000\n",
      "[403]: loss: 0.111701 accuracy: 0.080000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[404]: loss: 0.109832 accuracy: 0.080000\n",
      "[405]: loss: 0.110466 accuracy: 0.090000\n",
      "[406]: loss: 0.111619 accuracy: 0.100000\n",
      "[407]: loss: 0.111904 accuracy: 0.080000\n",
      "[408]: loss: 0.111643 accuracy: 0.090000\n",
      "[409]: loss: 0.111236 accuracy: 0.060000\n",
      "[410]: loss: 0.112286 accuracy: 0.070000\n",
      "[411]: loss: 0.110306 accuracy: 0.120000\n",
      "[412]: loss: 0.110588 accuracy: 0.100000\n",
      "[413]: loss: 0.112180 accuracy: 0.010000\n",
      "[414]: loss: 0.111405 accuracy: 0.090000\n",
      "[415]: loss: 0.110983 accuracy: 0.070000\n",
      "[416]: loss: 0.111365 accuracy: 0.070000\n",
      "[417]: loss: 0.111138 accuracy: 0.050000\n",
      "[418]: loss: 0.110075 accuracy: 0.120000\n",
      "[419]: loss: 0.110829 accuracy: 0.080000\n",
      "[420]: loss: 0.111344 accuracy: 0.080000\n",
      "[421]: loss: 0.110658 accuracy: 0.060000\n",
      "[422]: loss: 0.110431 accuracy: 0.130000\n",
      "[423]: loss: 0.111062 accuracy: 0.090000\n",
      "[424]: loss: 0.111854 accuracy: 0.060000\n",
      "[425]: loss: 0.109479 accuracy: 0.110000\n",
      "[426]: loss: 0.110981 accuracy: 0.070000\n",
      "[427]: loss: 0.111961 accuracy: 0.050000\n",
      "[428]: loss: 0.109691 accuracy: 0.100000\n",
      "[429]: loss: 0.110108 accuracy: 0.120000\n",
      "[430]: loss: 0.109295 accuracy: 0.120000\n",
      "[431]: loss: 0.107283 accuracy: 0.210000\n",
      "[432]: loss: 0.110333 accuracy: 0.080000\n",
      "[433]: loss: 0.111842 accuracy: 0.050000\n",
      "[434]: loss: 0.110926 accuracy: 0.120000\n",
      "[435]: loss: 0.112108 accuracy: 0.090000\n",
      "[436]: loss: 0.110204 accuracy: 0.090000\n",
      "[437]: loss: 0.110667 accuracy: 0.100000\n",
      "[438]: loss: 0.112246 accuracy: 0.070000\n",
      "[439]: loss: 0.110772 accuracy: 0.110000\n",
      "[440]: loss: 0.112177 accuracy: 0.060000\n",
      "[441]: loss: 0.110490 accuracy: 0.110000\n",
      "[442]: loss: 0.110824 accuracy: 0.070000\n",
      "[443]: loss: 0.110792 accuracy: 0.050000\n",
      "[444]: loss: 0.109713 accuracy: 0.100000\n",
      "[445]: loss: 0.111265 accuracy: 0.080000\n",
      "[446]: loss: 0.111451 accuracy: 0.090000\n",
      "[447]: loss: 0.109771 accuracy: 0.110000\n",
      "[448]: loss: 0.111206 accuracy: 0.060000\n",
      "[449]: loss: 0.110240 accuracy: 0.080000\n",
      "[450]: loss: 0.110569 accuracy: 0.090000\n",
      "[451]: loss: 0.108786 accuracy: 0.100000\n",
      "[452]: loss: 0.110196 accuracy: 0.140000\n",
      "[453]: loss: 0.111904 accuracy: 0.050000\n",
      "[454]: loss: 0.110691 accuracy: 0.110000\n",
      "[455]: loss: 0.110125 accuracy: 0.110000\n",
      "[456]: loss: 0.111195 accuracy: 0.090000\n",
      "[457]: loss: 0.110488 accuracy: 0.080000\n",
      "[458]: loss: 0.110554 accuracy: 0.090000\n",
      "[459]: loss: 0.111034 accuracy: 0.090000\n",
      "[460]: loss: 0.109957 accuracy: 0.100000\n",
      "[461]: loss: 0.110323 accuracy: 0.070000\n",
      "[462]: loss: 0.109866 accuracy: 0.130000\n",
      "[463]: loss: 0.110328 accuracy: 0.090000\n",
      "[464]: loss: 0.109658 accuracy: 0.100000\n",
      "[465]: loss: 0.112230 accuracy: 0.060000\n",
      "[466]: loss: 0.108900 accuracy: 0.130000\n",
      "[467]: loss: 0.110104 accuracy: 0.100000\n",
      "[468]: loss: 0.110901 accuracy: 0.110000\n",
      "[469]: loss: 0.110320 accuracy: 0.090000\n",
      "[470]: loss: 0.110680 accuracy: 0.080000\n",
      "[471]: loss: 0.110855 accuracy: 0.080000\n",
      "[472]: loss: 0.109073 accuracy: 0.120000\n",
      "[473]: loss: 0.112202 accuracy: 0.070000\n",
      "[474]: loss: 0.110640 accuracy: 0.090000\n",
      "[475]: loss: 0.109291 accuracy: 0.150000\n",
      "[476]: loss: 0.110609 accuracy: 0.090000\n",
      "[477]: loss: 0.110849 accuracy: 0.060000\n",
      "[478]: loss: 0.110569 accuracy: 0.100000\n",
      "[479]: loss: 0.110082 accuracy: 0.100000\n",
      "[480]: loss: 0.110306 accuracy: 0.090000\n",
      "[481]: loss: 0.109939 accuracy: 0.120000\n",
      "[482]: loss: 0.111127 accuracy: 0.050000\n",
      "[483]: loss: 0.111082 accuracy: 0.090000\n",
      "[484]: loss: 0.110356 accuracy: 0.090000\n",
      "[485]: loss: 0.110775 accuracy: 0.090000\n",
      "[486]: loss: 0.109591 accuracy: 0.120000\n",
      "[487]: loss: 0.110112 accuracy: 0.110000\n",
      "[488]: loss: 0.111194 accuracy: 0.100000\n",
      "[489]: loss: 0.110045 accuracy: 0.090000\n",
      "[490]: loss: 0.109986 accuracy: 0.100000\n",
      "[491]: loss: 0.111238 accuracy: 0.070000\n",
      "[492]: loss: 0.110756 accuracy: 0.090000\n",
      "[493]: loss: 0.109848 accuracy: 0.090000\n",
      "[494]: loss: 0.109641 accuracy: 0.140000\n",
      "[495]: loss: 0.110084 accuracy: 0.080000\n",
      "[496]: loss: 0.112305 accuracy: 0.070000\n",
      "[497]: loss: 0.109996 accuracy: 0.120000\n",
      "[498]: loss: 0.109786 accuracy: 0.070000\n",
      "[499]: loss: 0.112306 accuracy: 0.090000\n",
      "[500]: loss: 0.111551 accuracy: 0.070000\n",
      "[501]: loss: 0.109615 accuracy: 0.140000\n",
      "[502]: loss: 0.110600 accuracy: 0.110000\n",
      "[503]: loss: 0.109305 accuracy: 0.130000\n",
      "[504]: loss: 0.109398 accuracy: 0.110000\n",
      "[505]: loss: 0.112528 accuracy: 0.080000\n",
      "[506]: loss: 0.110296 accuracy: 0.060000\n",
      "[507]: loss: 0.109702 accuracy: 0.090000\n",
      "[508]: loss: 0.111807 accuracy: 0.040000\n",
      "[509]: loss: 0.109340 accuracy: 0.100000\n",
      "[510]: loss: 0.110730 accuracy: 0.110000\n",
      "[511]: loss: 0.111341 accuracy: 0.100000\n",
      "[512]: loss: 0.109936 accuracy: 0.060000\n",
      "[513]: loss: 0.111871 accuracy: 0.050000\n",
      "[514]: loss: 0.111968 accuracy: 0.060000\n",
      "[515]: loss: 0.110449 accuracy: 0.150000\n",
      "[516]: loss: 0.111240 accuracy: 0.060000\n",
      "[517]: loss: 0.109731 accuracy: 0.120000\n",
      "[518]: loss: 0.111908 accuracy: 0.080000\n",
      "[519]: loss: 0.111867 accuracy: 0.080000\n",
      "[520]: loss: 0.110243 accuracy: 0.110000\n",
      "[521]: loss: 0.109029 accuracy: 0.150000\n",
      "[522]: loss: 0.110729 accuracy: 0.110000\n",
      "[523]: loss: 0.110990 accuracy: 0.060000\n",
      "[524]: loss: 0.111082 accuracy: 0.060000\n",
      "[525]: loss: 0.110601 accuracy: 0.070000\n",
      "[526]: loss: 0.110904 accuracy: 0.040000\n",
      "[527]: loss: 0.109828 accuracy: 0.100000\n",
      "[528]: loss: 0.109944 accuracy: 0.100000\n",
      "[529]: loss: 0.110284 accuracy: 0.100000\n",
      "[530]: loss: 0.109878 accuracy: 0.090000\n",
      "[531]: loss: 0.110142 accuracy: 0.070000\n",
      "[532]: loss: 0.109591 accuracy: 0.110000\n",
      "[533]: loss: 0.111215 accuracy: 0.070000\n",
      "[534]: loss: 0.111626 accuracy: 0.050000\n",
      "[535]: loss: 0.109567 accuracy: 0.070000\n",
      "[536]: loss: 0.111365 accuracy: 0.080000\n",
      "[537]: loss: 0.110851 accuracy: 0.060000\n",
      "[538]: loss: 0.109510 accuracy: 0.160000\n",
      "[539]: loss: 0.110097 accuracy: 0.100000\n",
      "[540]: loss: 0.110323 accuracy: 0.070000\n",
      "[541]: loss: 0.110014 accuracy: 0.090000\n",
      "[542]: loss: 0.109067 accuracy: 0.110000\n",
      "[543]: loss: 0.110281 accuracy: 0.100000\n",
      "[544]: loss: 0.111503 accuracy: 0.060000\n",
      "[545]: loss: 0.110507 accuracy: 0.100000\n",
      "[546]: loss: 0.111225 accuracy: 0.070000\n",
      "[547]: loss: 0.111518 accuracy: 0.050000\n",
      "[548]: loss: 0.109811 accuracy: 0.120000\n",
      "[549]: loss: 0.108179 accuracy: 0.160000\n",
      "[550]: loss: 0.111605 accuracy: 0.080000\n",
      "[551]: loss: 0.109601 accuracy: 0.130000\n",
      "[552]: loss: 0.109163 accuracy: 0.160000\n",
      "[553]: loss: 0.108065 accuracy: 0.130000\n",
      "[554]: loss: 0.111218 accuracy: 0.090000\n",
      "[555]: loss: 0.110508 accuracy: 0.110000\n",
      "[556]: loss: 0.111589 accuracy: 0.090000\n",
      "[557]: loss: 0.109086 accuracy: 0.110000\n",
      "[558]: loss: 0.109599 accuracy: 0.140000\n",
      "[559]: loss: 0.109914 accuracy: 0.110000\n",
      "[560]: loss: 0.108213 accuracy: 0.150000\n",
      "[561]: loss: 0.110783 accuracy: 0.090000\n",
      "[562]: loss: 0.110551 accuracy: 0.090000\n",
      "[563]: loss: 0.111538 accuracy: 0.040000\n",
      "[564]: loss: 0.111363 accuracy: 0.040000\n",
      "[565]: loss: 0.112338 accuracy: 0.040000\n",
      "[566]: loss: 0.110695 accuracy: 0.110000\n",
      "[567]: loss: 0.110445 accuracy: 0.070000\n",
      "[568]: loss: 0.110183 accuracy: 0.050000\n",
      "[569]: loss: 0.110512 accuracy: 0.020000\n",
      "[570]: loss: 0.110411 accuracy: 0.090000\n",
      "[571]: loss: 0.112080 accuracy: 0.010000\n",
      "[572]: loss: 0.109927 accuracy: 0.040000\n",
      "[573]: loss: 0.109402 accuracy: 0.090000\n",
      "[574]: loss: 0.109997 accuracy: 0.060000\n",
      "[575]: loss: 0.109815 accuracy: 0.070000\n",
      "[576]: loss: 0.110660 accuracy: 0.070000\n",
      "[577]: loss: 0.109927 accuracy: 0.110000\n",
      "[578]: loss: 0.111004 accuracy: 0.050000\n",
      "[579]: loss: 0.109176 accuracy: 0.100000\n",
      "[580]: loss: 0.110075 accuracy: 0.070000\n",
      "[581]: loss: 0.109158 accuracy: 0.130000\n",
      "[582]: loss: 0.109988 accuracy: 0.060000\n",
      "[583]: loss: 0.108791 accuracy: 0.160000\n",
      "[584]: loss: 0.110298 accuracy: 0.070000\n",
      "[585]: loss: 0.109647 accuracy: 0.110000\n",
      "[586]: loss: 0.108927 accuracy: 0.100000\n",
      "[587]: loss: 0.111256 accuracy: 0.040000\n",
      "[588]: loss: 0.108659 accuracy: 0.100000\n",
      "[589]: loss: 0.108971 accuracy: 0.110000\n",
      "[590]: loss: 0.109013 accuracy: 0.080000\n",
      "[591]: loss: 0.107845 accuracy: 0.120000\n",
      "[592]: loss: 0.110740 accuracy: 0.070000\n",
      "[593]: loss: 0.109258 accuracy: 0.140000\n",
      "[594]: loss: 0.110948 accuracy: 0.070000\n",
      "[595]: loss: 0.109650 accuracy: 0.090000\n",
      "[596]: loss: 0.111446 accuracy: 0.070000\n",
      "[597]: loss: 0.108831 accuracy: 0.090000\n",
      "[598]: loss: 0.110410 accuracy: 0.090000\n",
      "[599]: loss: 0.107066 accuracy: 0.090000\n",
      "[600]: loss: 0.109021 accuracy: 0.100000\n",
      "[601]: loss: 0.110022 accuracy: 0.040000\n",
      "[602]: loss: 0.109445 accuracy: 0.040000\n",
      "[603]: loss: 0.110286 accuracy: 0.040000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[604]: loss: 0.109069 accuracy: 0.070000\n",
      "[605]: loss: 0.108236 accuracy: 0.110000\n",
      "[606]: loss: 0.109703 accuracy: 0.100000\n",
      "[607]: loss: 0.108409 accuracy: 0.100000\n",
      "[608]: loss: 0.107866 accuracy: 0.120000\n",
      "[609]: loss: 0.109083 accuracy: 0.090000\n",
      "[610]: loss: 0.108647 accuracy: 0.140000\n",
      "[611]: loss: 0.108778 accuracy: 0.120000\n",
      "[612]: loss: 0.108656 accuracy: 0.090000\n",
      "[613]: loss: 0.107867 accuracy: 0.110000\n",
      "[614]: loss: 0.108984 accuracy: 0.120000\n",
      "[615]: loss: 0.109221 accuracy: 0.130000\n",
      "[616]: loss: 0.109930 accuracy: 0.040000\n",
      "[617]: loss: 0.108673 accuracy: 0.120000\n",
      "[618]: loss: 0.109951 accuracy: 0.130000\n",
      "[619]: loss: 0.110841 accuracy: 0.130000\n",
      "[620]: loss: 0.106544 accuracy: 0.150000\n",
      "[621]: loss: 0.107263 accuracy: 0.150000\n",
      "[622]: loss: 0.109986 accuracy: 0.060000\n",
      "[623]: loss: 0.108892 accuracy: 0.110000\n",
      "[624]: loss: 0.107972 accuracy: 0.150000\n",
      "[625]: loss: 0.108872 accuracy: 0.090000\n",
      "[626]: loss: 0.107434 accuracy: 0.120000\n",
      "[627]: loss: 0.107398 accuracy: 0.120000\n",
      "[628]: loss: 0.108113 accuracy: 0.110000\n",
      "[629]: loss: 0.109047 accuracy: 0.070000\n",
      "[630]: loss: 0.108109 accuracy: 0.110000\n",
      "[631]: loss: 0.106526 accuracy: 0.120000\n",
      "[632]: loss: 0.107966 accuracy: 0.090000\n",
      "[633]: loss: 0.107392 accuracy: 0.140000\n",
      "[634]: loss: 0.109844 accuracy: 0.050000\n",
      "[635]: loss: 0.107765 accuracy: 0.110000\n",
      "[636]: loss: 0.105688 accuracy: 0.150000\n",
      "[637]: loss: 0.107863 accuracy: 0.120000\n",
      "[638]: loss: 0.105365 accuracy: 0.140000\n",
      "[639]: loss: 0.107613 accuracy: 0.130000\n",
      "[640]: loss: 0.107686 accuracy: 0.120000\n",
      "[641]: loss: 0.108952 accuracy: 0.170000\n",
      "[642]: loss: 0.108699 accuracy: 0.120000\n",
      "[643]: loss: 0.107832 accuracy: 0.110000\n",
      "[644]: loss: 0.108581 accuracy: 0.060000\n",
      "[645]: loss: 0.108305 accuracy: 0.060000\n",
      "[646]: loss: 0.108412 accuracy: 0.110000\n",
      "[647]: loss: 0.106741 accuracy: 0.180000\n",
      "[648]: loss: 0.107792 accuracy: 0.120000\n",
      "[649]: loss: 0.106919 accuracy: 0.090000\n",
      "[650]: loss: 0.108104 accuracy: 0.090000\n",
      "[651]: loss: 0.109153 accuracy: 0.100000\n",
      "[652]: loss: 0.106859 accuracy: 0.120000\n",
      "[653]: loss: 0.108254 accuracy: 0.120000\n",
      "[654]: loss: 0.107486 accuracy: 0.130000\n",
      "[655]: loss: 0.106553 accuracy: 0.170000\n",
      "[656]: loss: 0.108805 accuracy: 0.090000\n",
      "[657]: loss: 0.107653 accuracy: 0.080000\n",
      "[658]: loss: 0.106974 accuracy: 0.090000\n",
      "[659]: loss: 0.109949 accuracy: 0.110000\n",
      "[660]: loss: 0.108435 accuracy: 0.100000\n",
      "[661]: loss: 0.109314 accuracy: 0.120000\n",
      "[662]: loss: 0.107784 accuracy: 0.080000\n",
      "[663]: loss: 0.107573 accuracy: 0.110000\n",
      "[664]: loss: 0.108686 accuracy: 0.100000\n",
      "[665]: loss: 0.106132 accuracy: 0.140000\n",
      "[666]: loss: 0.107869 accuracy: 0.180000\n",
      "[667]: loss: 0.106343 accuracy: 0.110000\n",
      "[668]: loss: 0.107969 accuracy: 0.050000\n",
      "[669]: loss: 0.109604 accuracy: 0.080000\n",
      "[670]: loss: 0.106920 accuracy: 0.130000\n",
      "[671]: loss: 0.105435 accuracy: 0.150000\n",
      "[672]: loss: 0.105830 accuracy: 0.160000\n",
      "[673]: loss: 0.108588 accuracy: 0.090000\n",
      "[674]: loss: 0.108523 accuracy: 0.060000\n",
      "[675]: loss: 0.108425 accuracy: 0.100000\n",
      "[676]: loss: 0.107384 accuracy: 0.110000\n",
      "[677]: loss: 0.104241 accuracy: 0.190000\n",
      "[678]: loss: 0.107032 accuracy: 0.090000\n",
      "[679]: loss: 0.110665 accuracy: 0.060000\n",
      "[680]: loss: 0.106598 accuracy: 0.110000\n",
      "[681]: loss: 0.108227 accuracy: 0.130000\n",
      "[682]: loss: 0.103979 accuracy: 0.200000\n",
      "[683]: loss: 0.107460 accuracy: 0.140000\n",
      "[684]: loss: 0.107806 accuracy: 0.080000\n",
      "[685]: loss: 0.108840 accuracy: 0.050000\n",
      "[686]: loss: 0.107841 accuracy: 0.100000\n",
      "[687]: loss: 0.104691 accuracy: 0.190000\n",
      "[688]: loss: 0.106528 accuracy: 0.150000\n",
      "[689]: loss: 0.106605 accuracy: 0.130000\n",
      "[690]: loss: 0.106608 accuracy: 0.180000\n",
      "[691]: loss: 0.107483 accuracy: 0.090000\n",
      "[692]: loss: 0.107713 accuracy: 0.100000\n",
      "[693]: loss: 0.106445 accuracy: 0.150000\n",
      "[694]: loss: 0.104387 accuracy: 0.150000\n",
      "[695]: loss: 0.106590 accuracy: 0.160000\n",
      "[696]: loss: 0.108213 accuracy: 0.070000\n",
      "[697]: loss: 0.106698 accuracy: 0.090000\n",
      "[698]: loss: 0.108193 accuracy: 0.100000\n",
      "[699]: loss: 0.104068 accuracy: 0.160000\n",
      "[700]: loss: 0.104788 accuracy: 0.110000\n",
      "[701]: loss: 0.104822 accuracy: 0.170000\n",
      "[702]: loss: 0.106823 accuracy: 0.050000\n",
      "[703]: loss: 0.106945 accuracy: 0.140000\n",
      "[704]: loss: 0.107239 accuracy: 0.170000\n",
      "[705]: loss: 0.106616 accuracy: 0.130000\n",
      "[706]: loss: 0.107227 accuracy: 0.150000\n",
      "[707]: loss: 0.107667 accuracy: 0.100000\n",
      "[708]: loss: 0.105010 accuracy: 0.140000\n",
      "[709]: loss: 0.105704 accuracy: 0.090000\n",
      "[710]: loss: 0.108480 accuracy: 0.120000\n",
      "[711]: loss: 0.104824 accuracy: 0.140000\n",
      "[712]: loss: 0.106575 accuracy: 0.120000\n",
      "[713]: loss: 0.108220 accuracy: 0.080000\n",
      "[714]: loss: 0.106233 accuracy: 0.080000\n",
      "[715]: loss: 0.104795 accuracy: 0.180000\n",
      "[716]: loss: 0.105969 accuracy: 0.120000\n",
      "[717]: loss: 0.105170 accuracy: 0.080000\n",
      "[718]: loss: 0.104345 accuracy: 0.150000\n",
      "[719]: loss: 0.105237 accuracy: 0.160000\n",
      "[720]: loss: 0.106759 accuracy: 0.120000\n",
      "[721]: loss: 0.103761 accuracy: 0.110000\n",
      "[722]: loss: 0.102821 accuracy: 0.170000\n",
      "[723]: loss: 0.104889 accuracy: 0.150000\n",
      "[724]: loss: 0.103781 accuracy: 0.200000\n",
      "[725]: loss: 0.106360 accuracy: 0.110000\n",
      "[726]: loss: 0.105014 accuracy: 0.130000\n",
      "[727]: loss: 0.105059 accuracy: 0.180000\n",
      "[728]: loss: 0.104522 accuracy: 0.130000\n",
      "[729]: loss: 0.104955 accuracy: 0.100000\n",
      "[730]: loss: 0.105002 accuracy: 0.130000\n",
      "[731]: loss: 0.102840 accuracy: 0.130000\n",
      "[732]: loss: 0.102542 accuracy: 0.130000\n",
      "[733]: loss: 0.103534 accuracy: 0.170000\n",
      "[734]: loss: 0.108822 accuracy: 0.070000\n",
      "[735]: loss: 0.107396 accuracy: 0.190000\n",
      "[736]: loss: 0.103079 accuracy: 0.180000\n",
      "[737]: loss: 0.108478 accuracy: 0.080000\n",
      "[738]: loss: 0.103727 accuracy: 0.160000\n",
      "[739]: loss: 0.103077 accuracy: 0.150000\n",
      "[740]: loss: 0.103832 accuracy: 0.140000\n",
      "[741]: loss: 0.107960 accuracy: 0.040000\n",
      "[742]: loss: 0.107018 accuracy: 0.080000\n",
      "[743]: loss: 0.104082 accuracy: 0.170000\n",
      "[744]: loss: 0.105028 accuracy: 0.120000\n",
      "[745]: loss: 0.104685 accuracy: 0.130000\n",
      "[746]: loss: 0.104502 accuracy: 0.170000\n",
      "[747]: loss: 0.102266 accuracy: 0.110000\n",
      "[748]: loss: 0.105249 accuracy: 0.090000\n",
      "[749]: loss: 0.105142 accuracy: 0.160000\n",
      "[750]: loss: 0.103159 accuracy: 0.180000\n",
      "[751]: loss: 0.103626 accuracy: 0.140000\n",
      "[752]: loss: 0.108767 accuracy: 0.120000\n",
      "[753]: loss: 0.103634 accuracy: 0.150000\n",
      "[754]: loss: 0.100638 accuracy: 0.210000\n",
      "[755]: loss: 0.104981 accuracy: 0.130000\n",
      "[756]: loss: 0.103958 accuracy: 0.130000\n",
      "[757]: loss: 0.104369 accuracy: 0.140000\n",
      "[758]: loss: 0.104098 accuracy: 0.090000\n",
      "[759]: loss: 0.100700 accuracy: 0.210000\n",
      "[760]: loss: 0.097791 accuracy: 0.210000\n",
      "[761]: loss: 0.101469 accuracy: 0.150000\n",
      "[762]: loss: 0.102907 accuracy: 0.150000\n",
      "[763]: loss: 0.100486 accuracy: 0.240000\n",
      "[764]: loss: 0.103374 accuracy: 0.100000\n",
      "[765]: loss: 0.102590 accuracy: 0.170000\n",
      "[766]: loss: 0.104022 accuracy: 0.120000\n",
      "[767]: loss: 0.103244 accuracy: 0.180000\n",
      "[768]: loss: 0.101580 accuracy: 0.180000\n",
      "[769]: loss: 0.101455 accuracy: 0.160000\n",
      "[770]: loss: 0.101003 accuracy: 0.190000\n",
      "[771]: loss: 0.105538 accuracy: 0.140000\n",
      "[772]: loss: 0.100983 accuracy: 0.180000\n",
      "[773]: loss: 0.104520 accuracy: 0.120000\n",
      "[774]: loss: 0.100422 accuracy: 0.210000\n",
      "[775]: loss: 0.103011 accuracy: 0.130000\n",
      "[776]: loss: 0.103729 accuracy: 0.150000\n",
      "[777]: loss: 0.103291 accuracy: 0.180000\n",
      "[778]: loss: 0.101564 accuracy: 0.130000\n",
      "[779]: loss: 0.103802 accuracy: 0.100000\n",
      "[780]: loss: 0.103627 accuracy: 0.160000\n",
      "[781]: loss: 0.102686 accuracy: 0.090000\n",
      "[782]: loss: 0.102267 accuracy: 0.200000\n",
      "[783]: loss: 0.104382 accuracy: 0.150000\n",
      "[784]: loss: 0.102175 accuracy: 0.130000\n",
      "[785]: loss: 0.101958 accuracy: 0.190000\n",
      "[786]: loss: 0.098625 accuracy: 0.180000\n",
      "[787]: loss: 0.101769 accuracy: 0.120000\n",
      "[788]: loss: 0.099867 accuracy: 0.150000\n",
      "[789]: loss: 0.103927 accuracy: 0.140000\n",
      "[790]: loss: 0.099524 accuracy: 0.180000\n",
      "[791]: loss: 0.101965 accuracy: 0.160000\n",
      "[792]: loss: 0.101316 accuracy: 0.220000\n",
      "[793]: loss: 0.102682 accuracy: 0.190000\n",
      "[794]: loss: 0.100008 accuracy: 0.160000\n",
      "[795]: loss: 0.101394 accuracy: 0.120000\n",
      "[796]: loss: 0.095478 accuracy: 0.210000\n",
      "[797]: loss: 0.097915 accuracy: 0.180000\n",
      "[798]: loss: 0.099622 accuracy: 0.200000\n",
      "[799]: loss: 0.097476 accuracy: 0.190000\n",
      "[800]: loss: 0.095047 accuracy: 0.190000\n",
      "[801]: loss: 0.102146 accuracy: 0.220000\n",
      "[802]: loss: 0.100056 accuracy: 0.170000\n",
      "[803]: loss: 0.098650 accuracy: 0.150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804]: loss: 0.097333 accuracy: 0.210000\n",
      "[805]: loss: 0.098269 accuracy: 0.170000\n",
      "[806]: loss: 0.097667 accuracy: 0.190000\n",
      "[807]: loss: 0.098774 accuracy: 0.220000\n",
      "[808]: loss: 0.096685 accuracy: 0.220000\n",
      "[809]: loss: 0.095564 accuracy: 0.290000\n",
      "[810]: loss: 0.096461 accuracy: 0.190000\n",
      "[811]: loss: 0.097650 accuracy: 0.200000\n",
      "[812]: loss: 0.098522 accuracy: 0.190000\n",
      "[813]: loss: 0.097038 accuracy: 0.210000\n",
      "[814]: loss: 0.096719 accuracy: 0.220000\n",
      "[815]: loss: 0.093026 accuracy: 0.220000\n",
      "[816]: loss: 0.095953 accuracy: 0.230000\n",
      "[817]: loss: 0.099297 accuracy: 0.200000\n",
      "[818]: loss: 0.096098 accuracy: 0.180000\n",
      "[819]: loss: 0.097728 accuracy: 0.230000\n",
      "[820]: loss: 0.097648 accuracy: 0.200000\n",
      "[821]: loss: 0.094433 accuracy: 0.240000\n",
      "[822]: loss: 0.090879 accuracy: 0.320000\n",
      "[823]: loss: 0.091934 accuracy: 0.300000\n",
      "[824]: loss: 0.098979 accuracy: 0.180000\n",
      "[825]: loss: 0.095249 accuracy: 0.280000\n",
      "[826]: loss: 0.094903 accuracy: 0.210000\n",
      "[827]: loss: 0.094056 accuracy: 0.250000\n",
      "[828]: loss: 0.092914 accuracy: 0.280000\n",
      "[829]: loss: 0.093738 accuracy: 0.200000\n",
      "[830]: loss: 0.092322 accuracy: 0.250000\n",
      "[831]: loss: 0.092408 accuracy: 0.270000\n",
      "[832]: loss: 0.091259 accuracy: 0.310000\n",
      "[833]: loss: 0.091938 accuracy: 0.320000\n",
      "[834]: loss: 0.092909 accuracy: 0.260000\n",
      "[835]: loss: 0.094409 accuracy: 0.170000\n",
      "[836]: loss: 0.091573 accuracy: 0.280000\n",
      "[837]: loss: 0.086955 accuracy: 0.260000\n",
      "[838]: loss: 0.093940 accuracy: 0.280000\n",
      "[839]: loss: 0.094870 accuracy: 0.230000\n",
      "[840]: loss: 0.091756 accuracy: 0.250000\n",
      "[841]: loss: 0.089698 accuracy: 0.290000\n",
      "[842]: loss: 0.084756 accuracy: 0.370000\n",
      "[843]: loss: 0.096510 accuracy: 0.240000\n",
      "[844]: loss: 0.089151 accuracy: 0.320000\n",
      "[845]: loss: 0.096522 accuracy: 0.160000\n",
      "[846]: loss: 0.087115 accuracy: 0.330000\n",
      "[847]: loss: 0.088351 accuracy: 0.240000\n",
      "[848]: loss: 0.097557 accuracy: 0.200000\n",
      "[849]: loss: 0.087051 accuracy: 0.300000\n",
      "[850]: loss: 0.089483 accuracy: 0.340000\n",
      "[851]: loss: 0.092565 accuracy: 0.320000\n",
      "[852]: loss: 0.086100 accuracy: 0.370000\n",
      "[853]: loss: 0.088901 accuracy: 0.360000\n",
      "[854]: loss: 0.090291 accuracy: 0.330000\n",
      "[855]: loss: 0.092000 accuracy: 0.230000\n",
      "[856]: loss: 0.084592 accuracy: 0.340000\n",
      "[857]: loss: 0.086195 accuracy: 0.410000\n",
      "[858]: loss: 0.088053 accuracy: 0.280000\n",
      "[859]: loss: 0.089885 accuracy: 0.310000\n",
      "[860]: loss: 0.087259 accuracy: 0.310000\n",
      "[861]: loss: 0.089308 accuracy: 0.290000\n",
      "[862]: loss: 0.089700 accuracy: 0.270000\n",
      "[863]: loss: 0.084158 accuracy: 0.410000\n",
      "[864]: loss: 0.091109 accuracy: 0.300000\n",
      "[865]: loss: 0.085318 accuracy: 0.290000\n",
      "[866]: loss: 0.080001 accuracy: 0.390000\n",
      "[867]: loss: 0.086772 accuracy: 0.330000\n",
      "[868]: loss: 0.087187 accuracy: 0.330000\n",
      "[869]: loss: 0.078123 accuracy: 0.430000\n",
      "[870]: loss: 0.083295 accuracy: 0.370000\n",
      "[871]: loss: 0.084446 accuracy: 0.310000\n",
      "[872]: loss: 0.086961 accuracy: 0.310000\n",
      "[873]: loss: 0.089966 accuracy: 0.270000\n",
      "[874]: loss: 0.086357 accuracy: 0.320000\n",
      "[875]: loss: 0.080134 accuracy: 0.430000\n",
      "[876]: loss: 0.081478 accuracy: 0.330000\n",
      "[877]: loss: 0.080937 accuracy: 0.350000\n",
      "[878]: loss: 0.086165 accuracy: 0.420000\n",
      "[879]: loss: 0.081176 accuracy: 0.420000\n",
      "[880]: loss: 0.084153 accuracy: 0.370000\n",
      "[881]: loss: 0.082084 accuracy: 0.360000\n",
      "[882]: loss: 0.086796 accuracy: 0.370000\n",
      "[883]: loss: 0.082486 accuracy: 0.370000\n",
      "[884]: loss: 0.078809 accuracy: 0.450000\n",
      "[885]: loss: 0.075961 accuracy: 0.480000\n",
      "[886]: loss: 0.078258 accuracy: 0.360000\n",
      "[887]: loss: 0.076554 accuracy: 0.470000\n",
      "[888]: loss: 0.080928 accuracy: 0.390000\n",
      "[889]: loss: 0.086309 accuracy: 0.340000\n",
      "[890]: loss: 0.079608 accuracy: 0.450000\n",
      "[891]: loss: 0.078558 accuracy: 0.420000\n",
      "[892]: loss: 0.075569 accuracy: 0.400000\n",
      "[893]: loss: 0.077805 accuracy: 0.400000\n",
      "[894]: loss: 0.083604 accuracy: 0.400000\n",
      "[895]: loss: 0.082146 accuracy: 0.370000\n",
      "[896]: loss: 0.081104 accuracy: 0.420000\n",
      "[897]: loss: 0.076879 accuracy: 0.350000\n",
      "[898]: loss: 0.074386 accuracy: 0.480000\n",
      "[899]: loss: 0.070939 accuracy: 0.520000\n",
      "[900]: loss: 0.079993 accuracy: 0.420000\n",
      "[901]: loss: 0.076772 accuracy: 0.410000\n",
      "[902]: loss: 0.071883 accuracy: 0.510000\n",
      "[903]: loss: 0.071673 accuracy: 0.480000\n",
      "[904]: loss: 0.078265 accuracy: 0.420000\n",
      "[905]: loss: 0.083565 accuracy: 0.340000\n",
      "[906]: loss: 0.075102 accuracy: 0.430000\n",
      "[907]: loss: 0.074990 accuracy: 0.420000\n",
      "[908]: loss: 0.079290 accuracy: 0.390000\n",
      "[909]: loss: 0.079940 accuracy: 0.380000\n",
      "[910]: loss: 0.076403 accuracy: 0.480000\n",
      "[911]: loss: 0.076129 accuracy: 0.440000\n",
      "[912]: loss: 0.078023 accuracy: 0.460000\n",
      "[913]: loss: 0.072985 accuracy: 0.430000\n",
      "[914]: loss: 0.080203 accuracy: 0.420000\n",
      "[915]: loss: 0.077378 accuracy: 0.350000\n",
      "[916]: loss: 0.071112 accuracy: 0.450000\n",
      "[917]: loss: 0.074970 accuracy: 0.460000\n",
      "[918]: loss: 0.076285 accuracy: 0.440000\n",
      "[919]: loss: 0.075246 accuracy: 0.470000\n",
      "[920]: loss: 0.077452 accuracy: 0.390000\n",
      "[921]: loss: 0.072586 accuracy: 0.460000\n",
      "[922]: loss: 0.073440 accuracy: 0.500000\n",
      "[923]: loss: 0.078920 accuracy: 0.450000\n",
      "[924]: loss: 0.078660 accuracy: 0.380000\n",
      "[925]: loss: 0.080128 accuracy: 0.410000\n",
      "[926]: loss: 0.077455 accuracy: 0.410000\n",
      "[927]: loss: 0.071292 accuracy: 0.450000\n",
      "[928]: loss: 0.071245 accuracy: 0.520000\n",
      "[929]: loss: 0.078088 accuracy: 0.430000\n",
      "[930]: loss: 0.068815 accuracy: 0.480000\n",
      "[931]: loss: 0.071763 accuracy: 0.570000\n",
      "[932]: loss: 0.066535 accuracy: 0.530000\n",
      "[933]: loss: 0.073847 accuracy: 0.430000\n",
      "[934]: loss: 0.067731 accuracy: 0.600000\n",
      "[935]: loss: 0.067068 accuracy: 0.520000\n",
      "[936]: loss: 0.065235 accuracy: 0.550000\n",
      "[937]: loss: 0.080185 accuracy: 0.380000\n",
      "[938]: loss: 0.071365 accuracy: 0.480000\n",
      "[939]: loss: 0.070549 accuracy: 0.490000\n",
      "[940]: loss: 0.074511 accuracy: 0.410000\n",
      "[941]: loss: 0.069699 accuracy: 0.460000\n",
      "[942]: loss: 0.070574 accuracy: 0.440000\n",
      "[943]: loss: 0.072913 accuracy: 0.430000\n",
      "[944]: loss: 0.069134 accuracy: 0.520000\n",
      "[945]: loss: 0.068131 accuracy: 0.510000\n",
      "[946]: loss: 0.071300 accuracy: 0.450000\n",
      "[947]: loss: 0.071820 accuracy: 0.450000\n",
      "[948]: loss: 0.068347 accuracy: 0.540000\n",
      "[949]: loss: 0.071552 accuracy: 0.470000\n",
      "[950]: loss: 0.070170 accuracy: 0.460000\n",
      "[951]: loss: 0.061905 accuracy: 0.580000\n",
      "[952]: loss: 0.066629 accuracy: 0.540000\n",
      "[953]: loss: 0.062123 accuracy: 0.610000\n",
      "[954]: loss: 0.065262 accuracy: 0.580000\n",
      "[955]: loss: 0.069296 accuracy: 0.500000\n",
      "[956]: loss: 0.059098 accuracy: 0.540000\n",
      "[957]: loss: 0.067352 accuracy: 0.500000\n",
      "[958]: loss: 0.059819 accuracy: 0.560000\n",
      "[959]: loss: 0.067600 accuracy: 0.560000\n",
      "[960]: loss: 0.065948 accuracy: 0.580000\n",
      "[961]: loss: 0.065444 accuracy: 0.560000\n",
      "[962]: loss: 0.066127 accuracy: 0.500000\n",
      "[963]: loss: 0.058604 accuracy: 0.600000\n",
      "[964]: loss: 0.064663 accuracy: 0.580000\n",
      "[965]: loss: 0.072181 accuracy: 0.500000\n",
      "[966]: loss: 0.065274 accuracy: 0.560000\n",
      "[967]: loss: 0.058519 accuracy: 0.620000\n",
      "[968]: loss: 0.065761 accuracy: 0.510000\n",
      "[969]: loss: 0.065593 accuracy: 0.550000\n",
      "[970]: loss: 0.072005 accuracy: 0.420000\n",
      "[971]: loss: 0.063113 accuracy: 0.560000\n",
      "[972]: loss: 0.065275 accuracy: 0.510000\n",
      "[973]: loss: 0.067133 accuracy: 0.520000\n",
      "[974]: loss: 0.062631 accuracy: 0.600000\n",
      "[975]: loss: 0.067666 accuracy: 0.530000\n",
      "[976]: loss: 0.059172 accuracy: 0.600000\n",
      "[977]: loss: 0.064598 accuracy: 0.560000\n",
      "[978]: loss: 0.065583 accuracy: 0.580000\n",
      "[979]: loss: 0.061193 accuracy: 0.530000\n",
      "[980]: loss: 0.066683 accuracy: 0.520000\n",
      "[981]: loss: 0.059573 accuracy: 0.600000\n",
      "[982]: loss: 0.056343 accuracy: 0.650000\n",
      "[983]: loss: 0.062079 accuracy: 0.610000\n",
      "[984]: loss: 0.059117 accuracy: 0.560000\n",
      "[985]: loss: 0.057150 accuracy: 0.670000\n",
      "[986]: loss: 0.065072 accuracy: 0.480000\n",
      "[987]: loss: 0.057809 accuracy: 0.620000\n",
      "[988]: loss: 0.057416 accuracy: 0.630000\n",
      "[989]: loss: 0.065298 accuracy: 0.580000\n",
      "[990]: loss: 0.063163 accuracy: 0.570000\n",
      "[991]: loss: 0.056849 accuracy: 0.580000\n",
      "[992]: loss: 0.060940 accuracy: 0.550000\n",
      "[993]: loss: 0.062307 accuracy: 0.520000\n",
      "[994]: loss: 0.053593 accuracy: 0.650000\n",
      "[995]: loss: 0.058489 accuracy: 0.580000\n",
      "[996]: loss: 0.054999 accuracy: 0.590000\n",
      "[997]: loss: 0.055314 accuracy: 0.600000\n",
      "[998]: loss: 0.065011 accuracy: 0.570000\n",
      "[999]: loss: 0.069474 accuracy: 0.470000\n",
      "[1000]: loss: 0.055354 accuracy: 0.640000\n",
      "[1001]: loss: 0.060579 accuracy: 0.600000\n",
      "[1002]: loss: 0.068214 accuracy: 0.520000\n",
      "[1003]: loss: 0.053078 accuracy: 0.630000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1004]: loss: 0.057164 accuracy: 0.600000\n",
      "[1005]: loss: 0.049275 accuracy: 0.660000\n",
      "[1006]: loss: 0.057484 accuracy: 0.670000\n",
      "[1007]: loss: 0.057822 accuracy: 0.530000\n",
      "[1008]: loss: 0.052506 accuracy: 0.680000\n",
      "[1009]: loss: 0.057041 accuracy: 0.600000\n",
      "[1010]: loss: 0.065098 accuracy: 0.540000\n",
      "[1011]: loss: 0.053251 accuracy: 0.710000\n",
      "[1012]: loss: 0.050156 accuracy: 0.670000\n",
      "[1013]: loss: 0.058859 accuracy: 0.620000\n",
      "[1014]: loss: 0.047212 accuracy: 0.710000\n",
      "[1015]: loss: 0.052303 accuracy: 0.600000\n",
      "[1016]: loss: 0.053171 accuracy: 0.660000\n",
      "[1017]: loss: 0.045163 accuracy: 0.760000\n",
      "[1018]: loss: 0.067573 accuracy: 0.550000\n",
      "[1019]: loss: 0.054581 accuracy: 0.600000\n",
      "[1020]: loss: 0.057108 accuracy: 0.570000\n",
      "[1021]: loss: 0.050290 accuracy: 0.720000\n",
      "[1022]: loss: 0.055880 accuracy: 0.660000\n",
      "[1023]: loss: 0.050239 accuracy: 0.640000\n",
      "[1024]: loss: 0.053979 accuracy: 0.710000\n",
      "[1025]: loss: 0.056616 accuracy: 0.630000\n",
      "[1026]: loss: 0.048418 accuracy: 0.680000\n",
      "[1027]: loss: 0.057996 accuracy: 0.580000\n",
      "[1028]: loss: 0.053313 accuracy: 0.600000\n",
      "[1029]: loss: 0.050103 accuracy: 0.660000\n",
      "[1030]: loss: 0.048075 accuracy: 0.690000\n",
      "[1031]: loss: 0.049417 accuracy: 0.730000\n",
      "[1032]: loss: 0.051802 accuracy: 0.690000\n",
      "[1033]: loss: 0.052400 accuracy: 0.650000\n",
      "[1034]: loss: 0.047715 accuracy: 0.650000\n",
      "[1035]: loss: 0.045655 accuracy: 0.750000\n",
      "[1036]: loss: 0.051556 accuracy: 0.670000\n",
      "[1037]: loss: 0.047226 accuracy: 0.710000\n",
      "[1038]: loss: 0.048218 accuracy: 0.720000\n",
      "[1039]: loss: 0.048379 accuracy: 0.660000\n",
      "[1040]: loss: 0.047602 accuracy: 0.700000\n",
      "[1041]: loss: 0.048111 accuracy: 0.710000\n",
      "[1042]: loss: 0.052968 accuracy: 0.660000\n",
      "[1043]: loss: 0.050137 accuracy: 0.680000\n",
      "[1044]: loss: 0.045897 accuracy: 0.710000\n",
      "[1045]: loss: 0.048108 accuracy: 0.680000\n",
      "[1046]: loss: 0.046143 accuracy: 0.770000\n",
      "[1047]: loss: 0.054143 accuracy: 0.640000\n",
      "[1048]: loss: 0.049413 accuracy: 0.690000\n",
      "[1049]: loss: 0.046352 accuracy: 0.680000\n",
      "[1050]: loss: 0.051194 accuracy: 0.630000\n",
      "[1051]: loss: 0.040334 accuracy: 0.750000\n",
      "[1052]: loss: 0.047015 accuracy: 0.710000\n",
      "[1053]: loss: 0.045079 accuracy: 0.690000\n",
      "[1054]: loss: 0.045016 accuracy: 0.720000\n",
      "[1055]: loss: 0.046444 accuracy: 0.700000\n",
      "[1056]: loss: 0.047177 accuracy: 0.760000\n",
      "[1057]: loss: 0.047518 accuracy: 0.650000\n",
      "[1058]: loss: 0.040747 accuracy: 0.790000\n",
      "[1059]: loss: 0.042182 accuracy: 0.770000\n",
      "[1060]: loss: 0.035349 accuracy: 0.800000\n",
      "[1061]: loss: 0.046445 accuracy: 0.660000\n",
      "[1062]: loss: 0.049822 accuracy: 0.670000\n",
      "[1063]: loss: 0.045859 accuracy: 0.640000\n",
      "[1064]: loss: 0.043774 accuracy: 0.680000\n",
      "[1065]: loss: 0.041171 accuracy: 0.750000\n",
      "[1066]: loss: 0.045210 accuracy: 0.710000\n",
      "[1067]: loss: 0.045731 accuracy: 0.750000\n",
      "[1068]: loss: 0.041488 accuracy: 0.770000\n",
      "[1069]: loss: 0.045770 accuracy: 0.730000\n",
      "[1070]: loss: 0.047401 accuracy: 0.650000\n",
      "[1071]: loss: 0.038662 accuracy: 0.740000\n",
      "[1072]: loss: 0.042962 accuracy: 0.720000\n",
      "[1073]: loss: 0.040633 accuracy: 0.740000\n",
      "[1074]: loss: 0.050114 accuracy: 0.630000\n",
      "[1075]: loss: 0.042251 accuracy: 0.750000\n",
      "[1076]: loss: 0.042218 accuracy: 0.710000\n",
      "[1077]: loss: 0.045295 accuracy: 0.710000\n",
      "[1078]: loss: 0.045214 accuracy: 0.700000\n",
      "[1079]: loss: 0.040315 accuracy: 0.770000\n",
      "[1080]: loss: 0.046031 accuracy: 0.710000\n",
      "[1081]: loss: 0.046342 accuracy: 0.710000\n",
      "[1082]: loss: 0.046559 accuracy: 0.700000\n",
      "[1083]: loss: 0.039352 accuracy: 0.770000\n",
      "[1084]: loss: 0.043699 accuracy: 0.720000\n",
      "[1085]: loss: 0.049411 accuracy: 0.660000\n",
      "[1086]: loss: 0.045420 accuracy: 0.710000\n",
      "[1087]: loss: 0.046240 accuracy: 0.690000\n",
      "[1088]: loss: 0.041810 accuracy: 0.720000\n",
      "[1089]: loss: 0.063199 accuracy: 0.550000\n",
      "[1090]: loss: 0.046710 accuracy: 0.690000\n",
      "[1091]: loss: 0.040868 accuracy: 0.780000\n",
      "[1092]: loss: 0.050206 accuracy: 0.630000\n",
      "[1093]: loss: 0.043586 accuracy: 0.740000\n",
      "[1094]: loss: 0.035890 accuracy: 0.740000\n",
      "[1095]: loss: 0.044213 accuracy: 0.710000\n",
      "[1096]: loss: 0.049985 accuracy: 0.640000\n",
      "[1097]: loss: 0.046184 accuracy: 0.730000\n",
      "[1098]: loss: 0.037354 accuracy: 0.760000\n",
      "[1099]: loss: 0.042979 accuracy: 0.680000\n",
      "[1100]: loss: 0.052264 accuracy: 0.680000\n",
      "[1101]: loss: 0.047918 accuracy: 0.630000\n",
      "[1102]: loss: 0.045161 accuracy: 0.690000\n",
      "[1103]: loss: 0.039644 accuracy: 0.730000\n",
      "[1104]: loss: 0.039213 accuracy: 0.760000\n",
      "[1105]: loss: 0.038169 accuracy: 0.710000\n",
      "[1106]: loss: 0.053455 accuracy: 0.630000\n",
      "[1107]: loss: 0.057845 accuracy: 0.630000\n",
      "[1108]: loss: 0.037502 accuracy: 0.760000\n",
      "[1109]: loss: 0.041577 accuracy: 0.740000\n",
      "[1110]: loss: 0.033703 accuracy: 0.810000\n",
      "[1111]: loss: 0.029628 accuracy: 0.840000\n",
      "[1112]: loss: 0.037713 accuracy: 0.750000\n",
      "[1113]: loss: 0.032462 accuracy: 0.840000\n",
      "[1114]: loss: 0.044257 accuracy: 0.740000\n",
      "[1115]: loss: 0.034238 accuracy: 0.780000\n",
      "[1116]: loss: 0.034398 accuracy: 0.810000\n",
      "[1117]: loss: 0.045910 accuracy: 0.730000\n",
      "[1118]: loss: 0.042646 accuracy: 0.750000\n",
      "[1119]: loss: 0.034178 accuracy: 0.800000\n",
      "[1120]: loss: 0.041661 accuracy: 0.740000\n",
      "[1121]: loss: 0.042486 accuracy: 0.740000\n",
      "[1122]: loss: 0.035782 accuracy: 0.800000\n",
      "[1123]: loss: 0.036311 accuracy: 0.800000\n",
      "[1124]: loss: 0.034276 accuracy: 0.800000\n",
      "[1125]: loss: 0.036196 accuracy: 0.790000\n",
      "[1126]: loss: 0.038481 accuracy: 0.740000\n",
      "[1127]: loss: 0.038831 accuracy: 0.780000\n",
      "[1128]: loss: 0.042146 accuracy: 0.730000\n",
      "[1129]: loss: 0.048135 accuracy: 0.730000\n",
      "[1130]: loss: 0.036092 accuracy: 0.790000\n",
      "[1131]: loss: 0.044994 accuracy: 0.700000\n",
      "[1132]: loss: 0.041377 accuracy: 0.750000\n",
      "[1133]: loss: 0.032807 accuracy: 0.830000\n",
      "[1134]: loss: 0.038483 accuracy: 0.780000\n",
      "[1135]: loss: 0.044899 accuracy: 0.710000\n",
      "[1136]: loss: 0.037918 accuracy: 0.760000\n",
      "[1137]: loss: 0.027511 accuracy: 0.850000\n",
      "[1138]: loss: 0.040917 accuracy: 0.760000\n",
      "[1139]: loss: 0.035424 accuracy: 0.760000\n",
      "[1140]: loss: 0.034569 accuracy: 0.840000\n",
      "[1141]: loss: 0.039283 accuracy: 0.740000\n",
      "[1142]: loss: 0.036880 accuracy: 0.800000\n",
      "[1143]: loss: 0.037920 accuracy: 0.760000\n",
      "[1144]: loss: 0.032176 accuracy: 0.840000\n",
      "[1145]: loss: 0.039943 accuracy: 0.760000\n",
      "[1146]: loss: 0.041641 accuracy: 0.780000\n",
      "[1147]: loss: 0.035021 accuracy: 0.800000\n",
      "[1148]: loss: 0.031924 accuracy: 0.810000\n",
      "[1149]: loss: 0.042263 accuracy: 0.740000\n",
      "[1150]: loss: 0.037849 accuracy: 0.760000\n",
      "[1151]: loss: 0.036811 accuracy: 0.790000\n",
      "[1152]: loss: 0.031054 accuracy: 0.810000\n",
      "[1153]: loss: 0.034724 accuracy: 0.790000\n",
      "[1154]: loss: 0.035897 accuracy: 0.790000\n",
      "[1155]: loss: 0.036285 accuracy: 0.740000\n",
      "[1156]: loss: 0.034880 accuracy: 0.800000\n",
      "[1157]: loss: 0.031085 accuracy: 0.830000\n",
      "[1158]: loss: 0.029422 accuracy: 0.850000\n",
      "[1159]: loss: 0.032923 accuracy: 0.800000\n",
      "[1160]: loss: 0.033296 accuracy: 0.800000\n",
      "[1161]: loss: 0.034731 accuracy: 0.780000\n",
      "[1162]: loss: 0.032100 accuracy: 0.820000\n",
      "[1163]: loss: 0.036900 accuracy: 0.790000\n",
      "[1164]: loss: 0.030165 accuracy: 0.770000\n",
      "[1165]: loss: 0.037127 accuracy: 0.770000\n",
      "[1166]: loss: 0.034911 accuracy: 0.820000\n",
      "[1167]: loss: 0.040179 accuracy: 0.720000\n",
      "[1168]: loss: 0.035906 accuracy: 0.760000\n",
      "[1169]: loss: 0.042988 accuracy: 0.720000\n",
      "[1170]: loss: 0.031775 accuracy: 0.810000\n",
      "[1171]: loss: 0.039582 accuracy: 0.740000\n",
      "[1172]: loss: 0.044825 accuracy: 0.690000\n",
      "[1173]: loss: 0.027325 accuracy: 0.870000\n",
      "[1174]: loss: 0.037898 accuracy: 0.740000\n",
      "[1175]: loss: 0.033784 accuracy: 0.800000\n",
      "[1176]: loss: 0.030660 accuracy: 0.800000\n",
      "[1177]: loss: 0.025466 accuracy: 0.860000\n",
      "[1178]: loss: 0.035792 accuracy: 0.730000\n",
      "[1179]: loss: 0.032004 accuracy: 0.840000\n",
      "[1180]: loss: 0.027632 accuracy: 0.850000\n",
      "[1181]: loss: 0.035889 accuracy: 0.790000\n",
      "[1182]: loss: 0.036459 accuracy: 0.780000\n",
      "[1183]: loss: 0.033397 accuracy: 0.800000\n",
      "[1184]: loss: 0.027069 accuracy: 0.840000\n",
      "[1185]: loss: 0.034986 accuracy: 0.810000\n",
      "[1186]: loss: 0.033996 accuracy: 0.760000\n",
      "[1187]: loss: 0.031280 accuracy: 0.860000\n",
      "[1188]: loss: 0.028676 accuracy: 0.870000\n",
      "[1189]: loss: 0.028586 accuracy: 0.840000\n",
      "[1190]: loss: 0.034183 accuracy: 0.760000\n",
      "[1191]: loss: 0.027387 accuracy: 0.820000\n",
      "[1192]: loss: 0.033177 accuracy: 0.820000\n",
      "[1193]: loss: 0.038276 accuracy: 0.740000\n",
      "[1194]: loss: 0.029063 accuracy: 0.840000\n",
      "[1195]: loss: 0.036234 accuracy: 0.760000\n",
      "[1196]: loss: 0.030846 accuracy: 0.810000\n",
      "[1197]: loss: 0.028471 accuracy: 0.830000\n",
      "[1198]: loss: 0.033551 accuracy: 0.780000\n",
      "[1199]: loss: 0.034278 accuracy: 0.830000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]: loss: 0.026219 accuracy: 0.870000\n",
      "[1201]: loss: 0.029493 accuracy: 0.810000\n",
      "[1202]: loss: 0.030152 accuracy: 0.820000\n",
      "[1203]: loss: 0.029657 accuracy: 0.870000\n",
      "[1204]: loss: 0.032813 accuracy: 0.800000\n",
      "[1205]: loss: 0.027446 accuracy: 0.850000\n",
      "[1206]: loss: 0.025658 accuracy: 0.880000\n",
      "[1207]: loss: 0.037200 accuracy: 0.780000\n",
      "[1208]: loss: 0.028868 accuracy: 0.810000\n",
      "[1209]: loss: 0.029734 accuracy: 0.830000\n",
      "[1210]: loss: 0.035640 accuracy: 0.790000\n",
      "[1211]: loss: 0.030272 accuracy: 0.820000\n",
      "[1212]: loss: 0.028909 accuracy: 0.790000\n",
      "[1213]: loss: 0.031505 accuracy: 0.820000\n",
      "[1214]: loss: 0.030227 accuracy: 0.820000\n",
      "[1215]: loss: 0.028781 accuracy: 0.820000\n",
      "[1216]: loss: 0.024097 accuracy: 0.870000\n",
      "[1217]: loss: 0.029750 accuracy: 0.820000\n",
      "[1218]: loss: 0.036982 accuracy: 0.760000\n",
      "[1219]: loss: 0.038621 accuracy: 0.780000\n",
      "[1220]: loss: 0.032814 accuracy: 0.820000\n",
      "[1221]: loss: 0.031511 accuracy: 0.780000\n",
      "[1222]: loss: 0.032526 accuracy: 0.820000\n",
      "[1223]: loss: 0.029931 accuracy: 0.830000\n",
      "[1224]: loss: 0.029968 accuracy: 0.810000\n",
      "[1225]: loss: 0.025104 accuracy: 0.860000\n",
      "[1226]: loss: 0.034255 accuracy: 0.760000\n",
      "[1227]: loss: 0.031950 accuracy: 0.800000\n",
      "[1228]: loss: 0.024364 accuracy: 0.920000\n",
      "[1229]: loss: 0.031951 accuracy: 0.790000\n",
      "[1230]: loss: 0.031122 accuracy: 0.800000\n",
      "[1231]: loss: 0.028512 accuracy: 0.830000\n",
      "[1232]: loss: 0.031052 accuracy: 0.770000\n",
      "[1233]: loss: 0.028026 accuracy: 0.840000\n",
      "[1234]: loss: 0.020229 accuracy: 0.900000\n",
      "[1235]: loss: 0.025320 accuracy: 0.850000\n",
      "[1236]: loss: 0.031357 accuracy: 0.840000\n",
      "[1237]: loss: 0.022033 accuracy: 0.870000\n",
      "[1238]: loss: 0.033301 accuracy: 0.760000\n",
      "[1239]: loss: 0.024462 accuracy: 0.840000\n",
      "[1240]: loss: 0.023859 accuracy: 0.900000\n",
      "[1241]: loss: 0.035268 accuracy: 0.790000\n",
      "[1242]: loss: 0.032745 accuracy: 0.750000\n",
      "[1243]: loss: 0.023171 accuracy: 0.860000\n",
      "[1244]: loss: 0.029259 accuracy: 0.830000\n",
      "[1245]: loss: 0.024795 accuracy: 0.900000\n",
      "[1246]: loss: 0.031235 accuracy: 0.760000\n",
      "[1247]: loss: 0.020992 accuracy: 0.910000\n",
      "[1248]: loss: 0.033033 accuracy: 0.810000\n",
      "[1249]: loss: 0.034414 accuracy: 0.760000\n",
      "[1250]: loss: 0.027627 accuracy: 0.890000\n",
      "[1251]: loss: 0.036088 accuracy: 0.800000\n",
      "[1252]: loss: 0.024696 accuracy: 0.860000\n",
      "[1253]: loss: 0.031958 accuracy: 0.820000\n",
      "[1254]: loss: 0.027118 accuracy: 0.830000\n",
      "[1255]: loss: 0.027284 accuracy: 0.830000\n",
      "[1256]: loss: 0.025048 accuracy: 0.870000\n",
      "[1257]: loss: 0.034628 accuracy: 0.780000\n",
      "[1258]: loss: 0.036694 accuracy: 0.760000\n",
      "[1259]: loss: 0.026852 accuracy: 0.850000\n",
      "[1260]: loss: 0.028757 accuracy: 0.820000\n",
      "[1261]: loss: 0.034183 accuracy: 0.780000\n",
      "[1262]: loss: 0.023183 accuracy: 0.880000\n",
      "[1263]: loss: 0.032791 accuracy: 0.810000\n",
      "[1264]: loss: 0.027728 accuracy: 0.830000\n",
      "[1265]: loss: 0.023806 accuracy: 0.860000\n",
      "[1266]: loss: 0.024854 accuracy: 0.830000\n",
      "[1267]: loss: 0.021705 accuracy: 0.890000\n",
      "[1268]: loss: 0.029218 accuracy: 0.850000\n",
      "[1269]: loss: 0.023926 accuracy: 0.870000\n",
      "[1270]: loss: 0.028677 accuracy: 0.850000\n",
      "[1271]: loss: 0.027329 accuracy: 0.850000\n",
      "[1272]: loss: 0.027851 accuracy: 0.810000\n",
      "[1273]: loss: 0.031242 accuracy: 0.840000\n",
      "[1274]: loss: 0.023987 accuracy: 0.850000\n",
      "[1275]: loss: 0.025825 accuracy: 0.840000\n",
      "[1276]: loss: 0.030925 accuracy: 0.820000\n",
      "[1277]: loss: 0.028897 accuracy: 0.880000\n",
      "[1278]: loss: 0.022886 accuracy: 0.890000\n",
      "[1279]: loss: 0.027707 accuracy: 0.840000\n",
      "[1280]: loss: 0.028453 accuracy: 0.840000\n",
      "[1281]: loss: 0.031583 accuracy: 0.820000\n",
      "[1282]: loss: 0.032784 accuracy: 0.760000\n",
      "[1283]: loss: 0.026498 accuracy: 0.890000\n",
      "[1284]: loss: 0.029052 accuracy: 0.870000\n",
      "[1285]: loss: 0.023536 accuracy: 0.890000\n",
      "[1286]: loss: 0.026717 accuracy: 0.820000\n",
      "[1287]: loss: 0.032305 accuracy: 0.810000\n",
      "[1288]: loss: 0.022612 accuracy: 0.890000\n",
      "[1289]: loss: 0.020519 accuracy: 0.880000\n",
      "[1290]: loss: 0.035477 accuracy: 0.760000\n",
      "[1291]: loss: 0.029728 accuracy: 0.830000\n",
      "[1292]: loss: 0.028182 accuracy: 0.840000\n",
      "[1293]: loss: 0.027562 accuracy: 0.810000\n",
      "[1294]: loss: 0.017203 accuracy: 0.940000\n",
      "[1295]: loss: 0.027274 accuracy: 0.860000\n",
      "[1296]: loss: 0.025507 accuracy: 0.860000\n",
      "[1297]: loss: 0.029804 accuracy: 0.810000\n",
      "[1298]: loss: 0.028483 accuracy: 0.820000\n",
      "[1299]: loss: 0.024444 accuracy: 0.880000\n",
      "[1300]: loss: 0.023275 accuracy: 0.860000\n",
      "[1301]: loss: 0.023726 accuracy: 0.850000\n",
      "[1302]: loss: 0.029028 accuracy: 0.840000\n",
      "[1303]: loss: 0.028881 accuracy: 0.810000\n",
      "[1304]: loss: 0.023865 accuracy: 0.850000\n",
      "[1305]: loss: 0.019429 accuracy: 0.880000\n",
      "[1306]: loss: 0.021528 accuracy: 0.850000\n",
      "[1307]: loss: 0.026027 accuracy: 0.810000\n",
      "[1308]: loss: 0.020608 accuracy: 0.840000\n",
      "[1309]: loss: 0.024393 accuracy: 0.850000\n",
      "[1310]: loss: 0.027093 accuracy: 0.800000\n",
      "[1311]: loss: 0.021114 accuracy: 0.880000\n",
      "[1312]: loss: 0.022390 accuracy: 0.850000\n",
      "[1313]: loss: 0.026714 accuracy: 0.860000\n",
      "[1314]: loss: 0.023099 accuracy: 0.850000\n",
      "[1315]: loss: 0.028174 accuracy: 0.850000\n",
      "[1316]: loss: 0.028042 accuracy: 0.850000\n",
      "[1317]: loss: 0.022984 accuracy: 0.900000\n",
      "[1318]: loss: 0.026289 accuracy: 0.840000\n",
      "[1319]: loss: 0.032269 accuracy: 0.790000\n",
      "[1320]: loss: 0.027005 accuracy: 0.820000\n",
      "[1321]: loss: 0.021887 accuracy: 0.910000\n",
      "[1322]: loss: 0.022170 accuracy: 0.880000\n",
      "[1323]: loss: 0.030744 accuracy: 0.840000\n",
      "[1324]: loss: 0.021950 accuracy: 0.820000\n",
      "[1325]: loss: 0.017263 accuracy: 0.900000\n",
      "[1326]: loss: 0.027943 accuracy: 0.820000\n",
      "[1327]: loss: 0.026356 accuracy: 0.830000\n",
      "[1328]: loss: 0.026671 accuracy: 0.850000\n",
      "[1329]: loss: 0.027815 accuracy: 0.830000\n",
      "[1330]: loss: 0.025271 accuracy: 0.840000\n",
      "[1331]: loss: 0.031076 accuracy: 0.830000\n",
      "[1332]: loss: 0.025490 accuracy: 0.820000\n",
      "[1333]: loss: 0.025416 accuracy: 0.850000\n",
      "[1334]: loss: 0.025163 accuracy: 0.860000\n",
      "[1335]: loss: 0.030899 accuracy: 0.830000\n",
      "[1336]: loss: 0.028333 accuracy: 0.810000\n",
      "[1337]: loss: 0.021752 accuracy: 0.860000\n",
      "[1338]: loss: 0.020339 accuracy: 0.870000\n",
      "[1339]: loss: 0.026383 accuracy: 0.820000\n",
      "[1340]: loss: 0.030676 accuracy: 0.810000\n",
      "[1341]: loss: 0.025890 accuracy: 0.810000\n",
      "[1342]: loss: 0.022857 accuracy: 0.880000\n",
      "[1343]: loss: 0.027934 accuracy: 0.760000\n",
      "[1344]: loss: 0.024977 accuracy: 0.860000\n",
      "[1345]: loss: 0.024329 accuracy: 0.860000\n",
      "[1346]: loss: 0.019896 accuracy: 0.920000\n",
      "[1347]: loss: 0.023940 accuracy: 0.890000\n",
      "[1348]: loss: 0.028525 accuracy: 0.870000\n",
      "[1349]: loss: 0.024402 accuracy: 0.850000\n",
      "[1350]: loss: 0.018125 accuracy: 0.910000\n",
      "[1351]: loss: 0.016680 accuracy: 0.930000\n",
      "[1352]: loss: 0.018806 accuracy: 0.920000\n",
      "[1353]: loss: 0.017015 accuracy: 0.920000\n",
      "[1354]: loss: 0.028617 accuracy: 0.800000\n",
      "[1355]: loss: 0.024885 accuracy: 0.870000\n",
      "[1356]: loss: 0.020334 accuracy: 0.900000\n",
      "[1357]: loss: 0.025839 accuracy: 0.860000\n",
      "[1358]: loss: 0.025138 accuracy: 0.820000\n",
      "[1359]: loss: 0.020332 accuracy: 0.880000\n",
      "[1360]: loss: 0.023382 accuracy: 0.830000\n",
      "[1361]: loss: 0.021718 accuracy: 0.870000\n",
      "[1362]: loss: 0.028599 accuracy: 0.840000\n",
      "[1363]: loss: 0.023435 accuracy: 0.880000\n",
      "[1364]: loss: 0.016604 accuracy: 0.910000\n",
      "[1365]: loss: 0.026722 accuracy: 0.820000\n",
      "[1366]: loss: 0.019645 accuracy: 0.850000\n",
      "[1367]: loss: 0.024319 accuracy: 0.840000\n",
      "[1368]: loss: 0.027981 accuracy: 0.830000\n",
      "[1369]: loss: 0.017879 accuracy: 0.880000\n",
      "[1370]: loss: 0.023906 accuracy: 0.830000\n",
      "[1371]: loss: 0.024182 accuracy: 0.870000\n",
      "[1372]: loss: 0.024784 accuracy: 0.830000\n",
      "[1373]: loss: 0.024017 accuracy: 0.840000\n",
      "[1374]: loss: 0.027025 accuracy: 0.820000\n",
      "[1375]: loss: 0.022345 accuracy: 0.900000\n",
      "[1376]: loss: 0.026642 accuracy: 0.840000\n",
      "[1377]: loss: 0.026974 accuracy: 0.830000\n",
      "[1378]: loss: 0.024227 accuracy: 0.840000\n",
      "[1379]: loss: 0.024562 accuracy: 0.850000\n",
      "[1380]: loss: 0.026121 accuracy: 0.820000\n",
      "[1381]: loss: 0.020353 accuracy: 0.910000\n",
      "[1382]: loss: 0.025547 accuracy: 0.850000\n",
      "[1383]: loss: 0.021149 accuracy: 0.870000\n",
      "[1384]: loss: 0.021790 accuracy: 0.840000\n",
      "[1385]: loss: 0.026498 accuracy: 0.840000\n",
      "[1386]: loss: 0.026906 accuracy: 0.840000\n",
      "[1387]: loss: 0.016395 accuracy: 0.900000\n",
      "[1388]: loss: 0.023987 accuracy: 0.840000\n",
      "[1389]: loss: 0.019100 accuracy: 0.920000\n",
      "[1390]: loss: 0.022993 accuracy: 0.890000\n",
      "[1391]: loss: 0.026549 accuracy: 0.880000\n",
      "[1392]: loss: 0.022171 accuracy: 0.850000\n",
      "[1393]: loss: 0.015325 accuracy: 0.940000\n",
      "[1394]: loss: 0.026639 accuracy: 0.850000\n",
      "[1395]: loss: 0.019099 accuracy: 0.910000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1396]: loss: 0.021729 accuracy: 0.880000\n",
      "[1397]: loss: 0.019600 accuracy: 0.890000\n",
      "[1398]: loss: 0.025306 accuracy: 0.900000\n",
      "[1399]: loss: 0.025076 accuracy: 0.860000\n",
      "[1400]: loss: 0.020393 accuracy: 0.880000\n",
      "[1401]: loss: 0.020970 accuracy: 0.860000\n",
      "[1402]: loss: 0.022369 accuracy: 0.870000\n",
      "[1403]: loss: 0.020156 accuracy: 0.890000\n",
      "[1404]: loss: 0.011423 accuracy: 0.950000\n",
      "[1405]: loss: 0.018583 accuracy: 0.890000\n",
      "[1406]: loss: 0.018463 accuracy: 0.920000\n",
      "[1407]: loss: 0.020063 accuracy: 0.870000\n",
      "[1408]: loss: 0.021632 accuracy: 0.870000\n",
      "[1409]: loss: 0.017604 accuracy: 0.920000\n",
      "[1410]: loss: 0.018273 accuracy: 0.900000\n",
      "[1411]: loss: 0.023645 accuracy: 0.840000\n",
      "[1412]: loss: 0.018932 accuracy: 0.890000\n",
      "[1413]: loss: 0.019311 accuracy: 0.910000\n",
      "[1414]: loss: 0.025921 accuracy: 0.880000\n",
      "[1415]: loss: 0.028893 accuracy: 0.830000\n",
      "[1416]: loss: 0.025975 accuracy: 0.820000\n",
      "[1417]: loss: 0.020342 accuracy: 0.860000\n",
      "[1418]: loss: 0.022547 accuracy: 0.890000\n",
      "[1419]: loss: 0.016858 accuracy: 0.930000\n",
      "[1420]: loss: 0.017335 accuracy: 0.920000\n",
      "[1421]: loss: 0.018177 accuracy: 0.920000\n",
      "[1422]: loss: 0.022599 accuracy: 0.870000\n",
      "[1423]: loss: 0.017777 accuracy: 0.920000\n",
      "[1424]: loss: 0.023992 accuracy: 0.870000\n",
      "[1425]: loss: 0.022563 accuracy: 0.890000\n",
      "[1426]: loss: 0.019969 accuracy: 0.860000\n",
      "[1427]: loss: 0.027278 accuracy: 0.820000\n",
      "[1428]: loss: 0.022785 accuracy: 0.860000\n",
      "[1429]: loss: 0.018375 accuracy: 0.920000\n",
      "[1430]: loss: 0.018293 accuracy: 0.920000\n",
      "[1431]: loss: 0.022181 accuracy: 0.860000\n",
      "[1432]: loss: 0.018279 accuracy: 0.920000\n",
      "[1433]: loss: 0.020879 accuracy: 0.870000\n",
      "[1434]: loss: 0.018473 accuracy: 0.880000\n",
      "[1435]: loss: 0.020303 accuracy: 0.870000\n",
      "[1436]: loss: 0.020650 accuracy: 0.870000\n",
      "[1437]: loss: 0.024870 accuracy: 0.870000\n",
      "[1438]: loss: 0.018172 accuracy: 0.910000\n",
      "[1439]: loss: 0.022487 accuracy: 0.860000\n",
      "[1440]: loss: 0.023759 accuracy: 0.840000\n",
      "[1441]: loss: 0.023488 accuracy: 0.860000\n",
      "[1442]: loss: 0.019638 accuracy: 0.880000\n",
      "[1443]: loss: 0.022807 accuracy: 0.860000\n",
      "[1444]: loss: 0.021567 accuracy: 0.920000\n",
      "[1445]: loss: 0.019551 accuracy: 0.880000\n",
      "[1446]: loss: 0.015454 accuracy: 0.910000\n",
      "[1447]: loss: 0.020428 accuracy: 0.890000\n",
      "[1448]: loss: 0.019475 accuracy: 0.860000\n",
      "[1449]: loss: 0.015333 accuracy: 0.920000\n",
      "[1450]: loss: 0.021507 accuracy: 0.840000\n",
      "[1451]: loss: 0.019648 accuracy: 0.870000\n",
      "[1452]: loss: 0.019241 accuracy: 0.890000\n",
      "[1453]: loss: 0.016914 accuracy: 0.870000\n",
      "[1454]: loss: 0.018442 accuracy: 0.910000\n",
      "[1455]: loss: 0.016210 accuracy: 0.930000\n",
      "[1456]: loss: 0.018821 accuracy: 0.890000\n",
      "[1457]: loss: 0.025475 accuracy: 0.830000\n",
      "[1458]: loss: 0.021571 accuracy: 0.900000\n",
      "[1459]: loss: 0.023511 accuracy: 0.850000\n",
      "[1460]: loss: 0.020105 accuracy: 0.890000\n",
      "[1461]: loss: 0.013815 accuracy: 0.930000\n",
      "[1462]: loss: 0.019153 accuracy: 0.900000\n",
      "[1463]: loss: 0.019123 accuracy: 0.900000\n",
      "[1464]: loss: 0.021392 accuracy: 0.910000\n",
      "[1465]: loss: 0.012939 accuracy: 0.950000\n",
      "[1466]: loss: 0.023534 accuracy: 0.840000\n",
      "[1467]: loss: 0.023694 accuracy: 0.880000\n",
      "[1468]: loss: 0.017248 accuracy: 0.900000\n",
      "[1469]: loss: 0.016133 accuracy: 0.900000\n",
      "[1470]: loss: 0.018163 accuracy: 0.890000\n",
      "[1471]: loss: 0.022194 accuracy: 0.870000\n",
      "[1472]: loss: 0.009786 accuracy: 0.950000\n",
      "[1473]: loss: 0.016541 accuracy: 0.920000\n",
      "[1474]: loss: 0.022213 accuracy: 0.850000\n",
      "[1475]: loss: 0.018566 accuracy: 0.910000\n",
      "[1476]: loss: 0.021006 accuracy: 0.860000\n",
      "[1477]: loss: 0.016265 accuracy: 0.910000\n",
      "[1478]: loss: 0.014065 accuracy: 0.920000\n",
      "[1479]: loss: 0.014696 accuracy: 0.930000\n",
      "[1480]: loss: 0.025562 accuracy: 0.890000\n",
      "[1481]: loss: 0.011544 accuracy: 0.970000\n",
      "[1482]: loss: 0.020047 accuracy: 0.860000\n",
      "[1483]: loss: 0.021268 accuracy: 0.830000\n",
      "[1484]: loss: 0.019950 accuracy: 0.870000\n",
      "[1485]: loss: 0.016543 accuracy: 0.930000\n",
      "[1486]: loss: 0.017108 accuracy: 0.880000\n",
      "[1487]: loss: 0.014955 accuracy: 0.950000\n",
      "[1488]: loss: 0.018788 accuracy: 0.890000\n",
      "[1489]: loss: 0.023238 accuracy: 0.860000\n",
      "[1490]: loss: 0.018310 accuracy: 0.910000\n",
      "[1491]: loss: 0.015174 accuracy: 0.920000\n",
      "[1492]: loss: 0.020662 accuracy: 0.900000\n",
      "[1493]: loss: 0.017646 accuracy: 0.890000\n",
      "[1494]: loss: 0.016750 accuracy: 0.910000\n",
      "[1495]: loss: 0.015042 accuracy: 0.900000\n",
      "[1496]: loss: 0.023245 accuracy: 0.840000\n",
      "[1497]: loss: 0.016498 accuracy: 0.890000\n",
      "[1498]: loss: 0.014764 accuracy: 0.920000\n",
      "[1499]: loss: 0.021467 accuracy: 0.880000\n",
      "[1500]: loss: 0.018452 accuracy: 0.910000\n",
      "[1501]: loss: 0.022822 accuracy: 0.840000\n",
      "[1502]: loss: 0.014480 accuracy: 0.920000\n",
      "[1503]: loss: 0.014666 accuracy: 0.920000\n",
      "[1504]: loss: 0.016173 accuracy: 0.940000\n",
      "[1505]: loss: 0.017621 accuracy: 0.910000\n",
      "[1506]: loss: 0.019557 accuracy: 0.900000\n",
      "[1507]: loss: 0.022552 accuracy: 0.830000\n",
      "[1508]: loss: 0.015721 accuracy: 0.930000\n",
      "[1509]: loss: 0.017056 accuracy: 0.910000\n",
      "[1510]: loss: 0.019395 accuracy: 0.900000\n",
      "[1511]: loss: 0.020644 accuracy: 0.850000\n",
      "[1512]: loss: 0.012859 accuracy: 0.960000\n",
      "[1513]: loss: 0.015723 accuracy: 0.900000\n",
      "[1514]: loss: 0.015098 accuracy: 0.940000\n",
      "[1515]: loss: 0.017588 accuracy: 0.920000\n",
      "[1516]: loss: 0.021749 accuracy: 0.910000\n",
      "[1517]: loss: 0.014394 accuracy: 0.930000\n",
      "[1518]: loss: 0.014286 accuracy: 0.930000\n",
      "[1519]: loss: 0.016820 accuracy: 0.910000\n",
      "[1520]: loss: 0.015096 accuracy: 0.900000\n",
      "[1521]: loss: 0.019927 accuracy: 0.890000\n",
      "[1522]: loss: 0.018661 accuracy: 0.910000\n",
      "[1523]: loss: 0.016984 accuracy: 0.910000\n",
      "[1524]: loss: 0.021380 accuracy: 0.900000\n",
      "[1525]: loss: 0.023045 accuracy: 0.880000\n",
      "[1526]: loss: 0.017920 accuracy: 0.910000\n",
      "[1527]: loss: 0.018125 accuracy: 0.890000\n",
      "[1528]: loss: 0.020835 accuracy: 0.890000\n",
      "[1529]: loss: 0.014179 accuracy: 0.930000\n",
      "[1530]: loss: 0.022975 accuracy: 0.830000\n",
      "[1531]: loss: 0.013133 accuracy: 0.940000\n",
      "[1532]: loss: 0.018055 accuracy: 0.910000\n",
      "[1533]: loss: 0.016971 accuracy: 0.900000\n",
      "[1534]: loss: 0.018880 accuracy: 0.880000\n",
      "[1535]: loss: 0.014899 accuracy: 0.930000\n",
      "[1536]: loss: 0.017061 accuracy: 0.920000\n",
      "[1537]: loss: 0.014132 accuracy: 0.910000\n",
      "[1538]: loss: 0.016209 accuracy: 0.910000\n",
      "[1539]: loss: 0.011004 accuracy: 0.940000\n",
      "[1540]: loss: 0.010594 accuracy: 0.950000\n",
      "[1541]: loss: 0.013891 accuracy: 0.930000\n",
      "[1542]: loss: 0.027342 accuracy: 0.840000\n",
      "[1543]: loss: 0.017656 accuracy: 0.900000\n",
      "[1544]: loss: 0.018364 accuracy: 0.890000\n",
      "[1545]: loss: 0.016791 accuracy: 0.910000\n",
      "[1546]: loss: 0.014131 accuracy: 0.930000\n",
      "[1547]: loss: 0.013327 accuracy: 0.930000\n",
      "[1548]: loss: 0.016170 accuracy: 0.940000\n",
      "[1549]: loss: 0.021105 accuracy: 0.870000\n",
      "[1550]: loss: 0.013284 accuracy: 0.930000\n",
      "[1551]: loss: 0.023758 accuracy: 0.860000\n",
      "[1552]: loss: 0.023357 accuracy: 0.900000\n",
      "[1553]: loss: 0.019994 accuracy: 0.890000\n",
      "[1554]: loss: 0.020785 accuracy: 0.910000\n",
      "[1555]: loss: 0.015257 accuracy: 0.910000\n",
      "[1556]: loss: 0.022022 accuracy: 0.860000\n",
      "[1557]: loss: 0.017829 accuracy: 0.920000\n",
      "[1558]: loss: 0.012560 accuracy: 0.920000\n",
      "[1559]: loss: 0.020389 accuracy: 0.880000\n",
      "[1560]: loss: 0.011920 accuracy: 0.940000\n",
      "[1561]: loss: 0.012247 accuracy: 0.950000\n",
      "[1562]: loss: 0.019358 accuracy: 0.920000\n",
      "[1563]: loss: 0.012382 accuracy: 0.940000\n",
      "[1564]: loss: 0.018485 accuracy: 0.900000\n",
      "[1565]: loss: 0.012352 accuracy: 0.950000\n",
      "[1566]: loss: 0.010768 accuracy: 0.970000\n",
      "[1567]: loss: 0.008299 accuracy: 0.970000\n",
      "[1568]: loss: 0.011542 accuracy: 0.930000\n",
      "[1569]: loss: 0.019651 accuracy: 0.910000\n",
      "[1570]: loss: 0.018730 accuracy: 0.920000\n",
      "[1571]: loss: 0.021211 accuracy: 0.870000\n",
      "[1572]: loss: 0.012170 accuracy: 0.930000\n",
      "[1573]: loss: 0.019355 accuracy: 0.860000\n",
      "[1574]: loss: 0.013818 accuracy: 0.910000\n",
      "[1575]: loss: 0.017319 accuracy: 0.920000\n",
      "[1576]: loss: 0.013900 accuracy: 0.920000\n",
      "[1577]: loss: 0.013996 accuracy: 0.920000\n",
      "[1578]: loss: 0.019129 accuracy: 0.890000\n",
      "[1579]: loss: 0.022632 accuracy: 0.860000\n",
      "[1580]: loss: 0.013136 accuracy: 0.940000\n",
      "[1581]: loss: 0.014452 accuracy: 0.900000\n",
      "[1582]: loss: 0.016475 accuracy: 0.880000\n",
      "[1583]: loss: 0.022531 accuracy: 0.860000\n",
      "[1584]: loss: 0.017179 accuracy: 0.920000\n",
      "[1585]: loss: 0.014390 accuracy: 0.950000\n",
      "[1586]: loss: 0.013914 accuracy: 0.940000\n",
      "[1587]: loss: 0.010567 accuracy: 0.950000\n",
      "[1588]: loss: 0.021944 accuracy: 0.870000\n",
      "[1589]: loss: 0.014194 accuracy: 0.920000\n",
      "[1590]: loss: 0.019533 accuracy: 0.890000\n",
      "[1591]: loss: 0.013617 accuracy: 0.920000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1592]: loss: 0.014394 accuracy: 0.920000\n",
      "[1593]: loss: 0.015783 accuracy: 0.900000\n",
      "[1594]: loss: 0.019256 accuracy: 0.880000\n",
      "[1595]: loss: 0.019485 accuracy: 0.910000\n",
      "[1596]: loss: 0.012945 accuracy: 0.930000\n",
      "[1597]: loss: 0.012161 accuracy: 0.920000\n",
      "[1598]: loss: 0.013171 accuracy: 0.930000\n",
      "[1599]: loss: 0.009646 accuracy: 0.970000\n",
      "[1600]: loss: 0.019051 accuracy: 0.920000\n",
      "[1601]: loss: 0.017908 accuracy: 0.910000\n",
      "[1602]: loss: 0.014535 accuracy: 0.920000\n",
      "[1603]: loss: 0.016677 accuracy: 0.920000\n",
      "[1604]: loss: 0.014323 accuracy: 0.910000\n",
      "[1605]: loss: 0.015607 accuracy: 0.930000\n",
      "[1606]: loss: 0.013290 accuracy: 0.930000\n",
      "[1607]: loss: 0.010956 accuracy: 0.950000\n",
      "[1608]: loss: 0.019960 accuracy: 0.900000\n",
      "[1609]: loss: 0.015862 accuracy: 0.910000\n",
      "[1610]: loss: 0.015098 accuracy: 0.890000\n",
      "[1611]: loss: 0.017714 accuracy: 0.910000\n",
      "[1612]: loss: 0.015375 accuracy: 0.900000\n",
      "[1613]: loss: 0.011284 accuracy: 0.940000\n",
      "[1614]: loss: 0.020568 accuracy: 0.880000\n",
      "[1615]: loss: 0.011185 accuracy: 0.950000\n",
      "[1616]: loss: 0.014372 accuracy: 0.930000\n",
      "[1617]: loss: 0.017025 accuracy: 0.900000\n",
      "[1618]: loss: 0.014699 accuracy: 0.920000\n",
      "[1619]: loss: 0.015058 accuracy: 0.920000\n",
      "[1620]: loss: 0.012472 accuracy: 0.950000\n",
      "[1621]: loss: 0.018292 accuracy: 0.890000\n",
      "[1622]: loss: 0.015309 accuracy: 0.930000\n",
      "[1623]: loss: 0.022161 accuracy: 0.870000\n",
      "[1624]: loss: 0.012104 accuracy: 0.940000\n",
      "[1625]: loss: 0.019446 accuracy: 0.880000\n",
      "[1626]: loss: 0.021123 accuracy: 0.900000\n",
      "[1627]: loss: 0.012193 accuracy: 0.940000\n",
      "[1628]: loss: 0.016392 accuracy: 0.930000\n",
      "[1629]: loss: 0.013606 accuracy: 0.920000\n",
      "[1630]: loss: 0.019429 accuracy: 0.870000\n",
      "[1631]: loss: 0.009434 accuracy: 0.960000\n",
      "[1632]: loss: 0.016730 accuracy: 0.900000\n",
      "[1633]: loss: 0.023121 accuracy: 0.860000\n",
      "[1634]: loss: 0.015696 accuracy: 0.900000\n",
      "[1635]: loss: 0.011215 accuracy: 0.950000\n",
      "[1636]: loss: 0.014427 accuracy: 0.940000\n",
      "[1637]: loss: 0.014366 accuracy: 0.920000\n",
      "[1638]: loss: 0.011249 accuracy: 0.960000\n",
      "[1639]: loss: 0.017713 accuracy: 0.910000\n",
      "[1640]: loss: 0.014555 accuracy: 0.930000\n",
      "[1641]: loss: 0.016598 accuracy: 0.900000\n",
      "[1642]: loss: 0.013230 accuracy: 0.910000\n",
      "[1643]: loss: 0.010665 accuracy: 0.950000\n",
      "[1644]: loss: 0.014603 accuracy: 0.910000\n",
      "[1645]: loss: 0.011982 accuracy: 0.940000\n",
      "[1646]: loss: 0.016946 accuracy: 0.920000\n",
      "[1647]: loss: 0.010991 accuracy: 0.960000\n",
      "[1648]: loss: 0.015347 accuracy: 0.940000\n",
      "[1649]: loss: 0.012462 accuracy: 0.960000\n",
      "[1650]: loss: 0.011100 accuracy: 0.950000\n",
      "[1651]: loss: 0.012071 accuracy: 0.930000\n",
      "[1652]: loss: 0.016817 accuracy: 0.890000\n",
      "[1653]: loss: 0.009751 accuracy: 0.940000\n",
      "[1654]: loss: 0.011816 accuracy: 0.940000\n",
      "[1655]: loss: 0.013274 accuracy: 0.930000\n",
      "[1656]: loss: 0.018170 accuracy: 0.870000\n",
      "[1657]: loss: 0.014673 accuracy: 0.950000\n",
      "[1658]: loss: 0.019038 accuracy: 0.870000\n",
      "[1659]: loss: 0.012257 accuracy: 0.950000\n",
      "[1660]: loss: 0.009655 accuracy: 0.980000\n",
      "[1661]: loss: 0.012618 accuracy: 0.940000\n",
      "[1662]: loss: 0.023321 accuracy: 0.870000\n",
      "[1663]: loss: 0.010903 accuracy: 0.960000\n",
      "[1664]: loss: 0.012865 accuracy: 0.960000\n",
      "[1665]: loss: 0.016310 accuracy: 0.890000\n",
      "[1666]: loss: 0.013170 accuracy: 0.960000\n",
      "[1667]: loss: 0.014857 accuracy: 0.930000\n",
      "[1668]: loss: 0.011303 accuracy: 0.920000\n",
      "[1669]: loss: 0.014276 accuracy: 0.940000\n",
      "[1670]: loss: 0.014003 accuracy: 0.930000\n",
      "[1671]: loss: 0.011525 accuracy: 0.960000\n",
      "[1672]: loss: 0.014422 accuracy: 0.920000\n",
      "[1673]: loss: 0.011225 accuracy: 0.950000\n",
      "[1674]: loss: 0.012570 accuracy: 0.910000\n",
      "[1675]: loss: 0.010419 accuracy: 0.960000\n",
      "[1676]: loss: 0.014259 accuracy: 0.930000\n",
      "[1677]: loss: 0.013380 accuracy: 0.920000\n",
      "[1678]: loss: 0.014514 accuracy: 0.940000\n",
      "[1679]: loss: 0.012030 accuracy: 0.960000\n",
      "[1680]: loss: 0.008101 accuracy: 0.950000\n",
      "[1681]: loss: 0.012602 accuracy: 0.940000\n",
      "[1682]: loss: 0.010958 accuracy: 0.930000\n",
      "[1683]: loss: 0.011767 accuracy: 0.940000\n",
      "[1684]: loss: 0.013634 accuracy: 0.930000\n",
      "[1685]: loss: 0.009928 accuracy: 0.940000\n",
      "[1686]: loss: 0.017629 accuracy: 0.910000\n",
      "[1687]: loss: 0.020799 accuracy: 0.880000\n",
      "[1688]: loss: 0.009481 accuracy: 0.950000\n",
      "[1689]: loss: 0.012303 accuracy: 0.920000\n",
      "[1690]: loss: 0.017894 accuracy: 0.920000\n",
      "[1691]: loss: 0.009351 accuracy: 0.930000\n",
      "[1692]: loss: 0.009145 accuracy: 0.950000\n",
      "[1693]: loss: 0.019864 accuracy: 0.930000\n",
      "[1694]: loss: 0.015319 accuracy: 0.890000\n",
      "[1695]: loss: 0.015570 accuracy: 0.910000\n",
      "[1696]: loss: 0.017878 accuracy: 0.920000\n",
      "[1697]: loss: 0.015370 accuracy: 0.900000\n",
      "[1698]: loss: 0.008323 accuracy: 0.980000\n",
      "[1699]: loss: 0.011754 accuracy: 0.940000\n",
      "[1700]: loss: 0.015027 accuracy: 0.920000\n",
      "[1701]: loss: 0.014304 accuracy: 0.930000\n",
      "[1702]: loss: 0.014351 accuracy: 0.920000\n",
      "[1703]: loss: 0.010532 accuracy: 0.970000\n",
      "[1704]: loss: 0.012092 accuracy: 0.930000\n",
      "[1705]: loss: 0.012342 accuracy: 0.940000\n",
      "[1706]: loss: 0.012769 accuracy: 0.930000\n",
      "[1707]: loss: 0.012412 accuracy: 0.940000\n",
      "[1708]: loss: 0.015959 accuracy: 0.910000\n",
      "[1709]: loss: 0.010208 accuracy: 0.970000\n",
      "[1710]: loss: 0.013661 accuracy: 0.950000\n",
      "[1711]: loss: 0.010065 accuracy: 0.950000\n",
      "[1712]: loss: 0.014663 accuracy: 0.910000\n",
      "[1713]: loss: 0.010700 accuracy: 0.970000\n",
      "[1714]: loss: 0.016163 accuracy: 0.910000\n",
      "[1715]: loss: 0.010502 accuracy: 0.950000\n",
      "[1716]: loss: 0.013704 accuracy: 0.950000\n",
      "[1717]: loss: 0.012569 accuracy: 0.930000\n",
      "[1718]: loss: 0.011533 accuracy: 0.950000\n",
      "[1719]: loss: 0.009114 accuracy: 0.970000\n",
      "[1720]: loss: 0.013458 accuracy: 0.950000\n",
      "[1721]: loss: 0.014524 accuracy: 0.920000\n",
      "[1722]: loss: 0.012091 accuracy: 0.940000\n",
      "[1723]: loss: 0.013643 accuracy: 0.950000\n",
      "[1724]: loss: 0.017155 accuracy: 0.900000\n",
      "[1725]: loss: 0.015998 accuracy: 0.920000\n",
      "[1726]: loss: 0.008165 accuracy: 0.980000\n",
      "[1727]: loss: 0.009769 accuracy: 0.960000\n",
      "[1728]: loss: 0.011768 accuracy: 0.920000\n",
      "[1729]: loss: 0.011987 accuracy: 0.930000\n",
      "[1730]: loss: 0.010724 accuracy: 0.940000\n",
      "[1731]: loss: 0.013020 accuracy: 0.940000\n",
      "[1732]: loss: 0.012724 accuracy: 0.940000\n",
      "[1733]: loss: 0.009704 accuracy: 0.950000\n",
      "[1734]: loss: 0.007109 accuracy: 0.980000\n",
      "[1735]: loss: 0.008926 accuracy: 0.960000\n",
      "[1736]: loss: 0.013283 accuracy: 0.940000\n",
      "[1737]: loss: 0.011548 accuracy: 0.960000\n",
      "[1738]: loss: 0.011337 accuracy: 0.950000\n",
      "[1739]: loss: 0.012358 accuracy: 0.920000\n",
      "[1740]: loss: 0.006567 accuracy: 0.980000\n",
      "[1741]: loss: 0.011365 accuracy: 0.950000\n",
      "[1742]: loss: 0.009393 accuracy: 0.960000\n",
      "[1743]: loss: 0.012589 accuracy: 0.910000\n",
      "[1744]: loss: 0.010261 accuracy: 0.950000\n",
      "[1745]: loss: 0.019813 accuracy: 0.850000\n",
      "[1746]: loss: 0.011627 accuracy: 0.960000\n",
      "[1747]: loss: 0.011944 accuracy: 0.940000\n",
      "[1748]: loss: 0.008523 accuracy: 0.970000\n",
      "[1749]: loss: 0.009422 accuracy: 0.990000\n",
      "[1750]: loss: 0.010836 accuracy: 0.940000\n",
      "[1751]: loss: 0.016732 accuracy: 0.920000\n",
      "[1752]: loss: 0.012880 accuracy: 0.930000\n",
      "[1753]: loss: 0.015328 accuracy: 0.890000\n",
      "[1754]: loss: 0.022031 accuracy: 0.870000\n",
      "[1755]: loss: 0.009653 accuracy: 0.940000\n",
      "[1756]: loss: 0.015783 accuracy: 0.920000\n",
      "[1757]: loss: 0.005329 accuracy: 0.980000\n",
      "[1758]: loss: 0.011684 accuracy: 0.920000\n",
      "[1759]: loss: 0.016559 accuracy: 0.910000\n",
      "[1760]: loss: 0.012739 accuracy: 0.900000\n",
      "[1761]: loss: 0.014816 accuracy: 0.930000\n",
      "[1762]: loss: 0.010431 accuracy: 0.960000\n",
      "[1763]: loss: 0.013082 accuracy: 0.940000\n",
      "[1764]: loss: 0.009273 accuracy: 0.950000\n",
      "[1765]: loss: 0.010759 accuracy: 0.940000\n",
      "[1766]: loss: 0.016397 accuracy: 0.910000\n",
      "[1767]: loss: 0.010416 accuracy: 0.900000\n",
      "[1768]: loss: 0.022143 accuracy: 0.910000\n",
      "[1769]: loss: 0.011640 accuracy: 0.920000\n",
      "[1770]: loss: 0.010940 accuracy: 0.960000\n",
      "[1771]: loss: 0.010993 accuracy: 0.950000\n",
      "[1772]: loss: 0.007267 accuracy: 0.980000\n",
      "[1773]: loss: 0.009511 accuracy: 0.960000\n",
      "[1774]: loss: 0.013462 accuracy: 0.930000\n",
      "[1775]: loss: 0.016694 accuracy: 0.900000\n",
      "[1776]: loss: 0.016251 accuracy: 0.910000\n",
      "[1777]: loss: 0.008901 accuracy: 0.940000\n",
      "[1778]: loss: 0.010460 accuracy: 0.940000\n",
      "[1779]: loss: 0.011863 accuracy: 0.930000\n",
      "[1780]: loss: 0.011136 accuracy: 0.950000\n",
      "[1781]: loss: 0.017896 accuracy: 0.890000\n",
      "[1782]: loss: 0.012621 accuracy: 0.930000\n",
      "[1783]: loss: 0.013512 accuracy: 0.920000\n",
      "[1784]: loss: 0.015005 accuracy: 0.900000\n",
      "[1785]: loss: 0.016374 accuracy: 0.920000\n",
      "[1786]: loss: 0.014515 accuracy: 0.890000\n",
      "[1787]: loss: 0.017992 accuracy: 0.870000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1788]: loss: 0.009802 accuracy: 0.950000\n",
      "[1789]: loss: 0.012423 accuracy: 0.930000\n",
      "[1790]: loss: 0.014915 accuracy: 0.900000\n",
      "[1791]: loss: 0.011288 accuracy: 0.940000\n",
      "[1792]: loss: 0.011937 accuracy: 0.950000\n",
      "[1793]: loss: 0.017658 accuracy: 0.890000\n",
      "[1794]: loss: 0.014416 accuracy: 0.900000\n",
      "[1795]: loss: 0.018442 accuracy: 0.920000\n",
      "[1796]: loss: 0.013183 accuracy: 0.910000\n",
      "[1797]: loss: 0.011514 accuracy: 0.940000\n",
      "[1798]: loss: 0.012515 accuracy: 0.930000\n",
      "[1799]: loss: 0.014097 accuracy: 0.920000\n",
      "[1800]: loss: 0.014378 accuracy: 0.910000\n",
      "[1801]: loss: 0.009344 accuracy: 0.940000\n",
      "[1802]: loss: 0.013389 accuracy: 0.920000\n",
      "[1803]: loss: 0.012695 accuracy: 0.940000\n",
      "[1804]: loss: 0.015417 accuracy: 0.920000\n",
      "[1805]: loss: 0.007352 accuracy: 0.990000\n",
      "[1806]: loss: 0.008978 accuracy: 0.940000\n",
      "[1807]: loss: 0.014480 accuracy: 0.920000\n",
      "[1808]: loss: 0.012664 accuracy: 0.960000\n",
      "[1809]: loss: 0.017434 accuracy: 0.890000\n",
      "[1810]: loss: 0.012640 accuracy: 0.910000\n",
      "[1811]: loss: 0.014576 accuracy: 0.940000\n",
      "[1812]: loss: 0.015376 accuracy: 0.890000\n",
      "[1813]: loss: 0.012601 accuracy: 0.910000\n",
      "[1814]: loss: 0.009996 accuracy: 0.980000\n",
      "[1815]: loss: 0.010901 accuracy: 0.930000\n",
      "[1816]: loss: 0.017182 accuracy: 0.930000\n",
      "[1817]: loss: 0.012850 accuracy: 0.930000\n",
      "[1818]: loss: 0.010701 accuracy: 0.920000\n",
      "[1819]: loss: 0.009633 accuracy: 0.950000\n",
      "[1820]: loss: 0.010088 accuracy: 0.960000\n",
      "[1821]: loss: 0.015239 accuracy: 0.910000\n",
      "[1822]: loss: 0.011958 accuracy: 0.920000\n",
      "[1823]: loss: 0.011226 accuracy: 0.950000\n",
      "[1824]: loss: 0.007773 accuracy: 0.970000\n",
      "[1825]: loss: 0.017790 accuracy: 0.920000\n",
      "[1826]: loss: 0.009832 accuracy: 0.960000\n",
      "[1827]: loss: 0.009687 accuracy: 0.940000\n",
      "[1828]: loss: 0.012852 accuracy: 0.960000\n",
      "[1829]: loss: 0.012100 accuracy: 0.930000\n",
      "[1830]: loss: 0.009219 accuracy: 0.940000\n",
      "[1831]: loss: 0.012782 accuracy: 0.940000\n",
      "[1832]: loss: 0.010850 accuracy: 0.940000\n",
      "[1833]: loss: 0.013315 accuracy: 0.900000\n",
      "[1834]: loss: 0.011646 accuracy: 0.940000\n",
      "[1835]: loss: 0.008471 accuracy: 0.960000\n",
      "[1836]: loss: 0.011704 accuracy: 0.950000\n",
      "[1837]: loss: 0.012728 accuracy: 0.920000\n",
      "[1838]: loss: 0.008108 accuracy: 0.960000\n",
      "[1839]: loss: 0.007988 accuracy: 0.960000\n",
      "[1840]: loss: 0.009621 accuracy: 0.970000\n",
      "[1841]: loss: 0.011674 accuracy: 0.940000\n",
      "[1842]: loss: 0.014336 accuracy: 0.930000\n",
      "[1843]: loss: 0.010818 accuracy: 0.930000\n",
      "[1844]: loss: 0.010004 accuracy: 0.960000\n",
      "[1845]: loss: 0.014088 accuracy: 0.890000\n",
      "[1846]: loss: 0.010447 accuracy: 0.950000\n",
      "[1847]: loss: 0.016615 accuracy: 0.910000\n",
      "[1848]: loss: 0.010695 accuracy: 0.940000\n",
      "[1849]: loss: 0.013340 accuracy: 0.930000\n",
      "[1850]: loss: 0.012006 accuracy: 0.940000\n",
      "[1851]: loss: 0.018112 accuracy: 0.890000\n",
      "[1852]: loss: 0.007903 accuracy: 0.960000\n",
      "[1853]: loss: 0.016674 accuracy: 0.910000\n",
      "[1854]: loss: 0.011201 accuracy: 0.950000\n",
      "[1855]: loss: 0.011235 accuracy: 0.940000\n",
      "[1856]: loss: 0.012850 accuracy: 0.960000\n",
      "[1857]: loss: 0.010682 accuracy: 0.980000\n",
      "[1858]: loss: 0.006407 accuracy: 0.980000\n",
      "[1859]: loss: 0.007131 accuracy: 0.980000\n",
      "[1860]: loss: 0.012084 accuracy: 0.950000\n",
      "[1861]: loss: 0.010533 accuracy: 0.950000\n",
      "[1862]: loss: 0.011489 accuracy: 0.940000\n",
      "[1863]: loss: 0.005805 accuracy: 0.980000\n",
      "[1864]: loss: 0.007843 accuracy: 0.990000\n",
      "[1865]: loss: 0.010981 accuracy: 0.940000\n",
      "[1866]: loss: 0.007500 accuracy: 0.960000\n",
      "[1867]: loss: 0.008835 accuracy: 0.980000\n",
      "[1868]: loss: 0.014636 accuracy: 0.930000\n",
      "[1869]: loss: 0.011346 accuracy: 0.940000\n",
      "[1870]: loss: 0.016016 accuracy: 0.940000\n",
      "[1871]: loss: 0.011655 accuracy: 0.950000\n",
      "[1872]: loss: 0.017293 accuracy: 0.890000\n",
      "[1873]: loss: 0.012806 accuracy: 0.930000\n",
      "[1874]: loss: 0.017133 accuracy: 0.910000\n",
      "[1875]: loss: 0.010208 accuracy: 0.940000\n",
      "[1876]: loss: 0.012459 accuracy: 0.920000\n",
      "[1877]: loss: 0.012259 accuracy: 0.950000\n",
      "[1878]: loss: 0.010327 accuracy: 0.940000\n",
      "[1879]: loss: 0.012777 accuracy: 0.930000\n",
      "[1880]: loss: 0.009482 accuracy: 0.950000\n",
      "[1881]: loss: 0.005670 accuracy: 0.980000\n",
      "[1882]: loss: 0.012116 accuracy: 0.930000\n",
      "[1883]: loss: 0.011965 accuracy: 0.930000\n",
      "[1884]: loss: 0.015760 accuracy: 0.920000\n",
      "[1885]: loss: 0.012922 accuracy: 0.950000\n",
      "[1886]: loss: 0.009081 accuracy: 0.930000\n",
      "[1887]: loss: 0.012636 accuracy: 0.910000\n",
      "[1888]: loss: 0.013535 accuracy: 0.930000\n",
      "[1889]: loss: 0.007489 accuracy: 0.970000\n",
      "[1890]: loss: 0.013148 accuracy: 0.930000\n",
      "[1891]: loss: 0.011454 accuracy: 0.940000\n",
      "[1892]: loss: 0.012748 accuracy: 0.920000\n",
      "[1893]: loss: 0.010340 accuracy: 0.920000\n",
      "[1894]: loss: 0.009597 accuracy: 0.960000\n",
      "[1895]: loss: 0.010327 accuracy: 0.950000\n",
      "[1896]: loss: 0.011074 accuracy: 0.950000\n",
      "[1897]: loss: 0.011051 accuracy: 0.940000\n",
      "[1898]: loss: 0.014303 accuracy: 0.900000\n",
      "[1899]: loss: 0.009109 accuracy: 0.940000\n",
      "[1900]: loss: 0.014565 accuracy: 0.910000\n",
      "[1901]: loss: 0.010369 accuracy: 0.930000\n",
      "[1902]: loss: 0.013388 accuracy: 0.930000\n",
      "[1903]: loss: 0.015140 accuracy: 0.910000\n",
      "[1904]: loss: 0.012195 accuracy: 0.920000\n",
      "[1905]: loss: 0.008527 accuracy: 0.980000\n",
      "[1906]: loss: 0.015363 accuracy: 0.900000\n",
      "[1907]: loss: 0.014004 accuracy: 0.940000\n",
      "[1908]: loss: 0.012653 accuracy: 0.940000\n",
      "[1909]: loss: 0.007098 accuracy: 0.970000\n",
      "[1910]: loss: 0.011862 accuracy: 0.920000\n",
      "[1911]: loss: 0.009858 accuracy: 0.960000\n",
      "[1912]: loss: 0.013353 accuracy: 0.920000\n",
      "[1913]: loss: 0.013794 accuracy: 0.910000\n",
      "[1914]: loss: 0.007509 accuracy: 0.960000\n",
      "[1915]: loss: 0.010839 accuracy: 0.930000\n",
      "[1916]: loss: 0.006958 accuracy: 0.980000\n",
      "[1917]: loss: 0.006678 accuracy: 0.990000\n",
      "[1918]: loss: 0.012943 accuracy: 0.920000\n",
      "[1919]: loss: 0.013707 accuracy: 0.940000\n",
      "[1920]: loss: 0.013123 accuracy: 0.930000\n",
      "[1921]: loss: 0.006545 accuracy: 0.990000\n",
      "[1922]: loss: 0.012667 accuracy: 0.900000\n",
      "[1923]: loss: 0.007779 accuracy: 0.970000\n",
      "[1924]: loss: 0.012283 accuracy: 0.930000\n",
      "[1925]: loss: 0.013191 accuracy: 0.910000\n",
      "[1926]: loss: 0.010688 accuracy: 0.960000\n",
      "[1927]: loss: 0.008156 accuracy: 0.970000\n",
      "[1928]: loss: 0.011120 accuracy: 0.930000\n",
      "[1929]: loss: 0.007347 accuracy: 0.960000\n",
      "[1930]: loss: 0.010222 accuracy: 0.950000\n",
      "[1931]: loss: 0.012749 accuracy: 0.910000\n",
      "[1932]: loss: 0.008887 accuracy: 0.960000\n",
      "[1933]: loss: 0.013418 accuracy: 0.930000\n",
      "[1934]: loss: 0.010473 accuracy: 0.950000\n",
      "[1935]: loss: 0.006657 accuracy: 0.960000\n",
      "[1936]: loss: 0.011257 accuracy: 0.940000\n",
      "[1937]: loss: 0.017281 accuracy: 0.920000\n",
      "[1938]: loss: 0.010345 accuracy: 0.960000\n",
      "[1939]: loss: 0.011506 accuracy: 0.950000\n",
      "[1940]: loss: 0.009354 accuracy: 0.970000\n",
      "[1941]: loss: 0.011275 accuracy: 0.960000\n",
      "[1942]: loss: 0.013914 accuracy: 0.900000\n",
      "[1943]: loss: 0.007690 accuracy: 0.970000\n",
      "[1944]: loss: 0.007464 accuracy: 0.980000\n",
      "[1945]: loss: 0.011085 accuracy: 0.920000\n",
      "[1946]: loss: 0.008258 accuracy: 0.960000\n",
      "[1947]: loss: 0.008864 accuracy: 0.980000\n",
      "[1948]: loss: 0.009788 accuracy: 0.930000\n",
      "[1949]: loss: 0.014827 accuracy: 0.910000\n",
      "[1950]: loss: 0.009095 accuracy: 0.980000\n",
      "[1951]: loss: 0.014192 accuracy: 0.920000\n",
      "[1952]: loss: 0.013795 accuracy: 0.940000\n",
      "[1953]: loss: 0.011863 accuracy: 0.950000\n",
      "[1954]: loss: 0.009163 accuracy: 0.970000\n",
      "[1955]: loss: 0.009017 accuracy: 0.960000\n",
      "[1956]: loss: 0.016520 accuracy: 0.890000\n",
      "[1957]: loss: 0.010440 accuracy: 0.950000\n",
      "[1958]: loss: 0.009566 accuracy: 0.940000\n",
      "[1959]: loss: 0.008160 accuracy: 0.960000\n",
      "[1960]: loss: 0.009570 accuracy: 0.960000\n",
      "[1961]: loss: 0.012484 accuracy: 0.920000\n",
      "[1962]: loss: 0.009521 accuracy: 0.920000\n",
      "[1963]: loss: 0.010827 accuracy: 0.940000\n",
      "[1964]: loss: 0.014126 accuracy: 0.910000\n",
      "[1965]: loss: 0.007302 accuracy: 0.980000\n",
      "[1966]: loss: 0.006484 accuracy: 0.980000\n",
      "[1967]: loss: 0.010872 accuracy: 0.920000\n",
      "[1968]: loss: 0.005510 accuracy: 0.990000\n",
      "[1969]: loss: 0.007968 accuracy: 0.970000\n",
      "[1970]: loss: 0.010606 accuracy: 0.940000\n",
      "[1971]: loss: 0.008929 accuracy: 0.940000\n",
      "[1972]: loss: 0.009398 accuracy: 0.950000\n",
      "[1973]: loss: 0.012189 accuracy: 0.910000\n",
      "[1974]: loss: 0.009475 accuracy: 0.930000\n",
      "[1975]: loss: 0.005444 accuracy: 0.980000\n",
      "[1976]: loss: 0.006304 accuracy: 0.960000\n",
      "[1977]: loss: 0.009668 accuracy: 0.960000\n",
      "[1978]: loss: 0.007352 accuracy: 0.960000\n",
      "[1979]: loss: 0.010857 accuracy: 0.920000\n",
      "[1980]: loss: 0.005778 accuracy: 1.000000\n",
      "[1981]: loss: 0.011973 accuracy: 0.950000\n",
      "[1982]: loss: 0.010225 accuracy: 0.930000\n",
      "[1983]: loss: 0.003333 accuracy: 0.990000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1984]: loss: 0.006962 accuracy: 0.980000\n",
      "[1985]: loss: 0.011002 accuracy: 0.950000\n",
      "[1986]: loss: 0.009866 accuracy: 0.950000\n",
      "[1987]: loss: 0.012382 accuracy: 0.940000\n",
      "[1988]: loss: 0.007872 accuracy: 0.940000\n",
      "[1989]: loss: 0.008187 accuracy: 0.950000\n",
      "[1990]: loss: 0.007482 accuracy: 0.980000\n",
      "[1991]: loss: 0.011095 accuracy: 0.920000\n",
      "[1992]: loss: 0.009634 accuracy: 0.950000\n",
      "[1993]: loss: 0.009444 accuracy: 0.950000\n",
      "[1994]: loss: 0.006957 accuracy: 0.990000\n",
      "[1995]: loss: 0.009218 accuracy: 0.960000\n",
      "[1996]: loss: 0.007512 accuracy: 0.960000\n",
      "[1997]: loss: 0.010286 accuracy: 0.960000\n",
      "[1998]: loss: 0.005979 accuracy: 0.980000\n",
      "[1999]: loss: 0.006130 accuracy: 0.970000\n",
      "[2000]: loss: 0.013642 accuracy: 0.950000\n",
      "[2001]: loss: 0.007415 accuracy: 0.960000\n",
      "[2002]: loss: 0.007483 accuracy: 0.980000\n",
      "[2003]: loss: 0.015714 accuracy: 0.910000\n",
      "[2004]: loss: 0.005829 accuracy: 0.970000\n",
      "[2005]: loss: 0.010592 accuracy: 0.930000\n",
      "[2006]: loss: 0.013969 accuracy: 0.930000\n",
      "[2007]: loss: 0.013815 accuracy: 0.930000\n",
      "[2008]: loss: 0.004802 accuracy: 0.970000\n",
      "[2009]: loss: 0.009729 accuracy: 0.940000\n",
      "[2010]: loss: 0.012301 accuracy: 0.940000\n",
      "[2011]: loss: 0.009306 accuracy: 0.950000\n",
      "[2012]: loss: 0.007262 accuracy: 0.950000\n",
      "[2013]: loss: 0.006834 accuracy: 0.960000\n",
      "[2014]: loss: 0.011084 accuracy: 0.940000\n",
      "[2015]: loss: 0.006857 accuracy: 0.980000\n",
      "[2016]: loss: 0.013751 accuracy: 0.920000\n",
      "[2017]: loss: 0.019120 accuracy: 0.920000\n",
      "[2018]: loss: 0.008099 accuracy: 0.980000\n",
      "[2019]: loss: 0.010435 accuracy: 0.940000\n",
      "[2020]: loss: 0.010020 accuracy: 0.930000\n",
      "[2021]: loss: 0.014006 accuracy: 0.920000\n",
      "[2022]: loss: 0.012874 accuracy: 0.940000\n",
      "[2023]: loss: 0.013152 accuracy: 0.920000\n",
      "[2024]: loss: 0.014837 accuracy: 0.920000\n",
      "[2025]: loss: 0.010066 accuracy: 0.950000\n",
      "[2026]: loss: 0.008961 accuracy: 0.950000\n",
      "[2027]: loss: 0.008181 accuracy: 0.960000\n",
      "[2028]: loss: 0.006894 accuracy: 0.980000\n",
      "[2029]: loss: 0.009035 accuracy: 0.970000\n",
      "[2030]: loss: 0.009762 accuracy: 0.950000\n",
      "[2031]: loss: 0.016570 accuracy: 0.900000\n",
      "[2032]: loss: 0.006352 accuracy: 0.970000\n",
      "[2033]: loss: 0.012418 accuracy: 0.910000\n",
      "[2034]: loss: 0.008416 accuracy: 0.970000\n",
      "[2035]: loss: 0.008716 accuracy: 0.960000\n",
      "[2036]: loss: 0.005367 accuracy: 0.960000\n",
      "[2037]: loss: 0.005862 accuracy: 0.980000\n",
      "[2038]: loss: 0.012613 accuracy: 0.940000\n",
      "[2039]: loss: 0.006265 accuracy: 0.990000\n",
      "[2040]: loss: 0.011128 accuracy: 0.930000\n",
      "[2041]: loss: 0.006694 accuracy: 0.960000\n",
      "[2042]: loss: 0.010459 accuracy: 0.940000\n",
      "[2043]: loss: 0.008148 accuracy: 0.960000\n",
      "[2044]: loss: 0.008933 accuracy: 0.940000\n",
      "[2045]: loss: 0.008866 accuracy: 0.930000\n",
      "[2046]: loss: 0.014911 accuracy: 0.930000\n",
      "[2047]: loss: 0.009974 accuracy: 0.940000\n",
      "[2048]: loss: 0.006227 accuracy: 0.990000\n",
      "[2049]: loss: 0.006888 accuracy: 0.990000\n",
      "[2050]: loss: 0.005771 accuracy: 0.980000\n",
      "[2051]: loss: 0.014329 accuracy: 0.930000\n",
      "[2052]: loss: 0.009315 accuracy: 0.980000\n",
      "[2053]: loss: 0.006591 accuracy: 0.980000\n",
      "[2054]: loss: 0.009771 accuracy: 0.930000\n",
      "[2055]: loss: 0.007051 accuracy: 0.990000\n",
      "[2056]: loss: 0.005974 accuracy: 0.980000\n",
      "[2057]: loss: 0.011006 accuracy: 0.950000\n",
      "[2058]: loss: 0.006499 accuracy: 0.970000\n",
      "[2059]: loss: 0.013368 accuracy: 0.930000\n",
      "[2060]: loss: 0.016636 accuracy: 0.900000\n",
      "[2061]: loss: 0.005537 accuracy: 0.980000\n",
      "[2062]: loss: 0.012562 accuracy: 0.900000\n",
      "[2063]: loss: 0.009163 accuracy: 0.940000\n",
      "[2064]: loss: 0.008838 accuracy: 0.990000\n",
      "[2065]: loss: 0.004779 accuracy: 0.980000\n",
      "[2066]: loss: 0.009764 accuracy: 0.960000\n",
      "[2067]: loss: 0.015618 accuracy: 0.920000\n",
      "[2068]: loss: 0.011730 accuracy: 0.970000\n",
      "[2069]: loss: 0.008131 accuracy: 0.960000\n",
      "[2070]: loss: 0.009219 accuracy: 0.960000\n",
      "[2071]: loss: 0.010128 accuracy: 0.910000\n",
      "[2072]: loss: 0.009978 accuracy: 0.950000\n",
      "[2073]: loss: 0.009738 accuracy: 0.950000\n",
      "[2074]: loss: 0.008701 accuracy: 0.950000\n",
      "[2075]: loss: 0.008415 accuracy: 0.960000\n",
      "[2076]: loss: 0.009065 accuracy: 0.960000\n",
      "[2077]: loss: 0.004972 accuracy: 0.980000\n",
      "[2078]: loss: 0.010708 accuracy: 0.950000\n",
      "[2079]: loss: 0.007809 accuracy: 0.940000\n",
      "[2080]: loss: 0.008193 accuracy: 0.960000\n",
      "[2081]: loss: 0.009757 accuracy: 0.940000\n",
      "[2082]: loss: 0.007731 accuracy: 0.970000\n",
      "[2083]: loss: 0.008668 accuracy: 0.950000\n",
      "[2084]: loss: 0.007989 accuracy: 0.960000\n",
      "[2085]: loss: 0.009577 accuracy: 0.940000\n",
      "[2086]: loss: 0.015154 accuracy: 0.890000\n",
      "[2087]: loss: 0.006593 accuracy: 0.960000\n",
      "[2088]: loss: 0.009761 accuracy: 0.950000\n",
      "[2089]: loss: 0.009769 accuracy: 0.950000\n",
      "[2090]: loss: 0.006622 accuracy: 0.970000\n",
      "[2091]: loss: 0.015726 accuracy: 0.900000\n",
      "[2092]: loss: 0.010115 accuracy: 0.950000\n",
      "[2093]: loss: 0.012073 accuracy: 0.950000\n",
      "[2094]: loss: 0.010110 accuracy: 0.960000\n",
      "[2095]: loss: 0.008715 accuracy: 0.950000\n",
      "[2096]: loss: 0.010828 accuracy: 0.920000\n",
      "[2097]: loss: 0.008517 accuracy: 0.970000\n",
      "[2098]: loss: 0.012403 accuracy: 0.930000\n",
      "[2099]: loss: 0.007998 accuracy: 0.940000\n",
      "[2100]: loss: 0.009561 accuracy: 0.940000\n",
      "[2101]: loss: 0.008736 accuracy: 0.970000\n",
      "[2102]: loss: 0.010012 accuracy: 0.950000\n",
      "[2103]: loss: 0.006484 accuracy: 0.960000\n",
      "[2104]: loss: 0.007946 accuracy: 0.960000\n",
      "[2105]: loss: 0.006651 accuracy: 0.960000\n",
      "[2106]: loss: 0.005757 accuracy: 0.960000\n",
      "[2107]: loss: 0.007634 accuracy: 0.970000\n",
      "[2108]: loss: 0.004905 accuracy: 0.990000\n",
      "[2109]: loss: 0.004086 accuracy: 0.990000\n",
      "[2110]: loss: 0.008415 accuracy: 0.970000\n",
      "[2111]: loss: 0.007431 accuracy: 0.980000\n",
      "[2112]: loss: 0.009351 accuracy: 0.930000\n",
      "[2113]: loss: 0.006951 accuracy: 0.960000\n",
      "[2114]: loss: 0.008500 accuracy: 0.960000\n",
      "[2115]: loss: 0.012885 accuracy: 0.930000\n",
      "[2116]: loss: 0.007686 accuracy: 0.940000\n",
      "[2117]: loss: 0.006401 accuracy: 0.990000\n",
      "[2118]: loss: 0.004256 accuracy: 0.990000\n",
      "[2119]: loss: 0.008384 accuracy: 0.970000\n",
      "[2120]: loss: 0.007044 accuracy: 0.970000\n",
      "[2121]: loss: 0.004484 accuracy: 0.980000\n",
      "[2122]: loss: 0.008908 accuracy: 0.940000\n",
      "[2123]: loss: 0.010718 accuracy: 0.940000\n",
      "[2124]: loss: 0.005885 accuracy: 0.970000\n",
      "[2125]: loss: 0.008223 accuracy: 0.970000\n",
      "[2126]: loss: 0.007925 accuracy: 0.970000\n",
      "[2127]: loss: 0.006434 accuracy: 0.970000\n",
      "[2128]: loss: 0.007061 accuracy: 0.980000\n",
      "[2129]: loss: 0.008198 accuracy: 0.960000\n",
      "[2130]: loss: 0.010672 accuracy: 0.940000\n",
      "[2131]: loss: 0.003671 accuracy: 1.000000\n",
      "[2132]: loss: 0.008100 accuracy: 0.960000\n",
      "[2133]: loss: 0.006179 accuracy: 0.980000\n",
      "[2134]: loss: 0.010368 accuracy: 0.940000\n",
      "[2135]: loss: 0.009390 accuracy: 0.930000\n",
      "[2136]: loss: 0.006618 accuracy: 0.960000\n",
      "[2137]: loss: 0.011641 accuracy: 0.940000\n",
      "[2138]: loss: 0.006578 accuracy: 0.960000\n",
      "[2139]: loss: 0.009969 accuracy: 0.950000\n",
      "[2140]: loss: 0.006648 accuracy: 0.970000\n",
      "[2141]: loss: 0.014564 accuracy: 0.920000\n",
      "[2142]: loss: 0.004314 accuracy: 0.980000\n",
      "[2143]: loss: 0.011829 accuracy: 0.940000\n",
      "[2144]: loss: 0.005393 accuracy: 0.990000\n",
      "[2145]: loss: 0.010852 accuracy: 0.940000\n",
      "[2146]: loss: 0.007342 accuracy: 0.970000\n",
      "[2147]: loss: 0.007688 accuracy: 0.950000\n",
      "[2148]: loss: 0.007129 accuracy: 0.970000\n",
      "[2149]: loss: 0.009792 accuracy: 0.950000\n",
      "[2150]: loss: 0.006306 accuracy: 0.970000\n",
      "[2151]: loss: 0.006713 accuracy: 0.940000\n",
      "[2152]: loss: 0.006825 accuracy: 0.940000\n",
      "[2153]: loss: 0.008524 accuracy: 0.950000\n",
      "[2154]: loss: 0.010581 accuracy: 0.940000\n",
      "[2155]: loss: 0.005365 accuracy: 0.960000\n",
      "[2156]: loss: 0.004283 accuracy: 0.990000\n",
      "[2157]: loss: 0.007810 accuracy: 0.950000\n",
      "[2158]: loss: 0.007391 accuracy: 0.970000\n",
      "[2159]: loss: 0.008170 accuracy: 0.970000\n",
      "[2160]: loss: 0.008856 accuracy: 0.960000\n",
      "[2161]: loss: 0.007134 accuracy: 0.980000\n",
      "[2162]: loss: 0.006901 accuracy: 0.960000\n",
      "[2163]: loss: 0.008915 accuracy: 0.950000\n",
      "[2164]: loss: 0.009834 accuracy: 0.970000\n",
      "[2165]: loss: 0.004196 accuracy: 0.990000\n",
      "[2166]: loss: 0.009351 accuracy: 0.920000\n",
      "[2167]: loss: 0.006548 accuracy: 0.970000\n",
      "[2168]: loss: 0.006043 accuracy: 0.960000\n",
      "[2169]: loss: 0.010162 accuracy: 0.940000\n",
      "[2170]: loss: 0.015049 accuracy: 0.900000\n",
      "[2171]: loss: 0.014351 accuracy: 0.930000\n",
      "[2172]: loss: 0.009375 accuracy: 0.950000\n",
      "[2173]: loss: 0.010053 accuracy: 0.930000\n",
      "[2174]: loss: 0.004807 accuracy: 0.990000\n",
      "[2175]: loss: 0.010237 accuracy: 0.930000\n",
      "[2176]: loss: 0.008911 accuracy: 0.960000\n",
      "[2177]: loss: 0.005450 accuracy: 0.970000\n",
      "[2178]: loss: 0.005856 accuracy: 0.970000\n",
      "[2179]: loss: 0.004177 accuracy: 0.990000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2180]: loss: 0.012710 accuracy: 0.920000\n",
      "[2181]: loss: 0.011241 accuracy: 0.920000\n",
      "[2182]: loss: 0.008900 accuracy: 0.940000\n",
      "[2183]: loss: 0.005833 accuracy: 0.990000\n",
      "[2184]: loss: 0.007758 accuracy: 0.960000\n",
      "[2185]: loss: 0.011001 accuracy: 0.950000\n",
      "[2186]: loss: 0.003641 accuracy: 1.000000\n",
      "[2187]: loss: 0.006247 accuracy: 0.970000\n",
      "[2188]: loss: 0.011437 accuracy: 0.950000\n",
      "[2189]: loss: 0.011806 accuracy: 0.920000\n",
      "[2190]: loss: 0.008026 accuracy: 0.960000\n",
      "[2191]: loss: 0.007550 accuracy: 0.960000\n",
      "[2192]: loss: 0.006696 accuracy: 0.980000\n",
      "[2193]: loss: 0.007659 accuracy: 0.960000\n",
      "[2194]: loss: 0.007864 accuracy: 0.950000\n",
      "[2195]: loss: 0.010664 accuracy: 0.950000\n",
      "[2196]: loss: 0.009065 accuracy: 0.940000\n",
      "[2197]: loss: 0.008182 accuracy: 0.940000\n",
      "[2198]: loss: 0.006688 accuracy: 0.980000\n",
      "[2199]: loss: 0.008006 accuracy: 0.960000\n",
      "[2200]: loss: 0.011304 accuracy: 0.940000\n",
      "[2201]: loss: 0.008041 accuracy: 0.960000\n",
      "[2202]: loss: 0.007004 accuracy: 0.980000\n",
      "[2203]: loss: 0.011281 accuracy: 0.930000\n",
      "[2204]: loss: 0.006830 accuracy: 0.960000\n",
      "[2205]: loss: 0.008419 accuracy: 0.970000\n",
      "[2206]: loss: 0.005748 accuracy: 0.980000\n",
      "[2207]: loss: 0.010333 accuracy: 0.960000\n",
      "[2208]: loss: 0.014606 accuracy: 0.930000\n",
      "[2209]: loss: 0.005854 accuracy: 0.990000\n",
      "[2210]: loss: 0.008440 accuracy: 0.970000\n",
      "[2211]: loss: 0.004603 accuracy: 0.990000\n",
      "[2212]: loss: 0.009641 accuracy: 0.960000\n",
      "[2213]: loss: 0.007493 accuracy: 0.960000\n",
      "[2214]: loss: 0.009001 accuracy: 0.950000\n",
      "[2215]: loss: 0.005933 accuracy: 0.970000\n",
      "[2216]: loss: 0.009764 accuracy: 0.940000\n",
      "[2217]: loss: 0.008872 accuracy: 0.950000\n",
      "[2218]: loss: 0.004772 accuracy: 0.970000\n",
      "[2219]: loss: 0.005163 accuracy: 0.990000\n",
      "[2220]: loss: 0.006034 accuracy: 0.970000\n",
      "[2221]: loss: 0.012277 accuracy: 0.950000\n",
      "[2222]: loss: 0.002921 accuracy: 1.000000\n",
      "[2223]: loss: 0.005662 accuracy: 0.980000\n",
      "[2224]: loss: 0.008782 accuracy: 0.950000\n",
      "[2225]: loss: 0.011555 accuracy: 0.910000\n",
      "[2226]: loss: 0.009426 accuracy: 0.970000\n",
      "[2227]: loss: 0.010648 accuracy: 0.980000\n",
      "[2228]: loss: 0.006396 accuracy: 0.970000\n",
      "[2229]: loss: 0.007403 accuracy: 0.960000\n",
      "[2230]: loss: 0.006351 accuracy: 0.980000\n",
      "[2231]: loss: 0.003892 accuracy: 0.990000\n",
      "[2232]: loss: 0.006698 accuracy: 0.970000\n",
      "[2233]: loss: 0.007542 accuracy: 0.970000\n",
      "[2234]: loss: 0.010802 accuracy: 0.950000\n",
      "[2235]: loss: 0.006136 accuracy: 0.970000\n",
      "[2236]: loss: 0.008604 accuracy: 0.960000\n",
      "[2237]: loss: 0.011003 accuracy: 0.920000\n",
      "[2238]: loss: 0.006424 accuracy: 0.980000\n",
      "[2239]: loss: 0.006925 accuracy: 0.970000\n",
      "[2240]: loss: 0.009218 accuracy: 0.980000\n",
      "[2241]: loss: 0.008032 accuracy: 0.970000\n",
      "[2242]: loss: 0.005688 accuracy: 0.980000\n",
      "[2243]: loss: 0.008653 accuracy: 0.960000\n",
      "[2244]: loss: 0.005050 accuracy: 0.990000\n",
      "[2245]: loss: 0.007608 accuracy: 0.970000\n",
      "[2246]: loss: 0.005614 accuracy: 0.980000\n",
      "[2247]: loss: 0.012990 accuracy: 0.940000\n",
      "[2248]: loss: 0.007960 accuracy: 0.970000\n",
      "[2249]: loss: 0.009584 accuracy: 0.960000\n",
      "[2250]: loss: 0.007929 accuracy: 0.970000\n",
      "[2251]: loss: 0.007135 accuracy: 0.970000\n",
      "[2252]: loss: 0.011940 accuracy: 0.960000\n",
      "[2253]: loss: 0.008192 accuracy: 0.930000\n",
      "[2254]: loss: 0.008600 accuracy: 0.950000\n",
      "[2255]: loss: 0.005352 accuracy: 0.990000\n",
      "[2256]: loss: 0.008009 accuracy: 0.970000\n",
      "[2257]: loss: 0.012887 accuracy: 0.940000\n",
      "[2258]: loss: 0.008993 accuracy: 0.950000\n",
      "[2259]: loss: 0.010109 accuracy: 0.940000\n",
      "[2260]: loss: 0.006512 accuracy: 0.970000\n",
      "[2261]: loss: 0.010523 accuracy: 0.920000\n",
      "[2262]: loss: 0.010531 accuracy: 0.940000\n",
      "[2263]: loss: 0.011469 accuracy: 0.930000\n",
      "[2264]: loss: 0.016351 accuracy: 0.930000\n",
      "[2265]: loss: 0.009276 accuracy: 0.930000\n",
      "[2266]: loss: 0.012225 accuracy: 0.970000\n",
      "[2267]: loss: 0.007707 accuracy: 0.970000\n",
      "[2268]: loss: 0.007915 accuracy: 0.960000\n",
      "[2269]: loss: 0.007624 accuracy: 0.980000\n",
      "[2270]: loss: 0.006444 accuracy: 0.970000\n",
      "[2271]: loss: 0.009527 accuracy: 0.930000\n",
      "[2272]: loss: 0.005430 accuracy: 0.960000\n",
      "[2273]: loss: 0.006904 accuracy: 0.950000\n",
      "[2274]: loss: 0.006217 accuracy: 0.990000\n",
      "[2275]: loss: 0.004190 accuracy: 0.990000\n",
      "[2276]: loss: 0.005595 accuracy: 0.980000\n",
      "[2277]: loss: 0.013346 accuracy: 0.940000\n",
      "[2278]: loss: 0.009910 accuracy: 0.960000\n",
      "[2279]: loss: 0.007809 accuracy: 0.960000\n",
      "[2280]: loss: 0.005084 accuracy: 0.980000\n",
      "[2281]: loss: 0.007994 accuracy: 0.950000\n",
      "[2282]: loss: 0.011794 accuracy: 0.960000\n",
      "[2283]: loss: 0.012562 accuracy: 0.930000\n",
      "[2284]: loss: 0.011255 accuracy: 0.950000\n",
      "[2285]: loss: 0.007444 accuracy: 0.970000\n",
      "[2286]: loss: 0.004322 accuracy: 0.990000\n",
      "[2287]: loss: 0.004608 accuracy: 0.980000\n",
      "[2288]: loss: 0.009148 accuracy: 0.940000\n",
      "[2289]: loss: 0.006860 accuracy: 0.950000\n",
      "[2290]: loss: 0.007101 accuracy: 0.960000\n",
      "[2291]: loss: 0.006498 accuracy: 0.970000\n",
      "[2292]: loss: 0.012199 accuracy: 0.930000\n",
      "[2293]: loss: 0.004044 accuracy: 0.990000\n",
      "[2294]: loss: 0.007842 accuracy: 0.970000\n",
      "[2295]: loss: 0.005412 accuracy: 0.980000\n",
      "[2296]: loss: 0.004504 accuracy: 0.990000\n",
      "[2297]: loss: 0.005903 accuracy: 0.960000\n",
      "[2298]: loss: 0.006379 accuracy: 0.970000\n",
      "[2299]: loss: 0.006277 accuracy: 0.940000\n",
      "[2300]: loss: 0.008905 accuracy: 0.960000\n",
      "[2301]: loss: 0.005976 accuracy: 0.980000\n",
      "[2302]: loss: 0.009316 accuracy: 0.950000\n",
      "[2303]: loss: 0.005417 accuracy: 0.970000\n",
      "[2304]: loss: 0.006814 accuracy: 0.970000\n",
      "[2305]: loss: 0.004253 accuracy: 0.980000\n",
      "[2306]: loss: 0.007215 accuracy: 0.970000\n",
      "[2307]: loss: 0.008790 accuracy: 0.950000\n",
      "[2308]: loss: 0.009789 accuracy: 0.960000\n",
      "[2309]: loss: 0.005597 accuracy: 0.980000\n",
      "[2310]: loss: 0.007780 accuracy: 0.950000\n",
      "[2311]: loss: 0.005112 accuracy: 0.990000\n",
      "[2312]: loss: 0.007954 accuracy: 0.960000\n",
      "[2313]: loss: 0.008750 accuracy: 0.940000\n",
      "[2314]: loss: 0.003770 accuracy: 0.990000\n",
      "[2315]: loss: 0.006821 accuracy: 0.980000\n",
      "[2316]: loss: 0.005503 accuracy: 0.970000\n",
      "[2317]: loss: 0.008124 accuracy: 0.950000\n",
      "[2318]: loss: 0.008531 accuracy: 0.950000\n",
      "[2319]: loss: 0.009983 accuracy: 0.950000\n",
      "[2320]: loss: 0.006529 accuracy: 0.960000\n",
      "[2321]: loss: 0.002298 accuracy: 1.000000\n",
      "[2322]: loss: 0.005344 accuracy: 0.980000\n",
      "[2323]: loss: 0.004425 accuracy: 0.980000\n",
      "[2324]: loss: 0.007346 accuracy: 0.960000\n",
      "[2325]: loss: 0.008738 accuracy: 0.970000\n",
      "[2326]: loss: 0.009598 accuracy: 0.940000\n",
      "[2327]: loss: 0.007785 accuracy: 0.960000\n",
      "[2328]: loss: 0.003888 accuracy: 0.990000\n",
      "[2329]: loss: 0.011640 accuracy: 0.940000\n",
      "[2330]: loss: 0.006170 accuracy: 0.960000\n",
      "[2331]: loss: 0.005426 accuracy: 0.960000\n",
      "[2332]: loss: 0.006914 accuracy: 0.950000\n",
      "[2333]: loss: 0.011382 accuracy: 0.930000\n",
      "[2334]: loss: 0.008783 accuracy: 0.970000\n",
      "[2335]: loss: 0.003951 accuracy: 0.980000\n",
      "[2336]: loss: 0.006956 accuracy: 0.980000\n",
      "[2337]: loss: 0.012824 accuracy: 0.930000\n",
      "[2338]: loss: 0.005258 accuracy: 0.980000\n",
      "[2339]: loss: 0.007355 accuracy: 0.970000\n",
      "[2340]: loss: 0.004825 accuracy: 0.980000\n",
      "[2341]: loss: 0.006691 accuracy: 0.970000\n",
      "[2342]: loss: 0.008356 accuracy: 0.950000\n",
      "[2343]: loss: 0.006148 accuracy: 0.970000\n",
      "[2344]: loss: 0.006661 accuracy: 0.970000\n",
      "[2345]: loss: 0.002904 accuracy: 0.980000\n",
      "[2346]: loss: 0.007557 accuracy: 0.960000\n",
      "[2347]: loss: 0.006663 accuracy: 0.960000\n",
      "[2348]: loss: 0.006418 accuracy: 0.960000\n",
      "[2349]: loss: 0.009178 accuracy: 0.960000\n",
      "[2350]: loss: 0.010305 accuracy: 0.960000\n",
      "[2351]: loss: 0.005593 accuracy: 0.970000\n",
      "[2352]: loss: 0.005705 accuracy: 0.980000\n",
      "[2353]: loss: 0.006043 accuracy: 0.960000\n",
      "[2354]: loss: 0.007503 accuracy: 0.970000\n",
      "[2355]: loss: 0.008081 accuracy: 0.960000\n",
      "[2356]: loss: 0.003674 accuracy: 0.990000\n",
      "[2357]: loss: 0.006978 accuracy: 0.970000\n",
      "[2358]: loss: 0.006540 accuracy: 0.960000\n",
      "[2359]: loss: 0.007885 accuracy: 0.960000\n",
      "[2360]: loss: 0.006789 accuracy: 0.950000\n",
      "[2361]: loss: 0.006066 accuracy: 0.970000\n",
      "[2362]: loss: 0.005927 accuracy: 0.970000\n",
      "[2363]: loss: 0.009244 accuracy: 0.940000\n",
      "[2364]: loss: 0.007190 accuracy: 0.970000\n",
      "[2365]: loss: 0.004350 accuracy: 0.990000\n",
      "[2366]: loss: 0.011851 accuracy: 0.920000\n",
      "[2367]: loss: 0.009531 accuracy: 0.940000\n",
      "[2368]: loss: 0.007445 accuracy: 0.960000\n",
      "[2369]: loss: 0.007385 accuracy: 0.950000\n",
      "[2370]: loss: 0.010865 accuracy: 0.940000\n",
      "[2371]: loss: 0.010050 accuracy: 0.920000\n",
      "[2372]: loss: 0.011823 accuracy: 0.940000\n",
      "[2373]: loss: 0.006331 accuracy: 0.980000\n",
      "[2374]: loss: 0.004156 accuracy: 1.000000\n",
      "[2375]: loss: 0.010688 accuracy: 0.920000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2376]: loss: 0.010480 accuracy: 0.950000\n",
      "[2377]: loss: 0.005518 accuracy: 0.990000\n",
      "[2378]: loss: 0.003666 accuracy: 0.990000\n",
      "[2379]: loss: 0.002250 accuracy: 0.990000\n",
      "[2380]: loss: 0.005255 accuracy: 0.970000\n",
      "[2381]: loss: 0.006346 accuracy: 0.960000\n",
      "[2382]: loss: 0.006034 accuracy: 0.960000\n",
      "[2383]: loss: 0.003360 accuracy: 0.990000\n",
      "[2384]: loss: 0.007391 accuracy: 0.960000\n",
      "[2385]: loss: 0.006084 accuracy: 0.950000\n",
      "[2386]: loss: 0.007163 accuracy: 0.970000\n",
      "[2387]: loss: 0.007431 accuracy: 0.970000\n",
      "[2388]: loss: 0.007919 accuracy: 0.970000\n",
      "[2389]: loss: 0.005068 accuracy: 0.980000\n",
      "[2390]: loss: 0.006780 accuracy: 0.970000\n",
      "[2391]: loss: 0.003495 accuracy: 1.000000\n",
      "[2392]: loss: 0.005364 accuracy: 0.970000\n",
      "[2393]: loss: 0.011830 accuracy: 0.950000\n",
      "[2394]: loss: 0.005331 accuracy: 0.990000\n",
      "[2395]: loss: 0.009296 accuracy: 0.960000\n",
      "[2396]: loss: 0.010392 accuracy: 0.940000\n",
      "[2397]: loss: 0.013843 accuracy: 0.930000\n",
      "[2398]: loss: 0.009024 accuracy: 0.940000\n",
      "[2399]: loss: 0.007346 accuracy: 0.970000\n",
      "[2400]: loss: 0.006912 accuracy: 0.960000\n",
      "[2401]: loss: 0.008777 accuracy: 0.950000\n",
      "[2402]: loss: 0.006912 accuracy: 0.960000\n",
      "[2403]: loss: 0.004773 accuracy: 0.980000\n",
      "[2404]: loss: 0.006020 accuracy: 0.980000\n",
      "[2405]: loss: 0.007533 accuracy: 0.990000\n",
      "[2406]: loss: 0.005619 accuracy: 0.970000\n",
      "[2407]: loss: 0.005463 accuracy: 0.990000\n",
      "[2408]: loss: 0.002815 accuracy: 0.980000\n",
      "[2409]: loss: 0.007816 accuracy: 0.970000\n",
      "[2410]: loss: 0.008477 accuracy: 0.950000\n",
      "[2411]: loss: 0.011064 accuracy: 0.940000\n",
      "[2412]: loss: 0.011291 accuracy: 0.940000\n",
      "[2413]: loss: 0.006051 accuracy: 0.960000\n",
      "[2414]: loss: 0.007021 accuracy: 0.970000\n",
      "[2415]: loss: 0.007480 accuracy: 0.950000\n",
      "[2416]: loss: 0.008257 accuracy: 0.960000\n",
      "[2417]: loss: 0.005000 accuracy: 0.980000\n",
      "[2418]: loss: 0.002730 accuracy: 0.980000\n",
      "[2419]: loss: 0.009559 accuracy: 0.920000\n",
      "[2420]: loss: 0.009116 accuracy: 0.950000\n",
      "[2421]: loss: 0.007390 accuracy: 0.970000\n",
      "[2422]: loss: 0.005649 accuracy: 0.980000\n",
      "[2423]: loss: 0.007299 accuracy: 0.970000\n",
      "[2424]: loss: 0.007820 accuracy: 0.970000\n",
      "[2425]: loss: 0.008399 accuracy: 0.960000\n",
      "[2426]: loss: 0.010504 accuracy: 0.930000\n",
      "[2427]: loss: 0.006594 accuracy: 0.970000\n",
      "[2428]: loss: 0.003697 accuracy: 0.990000\n",
      "[2429]: loss: 0.008546 accuracy: 0.970000\n",
      "[2430]: loss: 0.008455 accuracy: 0.960000\n",
      "[2431]: loss: 0.003343 accuracy: 0.980000\n",
      "[2432]: loss: 0.008476 accuracy: 0.960000\n",
      "[2433]: loss: 0.009958 accuracy: 0.930000\n",
      "[2434]: loss: 0.005121 accuracy: 0.970000\n",
      "[2435]: loss: 0.006312 accuracy: 0.980000\n",
      "[2436]: loss: 0.007231 accuracy: 0.950000\n",
      "[2437]: loss: 0.006717 accuracy: 0.970000\n",
      "[2438]: loss: 0.004208 accuracy: 0.980000\n",
      "[2439]: loss: 0.005207 accuracy: 0.970000\n",
      "[2440]: loss: 0.007715 accuracy: 0.960000\n",
      "[2441]: loss: 0.008501 accuracy: 0.970000\n",
      "[2442]: loss: 0.004165 accuracy: 1.000000\n",
      "[2443]: loss: 0.004438 accuracy: 0.980000\n",
      "[2444]: loss: 0.005521 accuracy: 0.980000\n",
      "[2445]: loss: 0.006069 accuracy: 0.960000\n",
      "[2446]: loss: 0.006632 accuracy: 0.960000\n",
      "[2447]: loss: 0.007770 accuracy: 0.950000\n",
      "[2448]: loss: 0.003030 accuracy: 0.970000\n",
      "[2449]: loss: 0.005069 accuracy: 0.980000\n",
      "[2450]: loss: 0.003239 accuracy: 0.990000\n",
      "[2451]: loss: 0.003895 accuracy: 0.980000\n",
      "[2452]: loss: 0.005774 accuracy: 0.970000\n",
      "[2453]: loss: 0.006422 accuracy: 0.950000\n",
      "[2454]: loss: 0.006864 accuracy: 0.980000\n",
      "[2455]: loss: 0.005701 accuracy: 0.970000\n",
      "[2456]: loss: 0.007605 accuracy: 0.950000\n",
      "[2457]: loss: 0.010067 accuracy: 0.950000\n",
      "[2458]: loss: 0.003509 accuracy: 0.990000\n",
      "[2459]: loss: 0.003569 accuracy: 0.990000\n",
      "[2460]: loss: 0.008335 accuracy: 0.970000\n",
      "[2461]: loss: 0.005218 accuracy: 0.980000\n",
      "[2462]: loss: 0.003891 accuracy: 0.970000\n",
      "[2463]: loss: 0.007175 accuracy: 0.960000\n",
      "[2464]: loss: 0.004397 accuracy: 0.970000\n",
      "[2465]: loss: 0.008124 accuracy: 0.960000\n",
      "[2466]: loss: 0.003290 accuracy: 0.990000\n",
      "[2467]: loss: 0.006046 accuracy: 0.970000\n",
      "[2468]: loss: 0.004039 accuracy: 0.970000\n",
      "[2469]: loss: 0.005344 accuracy: 0.980000\n",
      "[2470]: loss: 0.008370 accuracy: 0.960000\n",
      "[2471]: loss: 0.005371 accuracy: 0.950000\n",
      "[2472]: loss: 0.007075 accuracy: 0.960000\n",
      "[2473]: loss: 0.011008 accuracy: 0.920000\n",
      "[2474]: loss: 0.004035 accuracy: 0.990000\n",
      "[2475]: loss: 0.007316 accuracy: 0.980000\n",
      "[2476]: loss: 0.004439 accuracy: 0.990000\n",
      "[2477]: loss: 0.005348 accuracy: 0.980000\n",
      "[2478]: loss: 0.006986 accuracy: 0.970000\n",
      "[2479]: loss: 0.005748 accuracy: 0.980000\n",
      "[2480]: loss: 0.002545 accuracy: 0.990000\n",
      "[2481]: loss: 0.006460 accuracy: 0.960000\n",
      "[2482]: loss: 0.009772 accuracy: 0.940000\n",
      "[2483]: loss: 0.004275 accuracy: 0.980000\n",
      "[2484]: loss: 0.006757 accuracy: 0.960000\n",
      "[2485]: loss: 0.007326 accuracy: 0.960000\n",
      "[2486]: loss: 0.006136 accuracy: 0.980000\n",
      "[2487]: loss: 0.005404 accuracy: 0.960000\n",
      "[2488]: loss: 0.011434 accuracy: 0.940000\n",
      "[2489]: loss: 0.009038 accuracy: 0.950000\n",
      "[2490]: loss: 0.007163 accuracy: 0.970000\n",
      "[2491]: loss: 0.004745 accuracy: 0.980000\n",
      "[2492]: loss: 0.003797 accuracy: 0.980000\n",
      "[2493]: loss: 0.005732 accuracy: 0.990000\n",
      "[2494]: loss: 0.007909 accuracy: 0.950000\n",
      "[2495]: loss: 0.008479 accuracy: 0.990000\n",
      "[2496]: loss: 0.011077 accuracy: 0.940000\n",
      "[2497]: loss: 0.008402 accuracy: 0.960000\n",
      "[2498]: loss: 0.003847 accuracy: 0.990000\n",
      "[2499]: loss: 0.005991 accuracy: 0.960000\n",
      "[2500]: loss: 0.003627 accuracy: 0.980000\n",
      "[2501]: loss: 0.009063 accuracy: 0.940000\n",
      "[2502]: loss: 0.010014 accuracy: 0.930000\n",
      "[2503]: loss: 0.012598 accuracy: 0.950000\n",
      "[2504]: loss: 0.010276 accuracy: 0.940000\n",
      "[2505]: loss: 0.003621 accuracy: 0.990000\n",
      "[2506]: loss: 0.004578 accuracy: 0.990000\n",
      "[2507]: loss: 0.008244 accuracy: 0.950000\n",
      "[2508]: loss: 0.010025 accuracy: 0.920000\n",
      "[2509]: loss: 0.003924 accuracy: 0.970000\n",
      "[2510]: loss: 0.008148 accuracy: 0.930000\n",
      "[2511]: loss: 0.004434 accuracy: 0.990000\n",
      "[2512]: loss: 0.007566 accuracy: 0.980000\n",
      "[2513]: loss: 0.004577 accuracy: 0.980000\n",
      "[2514]: loss: 0.005527 accuracy: 0.970000\n",
      "[2515]: loss: 0.005336 accuracy: 0.980000\n",
      "[2516]: loss: 0.006022 accuracy: 0.970000\n",
      "[2517]: loss: 0.002686 accuracy: 1.000000\n",
      "[2518]: loss: 0.006502 accuracy: 0.980000\n",
      "[2519]: loss: 0.007871 accuracy: 0.960000\n",
      "[2520]: loss: 0.009572 accuracy: 0.960000\n",
      "[2521]: loss: 0.005447 accuracy: 0.980000\n",
      "[2522]: loss: 0.007979 accuracy: 0.950000\n",
      "[2523]: loss: 0.006229 accuracy: 0.980000\n",
      "[2524]: loss: 0.005554 accuracy: 0.990000\n",
      "[2525]: loss: 0.007295 accuracy: 0.950000\n",
      "[2526]: loss: 0.006824 accuracy: 0.970000\n",
      "[2527]: loss: 0.010546 accuracy: 0.970000\n",
      "[2528]: loss: 0.005535 accuracy: 0.970000\n",
      "[2529]: loss: 0.005624 accuracy: 0.970000\n",
      "[2530]: loss: 0.002952 accuracy: 0.990000\n",
      "[2531]: loss: 0.004142 accuracy: 0.970000\n",
      "[2532]: loss: 0.003046 accuracy: 1.000000\n",
      "[2533]: loss: 0.003727 accuracy: 1.000000\n",
      "[2534]: loss: 0.005713 accuracy: 0.990000\n",
      "[2535]: loss: 0.010169 accuracy: 0.940000\n",
      "[2536]: loss: 0.004610 accuracy: 0.980000\n",
      "[2537]: loss: 0.007114 accuracy: 0.950000\n",
      "[2538]: loss: 0.005155 accuracy: 0.970000\n",
      "[2539]: loss: 0.005784 accuracy: 0.970000\n",
      "[2540]: loss: 0.007194 accuracy: 0.970000\n",
      "[2541]: loss: 0.007422 accuracy: 0.960000\n",
      "[2542]: loss: 0.007300 accuracy: 0.970000\n",
      "[2543]: loss: 0.004661 accuracy: 0.970000\n",
      "[2544]: loss: 0.008996 accuracy: 0.960000\n",
      "[2545]: loss: 0.004402 accuracy: 0.980000\n",
      "[2546]: loss: 0.003198 accuracy: 1.000000\n",
      "[2547]: loss: 0.007771 accuracy: 0.960000\n",
      "[2548]: loss: 0.003675 accuracy: 0.980000\n",
      "[2549]: loss: 0.005259 accuracy: 0.980000\n",
      "[2550]: loss: 0.004646 accuracy: 0.990000\n",
      "[2551]: loss: 0.004594 accuracy: 0.980000\n",
      "[2552]: loss: 0.007093 accuracy: 0.960000\n",
      "[2553]: loss: 0.005793 accuracy: 0.970000\n",
      "[2554]: loss: 0.003604 accuracy: 1.000000\n",
      "[2555]: loss: 0.005999 accuracy: 0.990000\n",
      "[2556]: loss: 0.006644 accuracy: 0.980000\n",
      "[2557]: loss: 0.002309 accuracy: 1.000000\n",
      "[2558]: loss: 0.005192 accuracy: 0.960000\n",
      "[2559]: loss: 0.006740 accuracy: 0.970000\n",
      "[2560]: loss: 0.009135 accuracy: 0.960000\n",
      "[2561]: loss: 0.007062 accuracy: 0.970000\n",
      "[2562]: loss: 0.005069 accuracy: 0.980000\n",
      "[2563]: loss: 0.004722 accuracy: 0.970000\n",
      "[2564]: loss: 0.007966 accuracy: 0.950000\n",
      "[2565]: loss: 0.005474 accuracy: 0.970000\n",
      "[2566]: loss: 0.004682 accuracy: 0.980000\n",
      "[2567]: loss: 0.006284 accuracy: 0.970000\n",
      "[2568]: loss: 0.006034 accuracy: 0.970000\n",
      "[2569]: loss: 0.003945 accuracy: 0.970000\n",
      "[2570]: loss: 0.002774 accuracy: 0.990000\n",
      "[2571]: loss: 0.010324 accuracy: 0.980000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2572]: loss: 0.004253 accuracy: 0.990000\n",
      "[2573]: loss: 0.006697 accuracy: 0.960000\n",
      "[2574]: loss: 0.004438 accuracy: 0.980000\n",
      "[2575]: loss: 0.003686 accuracy: 0.990000\n",
      "[2576]: loss: 0.008463 accuracy: 0.950000\n",
      "[2577]: loss: 0.007612 accuracy: 0.950000\n",
      "[2578]: loss: 0.007261 accuracy: 0.970000\n",
      "[2579]: loss: 0.003310 accuracy: 0.990000\n",
      "[2580]: loss: 0.005548 accuracy: 0.950000\n",
      "[2581]: loss: 0.003886 accuracy: 0.980000\n",
      "[2582]: loss: 0.003096 accuracy: 0.990000\n",
      "[2583]: loss: 0.004831 accuracy: 0.990000\n",
      "[2584]: loss: 0.004335 accuracy: 0.990000\n",
      "[2585]: loss: 0.004870 accuracy: 0.980000\n",
      "[2586]: loss: 0.009008 accuracy: 0.980000\n",
      "[2587]: loss: 0.007374 accuracy: 0.970000\n",
      "[2588]: loss: 0.006977 accuracy: 0.940000\n",
      "[2589]: loss: 0.005011 accuracy: 0.970000\n",
      "[2590]: loss: 0.007805 accuracy: 0.970000\n",
      "[2591]: loss: 0.004423 accuracy: 1.000000\n",
      "[2592]: loss: 0.006014 accuracy: 0.960000\n",
      "[2593]: loss: 0.007211 accuracy: 0.960000\n",
      "[2594]: loss: 0.005579 accuracy: 0.970000\n",
      "[2595]: loss: 0.006387 accuracy: 0.970000\n",
      "[2596]: loss: 0.009442 accuracy: 0.940000\n",
      "[2597]: loss: 0.006400 accuracy: 0.970000\n",
      "[2598]: loss: 0.005131 accuracy: 0.980000\n",
      "[2599]: loss: 0.004106 accuracy: 0.980000\n",
      "[2600]: loss: 0.010689 accuracy: 0.940000\n",
      "[2601]: loss: 0.015439 accuracy: 0.940000\n",
      "[2602]: loss: 0.008399 accuracy: 0.960000\n",
      "[2603]: loss: 0.007171 accuracy: 0.940000\n",
      "[2604]: loss: 0.008591 accuracy: 0.960000\n",
      "[2605]: loss: 0.002588 accuracy: 0.990000\n",
      "[2606]: loss: 0.003194 accuracy: 0.990000\n",
      "[2607]: loss: 0.005331 accuracy: 0.970000\n",
      "[2608]: loss: 0.007141 accuracy: 0.950000\n",
      "[2609]: loss: 0.006335 accuracy: 0.970000\n",
      "[2610]: loss: 0.005450 accuracy: 0.970000\n",
      "[2611]: loss: 0.007765 accuracy: 0.970000\n",
      "[2612]: loss: 0.008327 accuracy: 0.970000\n",
      "[2613]: loss: 0.002934 accuracy: 0.980000\n",
      "[2614]: loss: 0.006189 accuracy: 0.970000\n",
      "[2615]: loss: 0.006125 accuracy: 0.960000\n",
      "[2616]: loss: 0.002700 accuracy: 0.990000\n",
      "[2617]: loss: 0.008032 accuracy: 0.940000\n",
      "[2618]: loss: 0.005400 accuracy: 0.970000\n",
      "[2619]: loss: 0.006309 accuracy: 0.970000\n",
      "[2620]: loss: 0.006544 accuracy: 0.970000\n",
      "[2621]: loss: 0.004874 accuracy: 0.970000\n",
      "[2622]: loss: 0.003965 accuracy: 0.990000\n",
      "[2623]: loss: 0.005717 accuracy: 0.990000\n",
      "[2624]: loss: 0.007968 accuracy: 0.960000\n",
      "[2625]: loss: 0.006262 accuracy: 0.970000\n",
      "[2626]: loss: 0.004791 accuracy: 0.990000\n",
      "[2627]: loss: 0.009096 accuracy: 0.960000\n",
      "[2628]: loss: 0.005646 accuracy: 0.980000\n",
      "[2629]: loss: 0.006686 accuracy: 0.960000\n",
      "[2630]: loss: 0.005241 accuracy: 0.970000\n",
      "[2631]: loss: 0.004575 accuracy: 0.980000\n",
      "[2632]: loss: 0.005274 accuracy: 0.980000\n",
      "[2633]: loss: 0.007902 accuracy: 0.950000\n",
      "[2634]: loss: 0.005797 accuracy: 0.980000\n",
      "[2635]: loss: 0.004961 accuracy: 0.960000\n",
      "[2636]: loss: 0.003944 accuracy: 0.980000\n",
      "[2637]: loss: 0.004017 accuracy: 1.000000\n",
      "[2638]: loss: 0.007577 accuracy: 0.960000\n",
      "[2639]: loss: 0.008526 accuracy: 0.960000\n",
      "[2640]: loss: 0.004425 accuracy: 0.990000\n",
      "[2641]: loss: 0.004095 accuracy: 0.980000\n",
      "[2642]: loss: 0.006866 accuracy: 0.970000\n",
      "[2643]: loss: 0.007265 accuracy: 0.970000\n",
      "[2644]: loss: 0.006943 accuracy: 0.950000\n",
      "[2645]: loss: 0.008428 accuracy: 0.950000\n",
      "[2646]: loss: 0.003976 accuracy: 0.990000\n",
      "[2647]: loss: 0.004724 accuracy: 0.980000\n",
      "[2648]: loss: 0.004829 accuracy: 0.980000\n",
      "[2649]: loss: 0.005945 accuracy: 0.980000\n",
      "[2650]: loss: 0.009091 accuracy: 0.950000\n",
      "[2651]: loss: 0.006638 accuracy: 0.930000\n",
      "[2652]: loss: 0.006054 accuracy: 0.970000\n",
      "[2653]: loss: 0.005714 accuracy: 0.960000\n",
      "[2654]: loss: 0.004818 accuracy: 0.980000\n",
      "[2655]: loss: 0.006450 accuracy: 0.970000\n",
      "[2656]: loss: 0.006340 accuracy: 0.950000\n",
      "[2657]: loss: 0.009718 accuracy: 0.980000\n",
      "[2658]: loss: 0.006565 accuracy: 0.970000\n",
      "[2659]: loss: 0.005164 accuracy: 0.970000\n",
      "[2660]: loss: 0.004379 accuracy: 0.990000\n",
      "[2661]: loss: 0.004059 accuracy: 0.990000\n",
      "[2662]: loss: 0.006333 accuracy: 0.970000\n",
      "[2663]: loss: 0.011075 accuracy: 0.960000\n",
      "[2664]: loss: 0.004721 accuracy: 0.990000\n",
      "[2665]: loss: 0.003449 accuracy: 0.990000\n",
      "[2666]: loss: 0.007493 accuracy: 0.950000\n",
      "[2667]: loss: 0.004790 accuracy: 0.980000\n",
      "[2668]: loss: 0.007754 accuracy: 0.940000\n",
      "[2669]: loss: 0.005652 accuracy: 0.980000\n",
      "[2670]: loss: 0.009011 accuracy: 0.950000\n",
      "[2671]: loss: 0.007594 accuracy: 0.950000\n",
      "[2672]: loss: 0.007740 accuracy: 0.960000\n",
      "[2673]: loss: 0.005088 accuracy: 0.980000\n",
      "[2674]: loss: 0.005307 accuracy: 0.960000\n",
      "[2675]: loss: 0.010319 accuracy: 0.940000\n",
      "[2676]: loss: 0.003637 accuracy: 0.990000\n",
      "[2677]: loss: 0.003800 accuracy: 0.990000\n",
      "[2678]: loss: 0.009575 accuracy: 0.930000\n",
      "[2679]: loss: 0.008254 accuracy: 0.920000\n",
      "[2680]: loss: 0.006586 accuracy: 0.960000\n",
      "[2681]: loss: 0.007050 accuracy: 0.970000\n",
      "[2682]: loss: 0.007198 accuracy: 0.950000\n",
      "[2683]: loss: 0.005573 accuracy: 0.980000\n",
      "[2684]: loss: 0.004825 accuracy: 0.960000\n",
      "[2685]: loss: 0.004787 accuracy: 0.980000\n",
      "[2686]: loss: 0.008589 accuracy: 0.940000\n",
      "[2687]: loss: 0.009656 accuracy: 0.940000\n",
      "[2688]: loss: 0.007818 accuracy: 0.980000\n",
      "[2689]: loss: 0.003990 accuracy: 0.980000\n",
      "[2690]: loss: 0.006159 accuracy: 0.950000\n",
      "[2691]: loss: 0.005242 accuracy: 0.980000\n",
      "[2692]: loss: 0.004772 accuracy: 0.970000\n",
      "[2693]: loss: 0.005297 accuracy: 0.990000\n",
      "[2694]: loss: 0.006938 accuracy: 0.960000\n",
      "[2695]: loss: 0.003456 accuracy: 0.980000\n",
      "[2696]: loss: 0.004457 accuracy: 1.000000\n",
      "[2697]: loss: 0.008299 accuracy: 0.960000\n",
      "[2698]: loss: 0.007338 accuracy: 0.950000\n",
      "[2699]: loss: 0.004576 accuracy: 0.980000\n",
      "[2700]: loss: 0.006089 accuracy: 0.960000\n",
      "[2701]: loss: 0.007542 accuracy: 0.970000\n",
      "[2702]: loss: 0.002813 accuracy: 0.980000\n",
      "[2703]: loss: 0.006318 accuracy: 0.960000\n",
      "[2704]: loss: 0.004185 accuracy: 0.980000\n",
      "[2705]: loss: 0.006220 accuracy: 0.960000\n",
      "[2706]: loss: 0.007299 accuracy: 0.960000\n",
      "[2707]: loss: 0.005657 accuracy: 0.970000\n",
      "[2708]: loss: 0.003846 accuracy: 0.990000\n",
      "[2709]: loss: 0.007498 accuracy: 0.930000\n",
      "[2710]: loss: 0.007295 accuracy: 0.970000\n",
      "[2711]: loss: 0.002861 accuracy: 1.000000\n",
      "[2712]: loss: 0.009452 accuracy: 0.950000\n",
      "[2713]: loss: 0.014520 accuracy: 0.940000\n",
      "[2714]: loss: 0.003442 accuracy: 0.980000\n",
      "[2715]: loss: 0.004732 accuracy: 0.980000\n",
      "[2716]: loss: 0.006820 accuracy: 0.980000\n",
      "[2717]: loss: 0.007248 accuracy: 0.970000\n",
      "[2718]: loss: 0.008252 accuracy: 0.960000\n",
      "[2719]: loss: 0.003258 accuracy: 0.990000\n",
      "[2720]: loss: 0.004434 accuracy: 0.990000\n",
      "[2721]: loss: 0.008018 accuracy: 0.960000\n",
      "[2722]: loss: 0.008764 accuracy: 0.960000\n",
      "[2723]: loss: 0.004111 accuracy: 0.990000\n",
      "[2724]: loss: 0.006810 accuracy: 0.970000\n",
      "[2725]: loss: 0.008372 accuracy: 0.960000\n",
      "[2726]: loss: 0.005311 accuracy: 0.970000\n",
      "[2727]: loss: 0.005173 accuracy: 0.970000\n",
      "[2728]: loss: 0.009913 accuracy: 0.950000\n",
      "[2729]: loss: 0.006555 accuracy: 0.970000\n",
      "[2730]: loss: 0.005382 accuracy: 0.950000\n",
      "[2731]: loss: 0.008941 accuracy: 0.950000\n",
      "[2732]: loss: 0.007566 accuracy: 0.960000\n",
      "[2733]: loss: 0.003584 accuracy: 0.990000\n",
      "[2734]: loss: 0.007075 accuracy: 0.980000\n",
      "[2735]: loss: 0.005205 accuracy: 0.990000\n",
      "[2736]: loss: 0.007380 accuracy: 0.950000\n",
      "[2737]: loss: 0.008432 accuracy: 0.960000\n",
      "[2738]: loss: 0.003105 accuracy: 0.990000\n",
      "[2739]: loss: 0.005176 accuracy: 0.970000\n",
      "[2740]: loss: 0.006687 accuracy: 0.950000\n",
      "[2741]: loss: 0.004786 accuracy: 0.960000\n",
      "[2742]: loss: 0.008217 accuracy: 0.960000\n",
      "[2743]: loss: 0.006464 accuracy: 0.990000\n",
      "[2744]: loss: 0.008161 accuracy: 0.940000\n",
      "[2745]: loss: 0.007705 accuracy: 0.960000\n",
      "[2746]: loss: 0.004837 accuracy: 0.980000\n",
      "[2747]: loss: 0.006679 accuracy: 0.980000\n",
      "[2748]: loss: 0.003354 accuracy: 0.980000\n",
      "[2749]: loss: 0.009591 accuracy: 0.970000\n",
      "[2750]: loss: 0.004799 accuracy: 0.970000\n",
      "[2751]: loss: 0.003644 accuracy: 0.980000\n",
      "[2752]: loss: 0.006879 accuracy: 0.950000\n",
      "[2753]: loss: 0.008620 accuracy: 0.960000\n",
      "[2754]: loss: 0.008452 accuracy: 0.940000\n",
      "[2755]: loss: 0.005089 accuracy: 0.990000\n",
      "[2756]: loss: 0.006727 accuracy: 0.980000\n",
      "[2757]: loss: 0.005139 accuracy: 0.970000\n",
      "[2758]: loss: 0.004436 accuracy: 0.980000\n",
      "[2759]: loss: 0.006679 accuracy: 0.950000\n",
      "[2760]: loss: 0.005905 accuracy: 0.960000\n",
      "[2761]: loss: 0.004503 accuracy: 0.980000\n",
      "[2762]: loss: 0.008102 accuracy: 0.950000\n",
      "[2763]: loss: 0.005975 accuracy: 0.990000\n",
      "[2764]: loss: 0.004019 accuracy: 0.970000\n",
      "[2765]: loss: 0.004220 accuracy: 0.980000\n",
      "[2766]: loss: 0.003293 accuracy: 0.990000\n",
      "[2767]: loss: 0.005871 accuracy: 0.980000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2768]: loss: 0.006589 accuracy: 0.960000\n",
      "[2769]: loss: 0.003751 accuracy: 0.980000\n",
      "[2770]: loss: 0.009545 accuracy: 0.940000\n",
      "[2771]: loss: 0.009505 accuracy: 0.950000\n",
      "[2772]: loss: 0.005257 accuracy: 0.970000\n",
      "[2773]: loss: 0.009108 accuracy: 0.970000\n",
      "[2774]: loss: 0.004628 accuracy: 0.980000\n",
      "[2775]: loss: 0.004752 accuracy: 0.980000\n",
      "[2776]: loss: 0.002898 accuracy: 1.000000\n",
      "[2777]: loss: 0.006137 accuracy: 0.980000\n",
      "[2778]: loss: 0.006293 accuracy: 0.960000\n",
      "[2779]: loss: 0.003957 accuracy: 0.980000\n",
      "[2780]: loss: 0.006465 accuracy: 0.980000\n",
      "[2781]: loss: 0.010111 accuracy: 0.960000\n",
      "[2782]: loss: 0.004182 accuracy: 0.970000\n",
      "[2783]: loss: 0.010111 accuracy: 0.940000\n",
      "[2784]: loss: 0.008186 accuracy: 0.930000\n",
      "[2785]: loss: 0.011142 accuracy: 0.950000\n",
      "[2786]: loss: 0.005879 accuracy: 0.980000\n",
      "[2787]: loss: 0.005258 accuracy: 0.980000\n",
      "[2788]: loss: 0.006311 accuracy: 0.950000\n",
      "[2789]: loss: 0.006168 accuracy: 0.970000\n",
      "[2790]: loss: 0.006163 accuracy: 0.950000\n",
      "[2791]: loss: 0.008289 accuracy: 0.950000\n",
      "[2792]: loss: 0.005357 accuracy: 0.980000\n",
      "[2793]: loss: 0.009426 accuracy: 0.930000\n",
      "[2794]: loss: 0.006863 accuracy: 0.970000\n",
      "[2795]: loss: 0.004716 accuracy: 0.990000\n",
      "[2796]: loss: 0.005999 accuracy: 0.980000\n",
      "[2797]: loss: 0.004362 accuracy: 0.980000\n",
      "[2798]: loss: 0.003626 accuracy: 0.990000\n",
      "[2799]: loss: 0.005408 accuracy: 0.990000\n",
      "[2800]: loss: 0.002424 accuracy: 0.990000\n",
      "[2801]: loss: 0.006668 accuracy: 0.960000\n",
      "[2802]: loss: 0.003469 accuracy: 0.980000\n",
      "[2803]: loss: 0.008993 accuracy: 0.960000\n",
      "[2804]: loss: 0.006741 accuracy: 0.950000\n",
      "[2805]: loss: 0.002526 accuracy: 0.990000\n",
      "[2806]: loss: 0.005934 accuracy: 0.980000\n",
      "[2807]: loss: 0.009986 accuracy: 0.950000\n",
      "[2808]: loss: 0.003628 accuracy: 1.000000\n",
      "[2809]: loss: 0.002346 accuracy: 0.990000\n",
      "[2810]: loss: 0.005691 accuracy: 0.960000\n",
      "[2811]: loss: 0.001983 accuracy: 0.990000\n",
      "[2812]: loss: 0.007280 accuracy: 0.960000\n",
      "[2813]: loss: 0.002997 accuracy: 0.990000\n",
      "[2814]: loss: 0.004812 accuracy: 0.970000\n",
      "[2815]: loss: 0.002599 accuracy: 0.990000\n",
      "[2816]: loss: 0.004075 accuracy: 0.990000\n",
      "[2817]: loss: 0.003031 accuracy: 0.990000\n",
      "[2818]: loss: 0.002504 accuracy: 0.990000\n",
      "[2819]: loss: 0.003461 accuracy: 0.980000\n",
      "[2820]: loss: 0.006970 accuracy: 0.970000\n",
      "[2821]: loss: 0.005433 accuracy: 0.960000\n",
      "[2822]: loss: 0.004961 accuracy: 0.990000\n",
      "[2823]: loss: 0.003644 accuracy: 0.990000\n",
      "[2824]: loss: 0.007119 accuracy: 0.970000\n",
      "[2825]: loss: 0.004440 accuracy: 0.980000\n",
      "[2826]: loss: 0.003591 accuracy: 1.000000\n",
      "[2827]: loss: 0.004189 accuracy: 1.000000\n",
      "[2828]: loss: 0.003405 accuracy: 0.980000\n",
      "[2829]: loss: 0.005175 accuracy: 0.970000\n",
      "[2830]: loss: 0.002804 accuracy: 0.990000\n",
      "[2831]: loss: 0.004889 accuracy: 0.990000\n",
      "[2832]: loss: 0.007731 accuracy: 0.980000\n",
      "[2833]: loss: 0.006890 accuracy: 0.950000\n",
      "[2834]: loss: 0.008624 accuracy: 0.960000\n",
      "[2835]: loss: 0.008641 accuracy: 0.950000\n",
      "[2836]: loss: 0.004682 accuracy: 0.990000\n",
      "[2837]: loss: 0.006104 accuracy: 0.970000\n",
      "[2838]: loss: 0.004776 accuracy: 0.990000\n",
      "[2839]: loss: 0.005535 accuracy: 0.990000\n",
      "[2840]: loss: 0.004430 accuracy: 0.980000\n",
      "[2841]: loss: 0.002168 accuracy: 0.990000\n",
      "[2842]: loss: 0.002977 accuracy: 0.990000\n",
      "[2843]: loss: 0.007729 accuracy: 0.960000\n",
      "[2844]: loss: 0.005389 accuracy: 0.980000\n",
      "[2845]: loss: 0.005584 accuracy: 0.990000\n",
      "[2846]: loss: 0.007729 accuracy: 0.970000\n",
      "[2847]: loss: 0.003141 accuracy: 0.990000\n",
      "[2848]: loss: 0.005263 accuracy: 0.960000\n",
      "[2849]: loss: 0.009434 accuracy: 0.960000\n",
      "[2850]: loss: 0.003624 accuracy: 0.980000\n",
      "[2851]: loss: 0.004246 accuracy: 0.980000\n",
      "[2852]: loss: 0.003907 accuracy: 0.990000\n",
      "[2853]: loss: 0.006723 accuracy: 0.960000\n",
      "[2854]: loss: 0.006743 accuracy: 0.970000\n",
      "[2855]: loss: 0.003886 accuracy: 0.980000\n",
      "[2856]: loss: 0.005015 accuracy: 0.980000\n",
      "[2857]: loss: 0.005796 accuracy: 0.970000\n",
      "[2858]: loss: 0.005362 accuracy: 0.970000\n",
      "[2859]: loss: 0.003554 accuracy: 0.990000\n",
      "[2860]: loss: 0.002025 accuracy: 1.000000\n",
      "[2861]: loss: 0.005704 accuracy: 0.980000\n",
      "[2862]: loss: 0.010469 accuracy: 0.940000\n",
      "[2863]: loss: 0.002785 accuracy: 1.000000\n",
      "[2864]: loss: 0.003620 accuracy: 0.980000\n",
      "[2865]: loss: 0.003192 accuracy: 0.990000\n",
      "[2866]: loss: 0.008024 accuracy: 0.960000\n",
      "[2867]: loss: 0.004816 accuracy: 0.970000\n",
      "[2868]: loss: 0.004988 accuracy: 0.980000\n",
      "[2869]: loss: 0.003383 accuracy: 1.000000\n",
      "[2870]: loss: 0.010026 accuracy: 0.940000\n",
      "[2871]: loss: 0.005830 accuracy: 0.960000\n",
      "[2872]: loss: 0.002380 accuracy: 1.000000\n",
      "[2873]: loss: 0.004961 accuracy: 0.980000\n",
      "[2874]: loss: 0.003162 accuracy: 0.990000\n",
      "[2875]: loss: 0.004488 accuracy: 0.970000\n",
      "[2876]: loss: 0.006827 accuracy: 0.960000\n",
      "[2877]: loss: 0.005458 accuracy: 0.980000\n",
      "[2878]: loss: 0.004974 accuracy: 0.960000\n",
      "[2879]: loss: 0.011325 accuracy: 0.930000\n",
      "[2880]: loss: 0.004760 accuracy: 0.960000\n",
      "[2881]: loss: 0.010757 accuracy: 0.950000\n",
      "[2882]: loss: 0.007668 accuracy: 0.970000\n",
      "[2883]: loss: 0.006783 accuracy: 0.970000\n",
      "[2884]: loss: 0.004919 accuracy: 0.970000\n",
      "[2885]: loss: 0.006043 accuracy: 0.970000\n",
      "[2886]: loss: 0.005447 accuracy: 0.980000\n",
      "[2887]: loss: 0.006282 accuracy: 0.960000\n",
      "[2888]: loss: 0.003578 accuracy: 0.990000\n",
      "[2889]: loss: 0.007316 accuracy: 0.980000\n",
      "[2890]: loss: 0.002962 accuracy: 0.990000\n",
      "[2891]: loss: 0.004094 accuracy: 0.990000\n",
      "[2892]: loss: 0.008655 accuracy: 0.970000\n",
      "[2893]: loss: 0.002665 accuracy: 0.990000\n",
      "[2894]: loss: 0.005212 accuracy: 0.970000\n",
      "[2895]: loss: 0.004672 accuracy: 0.970000\n",
      "[2896]: loss: 0.005492 accuracy: 0.960000\n",
      "[2897]: loss: 0.004903 accuracy: 0.990000\n",
      "[2898]: loss: 0.003436 accuracy: 0.980000\n",
      "[2899]: loss: 0.005864 accuracy: 0.980000\n",
      "[2900]: loss: 0.002987 accuracy: 0.980000\n",
      "[2901]: loss: 0.003126 accuracy: 0.980000\n",
      "[2902]: loss: 0.002825 accuracy: 0.990000\n",
      "[2903]: loss: 0.004943 accuracy: 0.980000\n",
      "[2904]: loss: 0.005007 accuracy: 0.970000\n",
      "[2905]: loss: 0.003663 accuracy: 0.980000\n",
      "[2906]: loss: 0.004605 accuracy: 0.980000\n",
      "[2907]: loss: 0.007631 accuracy: 0.960000\n",
      "[2908]: loss: 0.009174 accuracy: 0.930000\n",
      "[2909]: loss: 0.003638 accuracy: 0.980000\n",
      "[2910]: loss: 0.004067 accuracy: 0.980000\n",
      "[2911]: loss: 0.007779 accuracy: 0.960000\n",
      "[2912]: loss: 0.005464 accuracy: 0.980000\n",
      "[2913]: loss: 0.003339 accuracy: 0.990000\n",
      "[2914]: loss: 0.006344 accuracy: 0.970000\n",
      "[2915]: loss: 0.006442 accuracy: 0.950000\n",
      "[2916]: loss: 0.009355 accuracy: 0.960000\n",
      "[2917]: loss: 0.003693 accuracy: 0.980000\n",
      "[2918]: loss: 0.004601 accuracy: 0.970000\n",
      "[2919]: loss: 0.004221 accuracy: 0.990000\n",
      "[2920]: loss: 0.003851 accuracy: 0.990000\n",
      "[2921]: loss: 0.004675 accuracy: 0.980000\n",
      "[2922]: loss: 0.006754 accuracy: 0.980000\n",
      "[2923]: loss: 0.005895 accuracy: 0.960000\n",
      "[2924]: loss: 0.003879 accuracy: 1.000000\n",
      "[2925]: loss: 0.002935 accuracy: 0.990000\n",
      "[2926]: loss: 0.005009 accuracy: 0.970000\n",
      "[2927]: loss: 0.004067 accuracy: 0.990000\n",
      "[2928]: loss: 0.003811 accuracy: 0.980000\n",
      "[2929]: loss: 0.002618 accuracy: 0.990000\n",
      "[2930]: loss: 0.009874 accuracy: 0.950000\n",
      "[2931]: loss: 0.003388 accuracy: 0.990000\n",
      "[2932]: loss: 0.006510 accuracy: 0.970000\n",
      "[2933]: loss: 0.005069 accuracy: 0.970000\n",
      "[2934]: loss: 0.004846 accuracy: 0.960000\n",
      "[2935]: loss: 0.006573 accuracy: 0.980000\n",
      "[2936]: loss: 0.006123 accuracy: 0.960000\n",
      "[2937]: loss: 0.009362 accuracy: 0.970000\n",
      "[2938]: loss: 0.004832 accuracy: 0.980000\n",
      "[2939]: loss: 0.006338 accuracy: 0.960000\n",
      "[2940]: loss: 0.006606 accuracy: 0.960000\n",
      "[2941]: loss: 0.005825 accuracy: 0.950000\n",
      "[2942]: loss: 0.009159 accuracy: 0.930000\n",
      "[2943]: loss: 0.009986 accuracy: 0.940000\n",
      "[2944]: loss: 0.002582 accuracy: 0.990000\n",
      "[2945]: loss: 0.003627 accuracy: 0.990000\n",
      "[2946]: loss: 0.007283 accuracy: 0.950000\n",
      "[2947]: loss: 0.010070 accuracy: 0.950000\n",
      "[2948]: loss: 0.005634 accuracy: 0.970000\n",
      "[2949]: loss: 0.004488 accuracy: 0.980000\n",
      "[2950]: loss: 0.004768 accuracy: 0.960000\n",
      "[2951]: loss: 0.004447 accuracy: 0.970000\n",
      "[2952]: loss: 0.010332 accuracy: 0.960000\n",
      "[2953]: loss: 0.004622 accuracy: 0.980000\n",
      "[2954]: loss: 0.003695 accuracy: 0.990000\n",
      "[2955]: loss: 0.004952 accuracy: 0.980000\n",
      "[2956]: loss: 0.005105 accuracy: 0.980000\n",
      "[2957]: loss: 0.006671 accuracy: 0.970000\n",
      "[2958]: loss: 0.003238 accuracy: 0.990000\n",
      "[2959]: loss: 0.004570 accuracy: 0.980000\n",
      "[2960]: loss: 0.002158 accuracy: 1.000000\n",
      "[2961]: loss: 0.002819 accuracy: 0.990000\n",
      "[2962]: loss: 0.005897 accuracy: 0.980000\n",
      "[2963]: loss: 0.000762 accuracy: 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2964]: loss: 0.004414 accuracy: 0.980000\n",
      "[2965]: loss: 0.005055 accuracy: 0.960000\n",
      "[2966]: loss: 0.013016 accuracy: 0.940000\n",
      "[2967]: loss: 0.003068 accuracy: 1.000000\n",
      "[2968]: loss: 0.008208 accuracy: 0.960000\n",
      "[2969]: loss: 0.004355 accuracy: 0.970000\n",
      "[2970]: loss: 0.008234 accuracy: 0.950000\n",
      "[2971]: loss: 0.004362 accuracy: 0.980000\n",
      "[2972]: loss: 0.004327 accuracy: 0.980000\n",
      "[2973]: loss: 0.002826 accuracy: 0.980000\n",
      "[2974]: loss: 0.003934 accuracy: 0.990000\n",
      "[2975]: loss: 0.003755 accuracy: 0.990000\n",
      "[2976]: loss: 0.003746 accuracy: 0.990000\n",
      "[2977]: loss: 0.005962 accuracy: 0.990000\n",
      "[2978]: loss: 0.009560 accuracy: 0.950000\n",
      "[2979]: loss: 0.005979 accuracy: 0.960000\n",
      "[2980]: loss: 0.001681 accuracy: 1.000000\n",
      "[2981]: loss: 0.004781 accuracy: 1.000000\n",
      "[2982]: loss: 0.007148 accuracy: 0.980000\n",
      "[2983]: loss: 0.006476 accuracy: 0.970000\n",
      "[2984]: loss: 0.001917 accuracy: 1.000000\n",
      "[2985]: loss: 0.003791 accuracy: 0.990000\n",
      "[2986]: loss: 0.003788 accuracy: 0.980000\n",
      "[2987]: loss: 0.005670 accuracy: 0.960000\n",
      "[2988]: loss: 0.004964 accuracy: 0.980000\n",
      "[2989]: loss: 0.004726 accuracy: 0.970000\n",
      "[2990]: loss: 0.004444 accuracy: 0.980000\n",
      "[2991]: loss: 0.003892 accuracy: 0.990000\n",
      "[2992]: loss: 0.004204 accuracy: 0.990000\n",
      "[2993]: loss: 0.002986 accuracy: 0.990000\n",
      "[2994]: loss: 0.006458 accuracy: 0.960000\n",
      "[2995]: loss: 0.004874 accuracy: 0.990000\n",
      "[2996]: loss: 0.003100 accuracy: 0.990000\n",
      "[2997]: loss: 0.005759 accuracy: 0.960000\n",
      "[2998]: loss: 0.007362 accuracy: 0.980000\n",
      "[2999]: loss: 0.004656 accuracy: 0.990000\n"
     ]
    }
   ],
   "source": [
    "for step in range(1, 3000):\n",
    "    imageList, codeList = getData(100)\n",
    "    codeList = map(lambda x: x[index], codeList) # changed \n",
    "    x_data = map(imageToVertor, imageList)\n",
    "    y_data = map(codeToVertor, codeList)\n",
    "    _, l, a = session.run([optimizer, loss, accuracy], feed_dict={x: x_data, y: y_data, keep_prob: .75})\n",
    "    saver.save(session, 'model/%s/model' % index, global_step=step)\n",
    "    print '[%d]: loss: %f accuracy: %f' % (step, l, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    'x': x.name,\n",
    "    'y': y.name,\n",
    "    'prediction': prediction.name,\n",
    "    'keep_prob': keep_prob.name,\n",
    "    'loss': loss.name\n",
    "}\n",
    "pickle.dump(nodes, open('model/%s/nodes.pk' % index, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### .测试模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1). 训练集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: wdn2d\n",
      "prediction: ['d']\n",
      "loss: 1.01029\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN8AAAAyCAIAAABTQZknAAAubklEQVR4nO19eXRUdZr2vVW39lv7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\nMYjGd/KdfJX8HwoDqu+hbbHkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=223x50 at 0x7EFC006C4B90>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageList, codeList = getData(1)\n",
    "x_data = map(imageToVertor, imageList)\n",
    "y_data = map(codeToVertor, codeList)\n",
    "p, l = session.run([prediction, loss], feed_dict={x: x_data, y: y_data, keep_prob: .75})\n",
    "print 'code:', codeList[0]\n",
    "print 'prediction:', map(lambda x: charset[x], p[0])\n",
    "print 'loss:', l\n",
    "imageList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2). 实际测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# url = 'https://s.nacao.org.cn/servlet/ValidateCode?time='\n",
    "# response = requests.get(url)\n",
    "# image = Image.open(StringIO(response.content))\n",
    "# imageList, codeList = [image], ['ca358']\n",
    "# x_data = map(imageToVertor, imageList)\n",
    "# y_data = map(codeToVertor, codeList)\n",
    "# p, l = session.run([prediction, loss], feed_dict={x: x_data, y: y_data, keep_prob: .75})\n",
    "# print 'prediction:', map(lambda x: charset[x], p[0])\n",
    "# print 'loss:', l\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: ['8']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN8AAAAyCAIAAABTQZknAAAwTklEQVR4nO19Z3CcVZru+Tp8nXNU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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=223x50 at 0x7EFC08AFACD0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://s.nacao.org.cn/servlet/ValidateCode?time='\n",
    "response = requests.get(url)\n",
    "image = Image.open(StringIO(response.content))\n",
    "imageList = [image]\n",
    "x_data = map(imageToVertor, imageList)\n",
    "p = session.run(prediction, feed_dict={x: x_data, keep_prob: 1})\n",
    "print 'prediction:', map(lambda x: charset[x], p[0])\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
